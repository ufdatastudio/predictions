{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling Prediction Sentences\n",
    "\n",
    "1. **Research Focus**\n",
    "    - **Main Idea:** Certifying textual predictions given some observations\n",
    "2. **Task**:\n",
    "    - **Main Idea:** Sequence Labeling is the action of tagging each term in the sequence\n",
    "3. **Methods:**\n",
    "    - **Main Idea:** Learn the structure of the sequence\n",
    "4. **Decoding Techniques:**\n",
    "    - Greedy\n",
    "    - Viterbi\n",
    "5. **Notes on the data and given files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "pd.set_option('max_colwidth', 800)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Focus\n",
    "\n",
    "- **Main Idea:** Certifying textual predictions given some observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Mathematical Representation of Prediction:**\n",
    "\n",
    "    $$\n",
    "    P = \\{p_1, p_2, ..., p_N\\}, where \\\\\n",
    "    p_i = (p_{source}, p_{target}, p_{date}, p_{outcome})\n",
    "    $$\n",
    "\n",
    "- **Mathematical Representation of Observation:**\n",
    "\n",
    "    $$\n",
    "    O = \\{o_1, o_2, ..., o_M\\}, where \\\\\n",
    "    o_i = (o_{source}, o_{target}, o_{date}, o_{outcome})\n",
    "    $$\n",
    "- **Difference between $ P $ and $ O $:**\n",
    "    1. $ P $ is future tense\n",
    "    2. $ O $ is past tense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to load P and O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "- **Main Idea:** Sequence Labeling is the action of providing a certain label to each term in the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Label Examples:**\n",
    "\n",
    "    1. Part-of-Speech (POS)\n",
    "    2. Named Entities \n",
    "    3. BOIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "- **Main Idea:** Learn the structure of the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Manually\n",
    "1. Rules\n",
    "    1. Think: if then statements\n",
    "    2. Curated by lingusts\n",
    "    3. Too many combinations\n",
    "    4. Tags can be ambiguous \n",
    "2.  Hidden Markov Model (HMM)\n",
    "    1. Markov Model\n",
    "        1. Developed by: Andrei A. Markov in 1913\n",
    "    2. Probabilistic based\n",
    "    2. Sequential model based on the Markov\n",
    "    2. Utilizes the joint distribution\n",
    "    2. Dependent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Update Data\n",
    "- [x] Find a way to separate sentences when loading the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str, file_name: str, is_test_file: bool, config_index: bool = True):\n",
    "    \n",
    "    if config_index == True:\n",
    "        if is_test_file != True:\n",
    "            file =  file_path + file_name\n",
    "            open_df = pd.read_table(file, sep = \"\\t\", names=['Index', 'Term', 'BIO x Prediction Tag'], skip_blank_lines=False)\n",
    "        else:\n",
    "            file =  file_path + file_name\n",
    "            open_df = pd.read_table(file, sep = \"\\t\", names=['Index', 'Word'], skip_blank_lines=False)\n",
    "        \n",
    "    return open_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_df_rows_with_dummy(df: pd.DataFrame, new_columns_name: list) -> pd.DataFrame:  \n",
    "    \"\"\"Update the rows of the dataframe if blank space, fill with dummy\"\"\"  \n",
    "\n",
    "    dummy_row = pd.DataFrame([['0.0', ' ', 'dummy']], columns=df.columns)\n",
    "    df = pd.concat([dummy_row, df], ignore_index=True)\n",
    "    df.columns = new_columns_name\n",
    "    df.fillna(\"dummy\", inplace=True)\n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data('../data/tagging/official/', 'train', False)\n",
    "# dev_df = load_data('data/', 'dev', False)\n",
    "# test_df = load_data('data/', 'test', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_columns_name = ['Index', 'Word', 'POS Tag']\n",
    "\n",
    "updated_train_df = update_df_rows_with_dummy(train_df, train_dev_columns_name)\n",
    "# updated_dev_df = update_df_rows_with_dummy(dev_df, train_dev_columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dummy', 'B-p_s', 'I-p_s', 'O', 'B-p_o', 'I-p_o', 'B-p_t', 'I-p_t',\n",
       "       'B-p_d', ' ', 'I-p_d'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pos_tags = updated_train_df['POS Tag'].unique()\n",
    "all_pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of Tasks\n",
    "\n",
    "1. Vocabulary Creation\n",
    "2. Model Learning\n",
    "3. Greedy Decoding with HMM\n",
    "4. Viterbi Decoding with HMM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Vocabulary Creation\n",
    "\n",
    "- **Problem:** Creating vocabulary to handle unkown words.\n",
    "    - **Solution:** Replace rare words wtih whose occurrences are less than a threshold (ie: 3) with a special token `< unk >`\n",
    "\n",
    "---\n",
    "\n",
    "1. [x] Create a vocabulary using the training data in the file train\n",
    "2. [x] Output the vocabulary into a txt file named `vocab.txt`\n",
    "    - [x] See PDF on how to properly format vocabulary file\n",
    "3. [x] Questions\n",
    "    1. [x] What is the selected threshold for unknown words replacement? 3\n",
    "    2. [x] What is the total size of your vocabulary? 13751\n",
    "    3. [x] What is the total occurrences of the special token `< unk >` after replacement? 29443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>likely</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>that</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>at</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>to</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rise</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2027</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr.</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>of</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>according</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stable</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stay</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>decrease</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>speculates</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>on</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>predicts</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>levels</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>increase</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>In</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>According</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>fall</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>On</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Q3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>August</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>envisions</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>forecasts</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2024</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Q2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>September</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2026</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Kim</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Chen</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>health</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>public</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Lee</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Weather</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>National</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Emily</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>average</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>activity</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>precipitation</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2029</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>November</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Meteorologist</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>rate</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Health</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>expected</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>David</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2028</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>and</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Rachel</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Michael</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Q4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>stock</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>price</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>index</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>centers</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>rates</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Denver</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>energy</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Renewable</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>sector</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Sophia</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Apple</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Patel</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Morgan</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Stanley</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>among</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>American</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>advisor</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>economic</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Physical</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>growth</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>investments</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>finance</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Brown</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>wind</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>are</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>temperature</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Miami</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>humidity</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>speed</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Angeles</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Los</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>analyst</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Sachs</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2024/08/21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>York</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>New</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Service</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>sugar</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Goldman</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>consumption</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Prevention</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Disease</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>January</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>S&amp;P</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>physical</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Association</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Heart</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>urban</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>for</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>obesity</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Centers</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Fargo</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Organization</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Wells</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>World</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Control</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>institutions</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>defense</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>allocation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Senator</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>moderately</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>trust</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>08</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>expects</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>schools</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Channel</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>emerging</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>States</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>United</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>rural</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>prevalence</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>could</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>awareness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>national</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Professor</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>climb</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>market</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>research</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>chronic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>teenagers</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>financial</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>equities</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>employment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Smith</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>small</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>James</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>businesses</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Mr.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>returns</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Federal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Reserve</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>&amp;</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>illnesses</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Institution</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Q1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>composite</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Africa</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>budget</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>economist</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>dummy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>spending</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>policy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Treasury</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Detravious</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>operating</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>yields</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Brookings</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>income</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>America</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Institutes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>clinics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Energy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Bank</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>from</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>children</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>mental</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>disease</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>government</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>number</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Policy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Bureau</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>International</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>healthcare</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>May</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Jones</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Chase</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>revenue</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>projected</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>John</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>engagement</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>preventative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>screenings</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>June</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Institute</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>interest</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Human</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Development</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Child</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Dow</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>08/21/2024</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Francisco</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>federal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>San</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Administration</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Taylor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Representative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>students</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>value</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>affordable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>July</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>units</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Hall</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>21/08/2024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Laboratory</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>housing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Atmospheric</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Davis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Oceanic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>policies</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>college</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>profit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>change</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>climate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>perception</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>projects</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>October</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>net</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>renewable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Alphabet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Analyst</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Ryan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>heart</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>cardiovascular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>strategist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>dollar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>production</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>turnout</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>College</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>projections</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>'s</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>cash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>flow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Henry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>states</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>battleground</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>voter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>oil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>nutritional</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Jane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>cafeterias</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>JPMorgan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Average</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Industrial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Sports</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Medicine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Monetary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Fund</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>global</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Agency</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Asia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>colleges</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Roger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>investor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>an</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Morales</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Ava</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Liam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>March</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tax</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>corporate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>markets</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>investment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>foreign</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Houston</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  count\n",
       "0                 ,    144\n",
       "1                 .    120\n",
       "2               the    118\n",
       "3                      117\n",
       "4              will    110\n",
       "5            likely    110\n",
       "6                in     85\n",
       "7              that     76\n",
       "8                at     64\n",
       "9                to     50\n",
       "10             rise     34\n",
       "11             2025     34\n",
       "12             2027     32\n",
       "13              Dr.     27\n",
       "14               of     26\n",
       "15        according     24\n",
       "16           stable     22\n",
       "17             stay     22\n",
       "18         decrease     20\n",
       "19       speculates     20\n",
       "20               on     20\n",
       "21         predicts     20\n",
       "22           levels     20\n",
       "23         increase     20\n",
       "24               In     20\n",
       "25        According     20\n",
       "26             fall     20\n",
       "27               On     20\n",
       "28              The     18\n",
       "29               Q3     17\n",
       "30           August     17\n",
       "31        envisions     16\n",
       "32        forecasts     16\n",
       "33             2024     15\n",
       "34               21     15\n",
       "35               Q2     15\n",
       "36        September     14\n",
       "37             2026     14\n",
       "38              Kim     14\n",
       "39             Chen     12\n",
       "40           health     12\n",
       "41           public     12\n",
       "42              Lee     11\n",
       "43          Weather     11\n",
       "44         National     11\n",
       "45            Emily     11\n",
       "46          average     10\n",
       "47         activity     10\n",
       "48    precipitation     10\n",
       "49             2029     10\n",
       "50         November     10\n",
       "51    Meteorologist      9\n",
       "52               15      9\n",
       "53             rate      9\n",
       "54           Health      9\n",
       "55                -      9\n",
       "56         expected      9\n",
       "57            David      8\n",
       "58             2028      8\n",
       "59              and      8\n",
       "60           Rachel      8\n",
       "61          Michael      8\n",
       "62               Q4      8\n",
       "63            stock      8\n",
       "64             U.S.      8\n",
       "65          Johnson      7\n",
       "66            price      7\n",
       "67            index      7\n",
       "68          centers      7\n",
       "69            rates      7\n",
       "70           Denver      7\n",
       "71           energy      6\n",
       "72        Renewable      6\n",
       "73           sector      6\n",
       "74           Sophia      6\n",
       "75            Apple      6\n",
       "76            Patel      6\n",
       "77           Morgan      6\n",
       "78          Stanley      6\n",
       "79            among      6\n",
       "80         American      6\n",
       "81          advisor      5\n",
       "82         economic      5\n",
       "83         Physical      5\n",
       "84           growth      5\n",
       "85      investments      5\n",
       "86          finance      5\n",
       "87            Brown      5\n",
       "88             wind      5\n",
       "89              are      5\n",
       "90      temperature      5\n",
       "91      Temperature      5\n",
       "92            Miami      5\n",
       "93         humidity      5\n",
       "94            speed      5\n",
       "95          Angeles      5\n",
       "96              Los      5\n",
       "97          analyst      5\n",
       "98            Sachs      5\n",
       "99       2024/08/21      5\n",
       "100            York      5\n",
       "101             New      5\n",
       "102         Service      5\n",
       "103           sugar      5\n",
       "104         Goldman      5\n",
       "105     consumption      5\n",
       "106               1      5\n",
       "107      Prevention      5\n",
       "108         Disease      5\n",
       "109         January      5\n",
       "110             S&P      5\n",
       "111             500      5\n",
       "112        physical      5\n",
       "113          Amazon      5\n",
       "114     Association      5\n",
       "115           Heart      5\n",
       "116           urban      5\n",
       "117             for      5\n",
       "118         obesity      5\n",
       "119         Centers      5\n",
       "120           Fargo      5\n",
       "121    Organization      5\n",
       "122           Wells      5\n",
       "123           World      5\n",
       "124         Control      5\n",
       "125    institutions      4\n",
       "126         defense      4\n",
       "127      allocation      4\n",
       "128         Senator      4\n",
       "129      moderately      4\n",
       "130           trust      4\n",
       "131              08      4\n",
       "132         expects      4\n",
       "133         Chicago      4\n",
       "134         schools      4\n",
       "135         Channel      4\n",
       "136        emerging      4\n",
       "137          States      4\n",
       "138          United      4\n",
       "139           rural      4\n",
       "140               3      4\n",
       "141      prevalence      4\n",
       "142           could      4\n",
       "143       awareness      4\n",
       "144        national      4\n",
       "145       Professor      4\n",
       "146           climb      4\n",
       "147          market      3\n",
       "148         Seattle      3\n",
       "149        research      3\n",
       "150         chronic      3\n",
       "151       teenagers      3\n",
       "152       financial      3\n",
       "153        equities      3\n",
       "154      employment      3\n",
       "155           Smith      3\n",
       "156           small      3\n",
       "157           James      3\n",
       "158               a      3\n",
       "159      businesses      3\n",
       "160             Mr.      3\n",
       "161         returns      3\n",
       "162         Federal      3\n",
       "163         Reserve      3\n",
       "164               &      3\n",
       "165       illnesses      3\n",
       "166     Institution      3\n",
       "167              Q1      3\n",
       "168       composite      3\n",
       "169            high      3\n",
       "170          Africa      3\n",
       "171              25      3\n",
       "172          budget      3\n",
       "173       economist      3\n",
       "174           dummy      3\n",
       "175        spending      3\n",
       "176          policy      3\n",
       "177        Treasury      3\n",
       "178      Detravious      3\n",
       "179       operating      3\n",
       "180          yields      3\n",
       "181       Brookings      3\n",
       "182          income      2\n",
       "183         America      2\n",
       "184      Institutes      2\n",
       "185         clinics      2\n",
       "186          Energy      2\n",
       "187            Bank      2\n",
       "188            from      2\n",
       "189        children      2\n",
       "190          mental      2\n",
       "191         disease      2\n",
       "192      government      2\n",
       "193          number      2\n",
       "194          Policy      2\n",
       "195          Bureau      2\n",
       "196              22      2\n",
       "197   International      2\n",
       "198      healthcare      2\n",
       "199             May      2\n",
       "200       Microsoft      2\n",
       "201           Jones      2\n",
       "202           Chase      2\n",
       "203         revenue      2\n",
       "204       projected      2\n",
       "205            John      2\n",
       "206              10      2\n",
       "207      engagement      2\n",
       "208    preventative      2\n",
       "209      screenings      2\n",
       "210            June      2\n",
       "211       Institute      2\n",
       "212        interest      2\n",
       "213           Human      2\n",
       "214     Development      2\n",
       "215           Child      2\n",
       "216             Dow      2\n",
       "217      08/21/2024      2\n",
       "218       Francisco      2\n",
       "219         federal      2\n",
       "220             San      2\n",
       "221  Administration      1\n",
       "222           Sarah      1\n",
       "223          Taylor      1\n",
       "224              is      1\n",
       "225  Representative      1\n",
       "226        students      1\n",
       "227           value      1\n",
       "228      affordable      1\n",
       "229            July      1\n",
       "230           units      1\n",
       "231            Hall      1\n",
       "232      21/08/2024      1\n",
       "233      Laboratory      1\n",
       "234         housing      1\n",
       "235           China      1\n",
       "236     Atmospheric      1\n",
       "237           Davis      1\n",
       "238         Oceanic      1\n",
       "239        policies      1\n",
       "240         college      1\n",
       "241          profit      1\n",
       "242          change      1\n",
       "243         climate      1\n",
       "244      perception      1\n",
       "245        projects      1\n",
       "246         October      1\n",
       "247             net      1\n",
       "248       renewable      1\n",
       "249        Alphabet      1\n",
       "250         Analyst      1\n",
       "251            Ryan      1\n",
       "252           heart      1\n",
       "253  cardiovascular      1\n",
       "254      strategist      1\n",
       "255          dollar      1\n",
       "256      production      1\n",
       "257         turnout      1\n",
       "258         College      1\n",
       "259     projections      1\n",
       "260              's      1\n",
       "261            cash      1\n",
       "262            flow      1\n",
       "263           Henry      1\n",
       "264          states      1\n",
       "265    battleground      1\n",
       "266           voter      1\n",
       "267             oil      1\n",
       "268     nutritional      1\n",
       "269            Jane      1\n",
       "270      California      1\n",
       "271      cafeterias      1\n",
       "272          school      1\n",
       "273        JPMorgan      1\n",
       "274         Average      1\n",
       "275      Industrial      1\n",
       "276          Sports      1\n",
       "277        Medicine      1\n",
       "278        Monetary      1\n",
       "279            Fund      1\n",
       "280          global      1\n",
       "281          Agency      1\n",
       "282            Asia      1\n",
       "283        colleges      1\n",
       "284           Roger      1\n",
       "285        investor      1\n",
       "286              an      1\n",
       "287         Morales      1\n",
       "288             Ava      1\n",
       "289            Liam      1\n",
       "290           March      1\n",
       "291      technology      1\n",
       "292             tax      1\n",
       "293       corporate      1\n",
       "294         markets      1\n",
       "295      investment      1\n",
       "296         foreign      1\n",
       "297         Houston      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_false_series = updated_train_df['Word'].value_counts()\n",
    "vocab_df = pd.DataFrame(true_false_series)\n",
    "vocab_df.reset_index(inplace = True)\n",
    "vocab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab_threshold_df(df: pd.DataFrame, word_col_name: str, count_col_name: str, threhold: int, special_token: str, save_df: bool, save_path_with_name: str):\n",
    "    \"\"\"For every word in df, replace with special_token if below threshold\n",
    "    \"\"\"\n",
    "    true_false_series = df[count_col_name] > 3\n",
    "    \n",
    "    updated_vocab_df = df.loc[true_false_series == True]\n",
    "    updated_false_vocab_df = df.loc[true_false_series == False]\n",
    "    updated_false_vocab_df[word_col_name] = special_token\n",
    "    \n",
    "    N_updated_false_vocab_df = len(updated_false_vocab_df)\n",
    "    \n",
    "    new_row = pd.DataFrame([[special_token, N_updated_false_vocab_df]], columns=updated_vocab_df.columns)\n",
    "    final_df = pd.concat([new_row, updated_vocab_df], ignore_index=True)\n",
    "    N_vocab = range(0, len(updated_vocab_df)+1)\n",
    "    \n",
    "    final_df[\"index\"] = N_vocab\n",
    "    \n",
    "    final_df = final_df.reindex(columns=[word_col_name, \"index\", count_col_name])\n",
    "    if save_df == True:\n",
    "        print(save_path_with_name)\n",
    "        final_df.to_csv(save_path_with_name, header=None, index=None, sep='\\t')\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/78/9z0b45fx1xqbwxh8vk97lcfh0000gn/T/ipykernel_75703/2314154369.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  updated_false_vocab_df[word_col_name] = special_token\n"
     ]
    }
   ],
   "source": [
    "word_col_name = \"Word\"\n",
    "count_col_name = \"count\"\n",
    "special_token = \"< unk >\"\n",
    "save_df = False\n",
    "save_file_path_and_name = \"final_submit/vocab.txt\"\n",
    "updated_vocab_df = create_vocab_threshold_df(vocab_df, word_col_name, count_col_name, 3, special_token, save_df, save_file_path_and_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>index</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt; unk &gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>will</td>\n",
       "      <td>5</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>likely</td>\n",
       "      <td>6</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>7</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that</td>\n",
       "      <td>8</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>at</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>to</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rise</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2027</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dr.</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>of</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>according</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stable</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>stay</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>decrease</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>speculates</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>on</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>predicts</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>levels</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>increase</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>In</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>According</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>fall</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>On</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Q3</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>August</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>envisions</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>forecasts</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2024</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Q2</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>September</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2026</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Kim</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Chen</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>health</td>\n",
       "      <td>41</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>public</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Lee</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Weather</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>National</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Emily</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>average</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>activity</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>precipitation</td>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2029</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>November</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Meteorologist</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>15</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>rate</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Health</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>expected</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>David</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2028</td>\n",
       "      <td>59</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>and</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Rachel</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Michael</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Q4</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>stock</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>price</td>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>index</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>centers</td>\n",
       "      <td>69</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>rates</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Denver</td>\n",
       "      <td>71</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>energy</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Renewable</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>sector</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Sophia</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Apple</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Patel</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Morgan</td>\n",
       "      <td>78</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Stanley</td>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>among</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>American</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>advisor</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>economic</td>\n",
       "      <td>83</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Physical</td>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>growth</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>investments</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>finance</td>\n",
       "      <td>87</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Brown</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>wind</td>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>are</td>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>temperature</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Miami</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>humidity</td>\n",
       "      <td>94</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>speed</td>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Angeles</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Los</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>analyst</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Sachs</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2024/08/21</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>York</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>New</td>\n",
       "      <td>102</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Service</td>\n",
       "      <td>103</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>sugar</td>\n",
       "      <td>104</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Goldman</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>consumption</td>\n",
       "      <td>106</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Prevention</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Disease</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>January</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>S&amp;P</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>500</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>physical</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Association</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Heart</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>urban</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>for</td>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>obesity</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Centers</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Fargo</td>\n",
       "      <td>121</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Organization</td>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Wells</td>\n",
       "      <td>123</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>World</td>\n",
       "      <td>124</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Control</td>\n",
       "      <td>125</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>institutions</td>\n",
       "      <td>126</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>defense</td>\n",
       "      <td>127</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>allocation</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Senator</td>\n",
       "      <td>129</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>moderately</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>trust</td>\n",
       "      <td>131</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>08</td>\n",
       "      <td>132</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>expects</td>\n",
       "      <td>133</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>134</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>schools</td>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Channel</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>emerging</td>\n",
       "      <td>137</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>States</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>United</td>\n",
       "      <td>139</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>rural</td>\n",
       "      <td>140</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3</td>\n",
       "      <td>141</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>prevalence</td>\n",
       "      <td>142</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>could</td>\n",
       "      <td>143</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>awareness</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>national</td>\n",
       "      <td>145</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Professor</td>\n",
       "      <td>146</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>climb</td>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word  index  count\n",
       "0          < unk >      0    151\n",
       "1                ,      1    144\n",
       "2                .      2    120\n",
       "3              the      3    118\n",
       "4                       4    117\n",
       "5             will      5    110\n",
       "6           likely      6    110\n",
       "7               in      7     85\n",
       "8             that      8     76\n",
       "9               at      9     64\n",
       "10              to     10     50\n",
       "11            rise     11     34\n",
       "12            2025     12     34\n",
       "13            2027     13     32\n",
       "14             Dr.     14     27\n",
       "15              of     15     26\n",
       "16       according     16     24\n",
       "17          stable     17     22\n",
       "18            stay     18     22\n",
       "19        decrease     19     20\n",
       "20      speculates     20     20\n",
       "21              on     21     20\n",
       "22        predicts     22     20\n",
       "23          levels     23     20\n",
       "24        increase     24     20\n",
       "25              In     25     20\n",
       "26       According     26     20\n",
       "27            fall     27     20\n",
       "28              On     28     20\n",
       "29             The     29     18\n",
       "30              Q3     30     17\n",
       "31          August     31     17\n",
       "32       envisions     32     16\n",
       "33       forecasts     33     16\n",
       "34            2024     34     15\n",
       "35              21     35     15\n",
       "36              Q2     36     15\n",
       "37       September     37     14\n",
       "38            2026     38     14\n",
       "39             Kim     39     14\n",
       "40            Chen     40     12\n",
       "41          health     41     12\n",
       "42          public     42     12\n",
       "43             Lee     43     11\n",
       "44         Weather     44     11\n",
       "45        National     45     11\n",
       "46           Emily     46     11\n",
       "47         average     47     10\n",
       "48        activity     48     10\n",
       "49   precipitation     49     10\n",
       "50            2029     50     10\n",
       "51        November     51     10\n",
       "52   Meteorologist     52      9\n",
       "53              15     53      9\n",
       "54            rate     54      9\n",
       "55          Health     55      9\n",
       "56               -     56      9\n",
       "57        expected     57      9\n",
       "58           David     58      8\n",
       "59            2028     59      8\n",
       "60             and     60      8\n",
       "61          Rachel     61      8\n",
       "62         Michael     62      8\n",
       "63              Q4     63      8\n",
       "64           stock     64      8\n",
       "65            U.S.     65      8\n",
       "66         Johnson     66      7\n",
       "67           price     67      7\n",
       "68           index     68      7\n",
       "69         centers     69      7\n",
       "70           rates     70      7\n",
       "71          Denver     71      7\n",
       "72          energy     72      6\n",
       "73       Renewable     73      6\n",
       "74          sector     74      6\n",
       "75          Sophia     75      6\n",
       "76           Apple     76      6\n",
       "77           Patel     77      6\n",
       "78          Morgan     78      6\n",
       "79         Stanley     79      6\n",
       "80           among     80      6\n",
       "81        American     81      6\n",
       "82         advisor     82      5\n",
       "83        economic     83      5\n",
       "84        Physical     84      5\n",
       "85          growth     85      5\n",
       "86     investments     86      5\n",
       "87         finance     87      5\n",
       "88           Brown     88      5\n",
       "89            wind     89      5\n",
       "90             are     90      5\n",
       "91     temperature     91      5\n",
       "92     Temperature     92      5\n",
       "93           Miami     93      5\n",
       "94        humidity     94      5\n",
       "95           speed     95      5\n",
       "96         Angeles     96      5\n",
       "97             Los     97      5\n",
       "98         analyst     98      5\n",
       "99           Sachs     99      5\n",
       "100     2024/08/21    100      5\n",
       "101           York    101      5\n",
       "102            New    102      5\n",
       "103        Service    103      5\n",
       "104          sugar    104      5\n",
       "105        Goldman    105      5\n",
       "106    consumption    106      5\n",
       "107              1    107      5\n",
       "108     Prevention    108      5\n",
       "109        Disease    109      5\n",
       "110        January    110      5\n",
       "111            S&P    111      5\n",
       "112            500    112      5\n",
       "113       physical    113      5\n",
       "114         Amazon    114      5\n",
       "115    Association    115      5\n",
       "116          Heart    116      5\n",
       "117          urban    117      5\n",
       "118            for    118      5\n",
       "119        obesity    119      5\n",
       "120        Centers    120      5\n",
       "121          Fargo    121      5\n",
       "122   Organization    122      5\n",
       "123          Wells    123      5\n",
       "124          World    124      5\n",
       "125        Control    125      5\n",
       "126   institutions    126      4\n",
       "127        defense    127      4\n",
       "128     allocation    128      4\n",
       "129        Senator    129      4\n",
       "130     moderately    130      4\n",
       "131          trust    131      4\n",
       "132             08    132      4\n",
       "133        expects    133      4\n",
       "134        Chicago    134      4\n",
       "135        schools    135      4\n",
       "136        Channel    136      4\n",
       "137       emerging    137      4\n",
       "138         States    138      4\n",
       "139         United    139      4\n",
       "140          rural    140      4\n",
       "141              3    141      4\n",
       "142     prevalence    142      4\n",
       "143          could    143      4\n",
       "144      awareness    144      4\n",
       "145       national    145      4\n",
       "146      Professor    146      4\n",
       "147          climb    147      4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_vocab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Learning\n",
    "\n",
    "- **Main Idea**: Learn an HMM from the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **HMM Parameters:**\n",
    "\n",
    "  $$ \n",
    "  \n",
    "  Q = q_1 q_2 ... q_N \\text{, a set of N states} \\\\\n",
    "\n",
    "  O = o_1 o_2 ... o_T \\text{, a set of T observations}\\\\ \n",
    "  \n",
    "  $$\n",
    "\n",
    "  ---\n",
    "- **HMM Properties:**\n",
    "\n",
    "  $$\n",
    "\n",
    "  \\text{1. Markov Assumption:} \\\\\n",
    "\n",
    "  \\text{2. Output Independence:}\n",
    "\n",
    "  $$ \n",
    "  ---\n",
    "- **Mapping HMMs to Sequence Labelling:**\n",
    "\n",
    "  $$\n",
    "\n",
    "  q_i : o_i :: t_i : w_i \\\\\n",
    "\n",
    "  t_i, \\text{ tag } \\\\\n",
    "\n",
    "  w_i, \\text{ word} \n",
    "\n",
    "  $$\n",
    "  ---\n",
    "- **HMM Properties: wrt Sequence Labelling:**\n",
    "  $$\n",
    "  \\text{Transition Probability (} t \\text{)}: \\quad t(t_i \\mid t_{i - 1}) = \\frac{\\text{count}(t_{i - 1} \\rightarrow t_i)}{\\text{count}(t_{i - 1})}\n",
    "\n",
    "  \\\\\n",
    "\n",
    "  \\text{Emission Probability (} e \\text{)}: \\quad e(w_i \\mid t_i) = \\frac{\\text{count}(t_i \\rightarrow w_i)}{\\text{count}(t_i)}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "1. [x] Learn a model using the training data in the file train\n",
    "2. [x] Output the learned model into a model file in json format, named `hmm.json`. The model file should contains two dictionaries for the emission and transition parameters, respectively.\n",
    "    1. [x] 1st dictionary: Named transition, contains items with pairs of (s, s′) as key and t(s′|s) as value. \n",
    "    2. [x] 2nd dictionary: Named emission, contains items with pairs of (s, x) as key and e(x|s) as value.\n",
    "3. Question\n",
    "    1. [x] How many transition and emission parameters in your HMM? transition = 1416. emission = 50287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Detravious</td>\n",
       "      <td>B-p_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>I-p_s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Index        Word POS Tag\n",
       "0   0.0               dummy\n",
       "1     0  Detravious   B-p_s\n",
       "2     1           ,   I-p_s"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(df: pd.DataFrame, word_col_name: str, pos_tag_col_name: str, prev_pos_tag_col_name: str):\n",
    "    \"\"\"Count the transition and emission states, respectively\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The df to get the words and POS Tags from\n",
    "\n",
    "    word_col_name: `str`\n",
    "        The name of the word column in the df\n",
    "\n",
    "    pos_tag_col_name: `str`\n",
    "        The name of the POS Tag column in the df\n",
    "        \n",
    "    prev_pos_tag_col_name: `str`\n",
    "        The name of the Previous POS Tag column in the df\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    transition_states (`dict`), emission_state_word (`dict`), N_state (`dict`): `tuple`\n",
    "        A tuple with the counts for transition previous state and current state,\n",
    "        emission state and word, and total number of states\n",
    "    \n",
    "    \"\"\"\n",
    "    transition_states = defaultdict(int)\n",
    "    emission_state_word = defaultdict(int)\n",
    "    N_state = defaultdict(int)\n",
    "    \n",
    "    df[prev_pos_tag_col_name] = df[pos_tag_col_name].shift(1) # create new col to store previous states\n",
    "\n",
    "    vocabulary = df.iterrows()\n",
    "    # iterate through vocabulary\n",
    "    for _, row in tqdm(vocabulary, total=df.shape[0]):\n",
    "\n",
    "        emission_state_word[(row[pos_tag_col_name], row[word_col_name])] += 1 # get emissions count at POS Tag col and Word col\n",
    "        # transition count + 1\n",
    "        if pd.notnull(row[prev_pos_tag_col_name]):  # Check if it's not NaN\n",
    "            transition_states[(row[prev_pos_tag_col_name], row[pos_tag_col_name])] += 1 # get transition count at Previous POS Tag col and POS Tag col\n",
    "\n",
    "        \n",
    "        N_state[(row[pos_tag_col_name])] += 1 # increment POS Tag to get total number of states (POS Tags)\n",
    "\n",
    "    return transition_states, emission_state_word, N_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2504/2504 [00:00<00:00, 89997.58it/s]\n"
     ]
    }
   ],
   "source": [
    "word_col_name = \"Word\"\n",
    "pos_tag_col_name = \"POS Tag\"\n",
    "prev_pos_tag_col_name = 'Previous_POS Tag'\n",
    "transitions, emissions, N_states = get_counts(updated_train_df, word_col_name, pos_tag_col_name, prev_pos_tag_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Transition params = 37 \n",
      "# Emissions params = 443\n"
     ]
    }
   ],
   "source": [
    "print(f\"# Transition params = {len(transitions.items())} \\n# Emissions params = {len(emissions.items())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prob(transitions: dict, emissions: dict, N_states: dict, prob_type: str):   \n",
    "    \"\"\"Calculate the transistion and emissions probabilities, respectively\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transitions: `dict`\n",
    "        Counts for transition previous state and current state as key and value as total number (or counts) of pairs\n",
    "        \n",
    "    emissions: `dict`\n",
    "        Counts for emission state and word as key and value as total number (or counts) of pairs\n",
    "\n",
    "    N_states: `dict`\n",
    "        Counts of state (POS Tag) as key and value as total number (or counts) of states\n",
    "\n",
    "    prob_type: `str`\n",
    "        A string representing either transistion or emissions\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    store_probs: `dict`\n",
    "        A dictionary containing the probabilities of transitions and emissions, respectively. Key are pairings and values are probability, respectively\n",
    "    \"\"\"\n",
    "\n",
    "    if prob_type == \"t\":\n",
    "        t_or_e = transitions\n",
    "    elif prob_type == \"e\":\n",
    "        t_or_e = emissions\n",
    "    else:\n",
    "        print(f\"Invalid prob_type {prob_type}\")\n",
    "\n",
    "    store_probs = {}\n",
    "    for key, value in t_or_e.items():\n",
    "        \n",
    "        curr_state = key[0]       \n",
    "        store_probs[key] = value / N_states[curr_state]\n",
    "        \n",
    "    return store_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_probs = calculate_prob(transitions, emissions, N_states, 't')\n",
    "e_probs = calculate_prob(transitions, emissions, N_states, 'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(t_probs.items())[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(e_probs.items())[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save HMM Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hmm = \"final_submit/hmm.json\"\n",
    "\n",
    "combine_t_and_e_probs = {}\n",
    "combine_t_and_e_probs[\"transitions\"] = t_probs\n",
    "combine_t_and_e_probs[\"emissions\"] = e_probs\n",
    "\n",
    "t_e_probs_df = pd.DataFrame(combine_t_and_e_probs)\n",
    "# t_e_probs_df.to_json(save_hmm) # save\n",
    "t_e_probs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Decoding Techniques:**\n",
    "    1. Greedy [find the optimal (OPT) solution at each step]\n",
    "    2. Viterbi [make use of dynammic programming to find the OPT solution with backtracking while searching the entire search space]\n",
    "4. **Notes of the data and given files:**\n",
    "    - Dataset: Wall Street Journal section of the Penn Treebank\n",
    "    - Folder named `data` with the following files:\n",
    "        1. `train`, sentences *with* human-annotated POS Tags\n",
    "        2. `dev`, sentences *with* human-annotated POS Tags\n",
    "        3. `test`, sentences *without* POS Tags, thus predict the POS Tags\n",
    "    - Format: Blank like at the end of each sentence. Each line contains 3 items separated by the `\\t`, the tab symbol. These three items are\n",
    "        1. Index of the word in the sentence\n",
    "        2. Word type\n",
    "        3. POS Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Greedy Decoding with HMM\n",
    "\n",
    "1. [x] Implement the greedy decoding algorithm\n",
    "2. [x] Evaluate it on the development data\n",
    "3. [x] Predicting the POS Tags of the sentences in the test data\n",
    "4. [x] Output the predictions in a file named `greedy.out`, in the same format of training data\n",
    "5. [x] Evaluate the results of the model on `eval.py` in the terminal with `python eval.py − p {predicted file} − g {gold-standard file}`\n",
    "    - Spefically: `python eval.py -p final_submit/greedy.out -g data/dev`\n",
    "6. [x] Question\n",
    "    1. [x] What is the accuracy on the dev data? 80.99%. Possibly need to properly clean data, improve Parts 1 and 2, and include more training data to improve accuracy. I didn’t replace any words based on a certain threshold because I thought it was only for part 1. Some pairs (of both transition and emission, respectively) weren’t found, so I used a low number instead such that we don’t pick that pair. I also need to learn how to write correct and efficient code. Seeing your solution to this HW and previous HWs will help as I struggled on all HWs thus far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated_dev_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decoding(dev_df: pd.DataFrame, t_probs: dict, e_probs: dict, N_pos_tags: np.array):\n",
    "    \"\"\"Implement greedy decoding on the development file (words only) using the transition probability and emission probability. Furthermore, don't use POS Tag of development file, thus only use POS Tag from training data.\n",
    "\n",
    "    If 't_' or 'e_', transition and emission probabilities, respectively.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        Dev file\n",
    "\n",
    "    t_probs: `py dict`\n",
    "        Tranision probabilities for POS Tag given previous POS Tag\n",
    "\n",
    "    e_probs: `py dict`\n",
    "        Emission probabilities for Word given POS Tags\n",
    "\n",
    "    N_pos_tags: `np.array`\n",
    "        All POS Tags found in the training file\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    all_words_with_pos_tag: `list` \n",
    "        Store the words with highest probability POS Tag for that word as a tuple\n",
    "    \"\"\"\n",
    "\n",
    "    previous_pos_tag = \"dummy\"\n",
    "    not_found_value = 0.000000001\n",
    "    all_words_with_pos_tag = []\n",
    "\n",
    "    # Go through each row (word), get the corresponding POS Tag to calculate probabilities    \n",
    "    for index, row in tqdm(dev_df.iterrows(), total=dev_df.shape[0]):\n",
    "        # print(\"index\", index, \"with word\", row['Word'])\n",
    "\n",
    "        if row['POS Tag'] != \"dummy\": # check if POS Tag is dummy so we know where each new sentence starts\n",
    "\n",
    "            # For current word, store score from greedy calculatons. Empty when new word is encountered\n",
    "            store_scores = []\n",
    "            \n",
    "            for N_pos_tags_idx in range(len(N_pos_tags)):\n",
    "                current_pos_tag = N_pos_tags[N_pos_tags_idx]\n",
    "    \n",
    "                \"\"\"Transition Probability\n",
    "                    t(t_find_pos_tag | t_given_pos_tag)\n",
    "                \"\"\"\n",
    "                t_find_pos_tag = current_pos_tag\n",
    "                t_given_pos_tag = previous_pos_tag\n",
    "                \n",
    "                \"\"\"Emission Probability\n",
    "                    e(e_word | e_given_pos_tag)\n",
    "                \"\"\"\n",
    "                e_word = row['Word']\n",
    "                e_given_pos_tag = current_pos_tag\n",
    "                \n",
    "                \"\"\"Transition * Emission\"\"\"\n",
    "                t_key = (t_find_pos_tag, t_given_pos_tag)\n",
    "                e_key = (e_given_pos_tag, e_word)\n",
    "    \n",
    "                # IF-ELSE bc not all pairs will be found. If pair is found, use score, otherwise (pair isn't found) set alternative score\n",
    "                if t_key in t_probs and e_key in e_probs:\n",
    "                    t = t_probs[t_key]\n",
    "                    e = e_probs[e_key]\n",
    "                    score = t * e\n",
    "                    # print(f\"---  t({t_find_pos_tag} | {t_given_pos_tag}) * e({e_word} | {e_given_pos_tag}) = {score}\")\n",
    "                    \n",
    "                else:\n",
    "                    t = not_found_value\n",
    "                    e = not_found_value\n",
    "                    score = t * e\n",
    "                    # print(f\"--- t({t_find_pos_tag} | {t_given_pos_tag}) * e({e_word} | {e_given_pos_tag}) = {score}\")\n",
    "                            \n",
    "                store_scores.append(score)\n",
    "        \n",
    "            max_score_idx = np.argmax(np.array(store_scores)) # use argmax to get the index of max score\n",
    "            current_pos_tag = N_pos_tags[max_score_idx] # use the index of the max score to find which POS Tag to \n",
    "            all_words_with_pos_tag.append([row['Word'], current_pos_tag]) # store word and POS Tag with max score\n",
    "            previous_pos_tag = current_pos_tag # update the previous POS Tag\n",
    "        else:\n",
    "            empty = \"\" # formatting final 2D list\n",
    "            all_words_with_pos_tag.append([empty, empty]) # Adds extra space in final 2D list\n",
    "        \n",
    "    return all_words_with_pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_output = greedy_decoding(updated_dev_df, t_probs, e_probs, all_pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_output = gd_output[1:] # remove intial empty list\n",
    "gd_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Greedy Decoding Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('final_submit/greedy.out', 'w') as op:\n",
    "    \n",
    "#     index = 1\n",
    "#     for idx, word in enumerate(gd_output):\n",
    "#         if word[0] == \"\":\n",
    "#             index = 1\n",
    "#             op.write(\"\\n\")\n",
    "#         else:\n",
    "#             op.write(f'{index}\\t{word[0]}\\t{word[1]}')\n",
    "#             op.write(\"\\n\")\n",
    "#             index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Viterbi Decoding with HMM\n",
    "\n",
    "1. [x] Implement the viterbi decoding algorithm\n",
    "2. [x] Evaluate it on the development data\n",
    "3. [x] Predict the POS Tags of the sentences in the test data\n",
    "4. [x] Output the predictions in a file named `viterbi.out`, in the same format of training data\n",
    "    - Specifically, `python eval.py -p final_submit/viterbi.out -g data/dev`\n",
    "5. [x] Question\n",
    "    1. [x] What is the accuracy on the dev data? 85.27%. Possibly need to properly clean data, improve Parts 1 and 2, and include more training data to improve accuracy. I didn’t replace any words based on a certain threshold because I thought it was only for part 1. Some pairs (of both transition and emission, respectively) weren’t found, so I used a low number instead such that we don’t pick that pair. I also need to learn how to write correct and efficient code. Seeing your solution to this HW and previous HWs will help as I struggled on all HWs thus far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat dev df so Viterbi will be more optimized compared to if dev df was a DF\n",
    "def dataframe_to_list(df: pd.DataFrame):\n",
    "    \"\"\"Convert a DF to a list of lists\"\"\"\n",
    "    list_of_sentences = []\n",
    "    sublist = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        if row['POS Tag'] == 'dummy': # dummy POS Tag indicates a new sentence\n",
    "            list_of_sentences.append(sublist)\n",
    "            sublist = []\n",
    "        else:\n",
    "            sublist.append(row['Word'])\n",
    "            \n",
    "    # Append the last sublist\n",
    "    if sublist:\n",
    "        list_of_sentences.append(sublist)\n",
    "        \n",
    "    return list_of_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = dataframe_to_list(updated_dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decoding(sentences: list, t_probs: dict, e_probs: dict, pos_tags: np.array):\n",
    "    \"\"\"Implement Viterbi decoding on the development file (words only) using the transition probability and emission probability. \n",
    "    \n",
    "    Parameters\n",
    "    ----------        \n",
    "    sentences: `list`\n",
    "        List of sentences from dev file\n",
    "\n",
    "    t_probs: `py dict`\n",
    "        Tranision probabilities for POS Tag given previous POS Tag\n",
    "\n",
    "    e_probs: `py dict`\n",
    "        Emission probabilities for Word given POS Tags\n",
    "\n",
    "    pos_tags: `np.array`\n",
    "        All POS Tags found in the training file\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    all_words_with_pos_tag: `list` \n",
    "        Store the words with highest probability POS Tag for that word as a tuple\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"Clarifications of variables\n",
    "        - If 't_' or 'e_', transition and emission probabilities, respectively.\n",
    "        - If `v_pi`, viterbi_pi (from slide deck as it had the pi symbol)\"\"\"\n",
    "    \"\"\"\n",
    "    Initialization with base cases\n",
    "        - For the first word of every new sentence, create a base case\n",
    "    \"\"\"\n",
    "    \n",
    "    initial_pos_tag = \"dummy\"\n",
    "    not_found_value = 0.000001\n",
    "    all_words_with_pos_tag = []\n",
    "    \n",
    "    for sentences_idx in range(len(sentences)):\n",
    "        sentence = sentences[sentences_idx]\n",
    "        # print(f\"Sentence --- {sentence}\")\n",
    "\n",
    "        store_initial_scores = []\n",
    "\n",
    "        len_of_sentence = len(sentence)\n",
    "        N_pos_tags = len(pos_tags)\n",
    "        \n",
    "        v_pi = np.zeros((N_pos_tags, len_of_sentence)) # 2D matrix (or table) containing all POS tags and length of each specific sentence\n",
    "\n",
    "        for pos_tags_idx in range(N_pos_tags):\n",
    "            initial_t_given_pos_tag = initial_pos_tag\n",
    "            initial_t_find_pos_tag = pos_tags[pos_tags_idx]\n",
    "            initial_t_key = (initial_t_find_pos_tag, initial_t_given_pos_tag)\n",
    "            \n",
    "            initial_e_given_pos_tag = pos_tags[pos_tags_idx]\n",
    "            initial_e_word = sentence[0]\n",
    "            initial_e_key = (initial_e_given_pos_tag, initial_e_word)\n",
    "            \n",
    "            # Check if the keys for t_prob and e_prob are valid, respectively. If not, assign alternate score\n",
    "            if initial_t_key in t_probs and initial_e_key in e_probs:\n",
    "                v_pi[pos_tags_idx, 0] = t_probs[initial_t_key] * e_probs[initial_e_key]\n",
    "            else: \n",
    "                v_pi[pos_tags_idx, 0] = not_found_value\n",
    "        \n",
    "            store_initial_scores.append(v_pi[pos_tags_idx, 0])        \n",
    "        all_words_with_pos_tag.append([initial_e_word, pos_tags[pos_tags_idx]])\n",
    "\n",
    "\n",
    "        \"\"\"DP Algo\n",
    "            - End base case at first word this sentence\n",
    "            - For the remaining words in this sentence, find the best combo of word and POS Tag\n",
    "        \"\"\"\n",
    "        previous_word_idx = 0\n",
    "        \n",
    "        for word_idx in range(1, len_of_sentence):\n",
    "            e_word = sentence[word_idx]\n",
    "\n",
    "            word_with_best_pos_tags = []\n",
    "            \n",
    "            for pos_tags_idx in range(N_pos_tags):\n",
    "                current_pos_tag = pos_tags[pos_tags_idx]\n",
    "                \n",
    "                store_scores = []\n",
    "                \n",
    "                for previous_pos_tags_idx in range(N_pos_tags):\n",
    "                    previous_pos_tag = pos_tags[previous_pos_tags_idx]\n",
    "                    \n",
    "                    v_pi_idx = (previous_pos_tags_idx, previous_word_idx)\n",
    "                    \"\"\"Transition Probability\n",
    "                        t(t_find_pos_tag | t_given_pos_tag)\n",
    "                    \"\"\"\n",
    "                    t_find_pos_tag = current_pos_tag\n",
    "                    t_given_pos_tag = previous_pos_tag\n",
    "                    \n",
    "                    \n",
    "                    \"\"\"Emission Probability\n",
    "                        e(e_word | e_given_pos_tag)\n",
    "                    \"\"\"\n",
    "                    # e_word is above\n",
    "                    e_given_pos_tag = current_pos_tag \n",
    "                    \n",
    "                    \"\"\"Transition * Emission\"\"\"\n",
    "                    t_key = (t_find_pos_tag, t_given_pos_tag)\n",
    "                    e_key = (e_given_pos_tag, e_word)\n",
    "                    \n",
    "                    # IF-ELSE bc not all pairs will be found. If pair is found, use score, otherwise (pair isn't found) set alternative score\n",
    "                    if t_key in t_probs and e_key in e_probs:\n",
    "                        t = t_probs[t_key]\n",
    "                        e = e_probs[e_key]\n",
    "                        score = v_pi[v_pi_idx] * t * e\n",
    "                        # print(f\"--- FOUND: v_pi[{t_find_pos_tag}, {e_word}] = v_pi[{previous_pos_tag}, {previous_word}] * t({t_find_pos_tag} | {t_given_pos_tag}) * e({e_word} | {e_given_pos_tag}) = {score}\")\n",
    "\n",
    "                    else:\n",
    "                        t = not_found_value\n",
    "                        e = not_found_value\n",
    "                        score = v_pi[v_pi_idx] * t * e\n",
    "                        # print(f\"--- NOT FOUND: v_pi[{t_find_pos_tag}, {e_word}] = v_pi[{previous_pos_tag}, {previous_word}] * t({t_find_pos_tag} | {t_given_pos_tag}) * e({e_word} | {e_given_pos_tag}) = {score}\")\n",
    "\n",
    "                    store_scores.append(score)\n",
    "\n",
    "                max_score_idx = np.argmax(np.array(store_scores)) # use argmax to get the index of max score\n",
    "                current_pos_tag = pos_tags[max_score_idx] # use the index of the max score to find which POS Tag to update to\n",
    "                word_with_best_pos_tags.append(store_scores[max_score_idx]) # store max score \n",
    "            \n",
    "            max_score_of_word_idx = np.argmax(np.array(word_with_best_pos_tags))\n",
    "            all_words_with_pos_tag.append([e_word, pos_tags[max_score_of_word_idx]])\n",
    "            \n",
    "        empty = \"\" # formatting final 2D list\n",
    "        all_words_with_pos_tag.append([empty, empty]) # Adds extra space in final 2D list\n",
    "\n",
    "    return all_words_with_pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore first sentence as it's empty\n",
    "# ignore first tag as it's \"dummmy\"\n",
    "vd_output = viterbi_decoding(sentences[1:], t_probs, e_probs, all_pos_tags[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Viterbi Decoding Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_submit/viterbi.out', 'w') as op:\n",
    "    # # # # # # # \n",
    "    index = 1\n",
    "    for idx, word in enumerate(vd_output):\n",
    "        if word[0] == \"\":\n",
    "            index = 1\n",
    "            op.write(\"\\n\")\n",
    "        else:\n",
    "            op.write(f'{index}\\t{word[0]}\\t{word[1]}')\n",
    "            op.write(\"\\n\")\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc\n",
    "\n",
    "- Learn an HMM from the training data\n",
    "\n",
    "- **HMM Parameters:**\n",
    "  $$ \n",
    "  Q = q_1 q_2 ... q_N \\\\\n",
    "  A = a_{11} ... a_{ij} ... a_{NN}, \\text{transition probability matrix } A \\\\\n",
    "    \\text{- probability of moving from state i to state j, s.t.} \\sum_{j = 1}^N a_{ij} = 1 \\forall i \\\\\n",
    "  B = b_i(o_t), \\text{emission probability} \\\\\n",
    "    \\text{- each expressing the probability of an observation } o_t (\\text{drawn from a vocabulary } V = v_1, v_2, ..., v_V) \\\\ \\text{being generated from a state } q_i \\\\\n",
    "\n",
    "\n",
    "  \\text{Transition Probability (} t \\text{)}: \\quad t(s' \\mid s) = \\frac{\\text{count}(s \\rightarrow s')}{\\text{count}(s)}\n",
    "\n",
    "  \\\\\n",
    "\n",
    "  \\text{Emission Probability (} e \\text{)}: \\quad e(x \\mid s) = \\frac{\\text{count}(s \\rightarrow x)}{\\text{count}(s)}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "1. [x] Learn a model using the training data in the file train\n",
    "2. [x] Output the learned model into a model file in json format, named `hmm.json`. The model file should contains two dictionaries for the emission and transition parameters, respectively.\n",
    "    1. [x] 1st dictionary: Named transition, contains items with pairs of (s, s′) as key and t(s′|s) as value. \n",
    "    2. [x] 2nd dictionary: Named emission, contains items with pairs of (s, x) as key and e(x|s) as value.\n",
    "3. Question\n",
    "    1. [x] How many transition and emission parameters in your HMM? transition = 1416. emission = 50287\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_predictions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
