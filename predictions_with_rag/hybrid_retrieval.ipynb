{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2690733",
   "metadata": {},
   "source": [
    "# Tutorial: Creating a Hybrid Retrieval Pipeline\n",
    "\n",
    "- **Level**: Intermediate\n",
    "- **Time to complete**: 15 minutes\n",
    "- **Components Used**: [`DocumentSplitter`](https://docs.haystack.deepset.ai/docs/documentsplitter), [`SentenceTransformersDocumentEmbedder`](https://docs.haystack.deepset.ai/docs/sentencetransformersdocumentembedder), [`DocumentJoiner`](https://docs.haystack.deepset.ai/docs/documentjoiner), [`InMemoryDocumentStore`](https://docs.haystack.deepset.ai/docs/inmemorydocumentstore), [`InMemoryBM25Retriever`](https://docs.haystack.deepset.ai/docs/inmemorybm25retriever), [`InMemoryEmbeddingRetriever`](https://docs.haystack.deepset.ai/docs/inmemoryembeddingretriever), and [`TransformersSimilarityRanker`](https://docs.haystack.deepset.ai/docs/transformerssimilarityranker)\n",
    "- **Prerequisites**: None\n",
    "- **Goal**: After completing this tutorial, you will have learned about creating a hybrid retrieval and when it's useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aeb4f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from haystack import Document\n",
    "from haystack import Pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.rankers import TransformersSimilarityRanker\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.preprocessors.document_splitter import DocumentSplitter\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever, InMemoryEmbeddingRetriever\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.join(notebook_dir, '../'))\n",
    "\n",
    "# import log_files\n",
    "from data_processing import DataProcessing\n",
    "from prediction_properties import PredictionProperties\n",
    "from text_generation_models import TextGenerationModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10be77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 800)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83349efc",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "- **Problems:**\n",
    "    1. Multiple files with distinct retrieved results\n",
    "    2. Same file where we duplicate retrieved results. Duplicate as in first run: 0 to 7, second run 7 to 14, but it includes 0 to 7, so file would be 0 to 7, 0 to 7, then 7 to 14.\n",
    "\n",
    "- `new_file = True:` Only when it's the first usage. Load the original dataset named as `all_data-adjusted_header.csv`.\n",
    "- `new_file = False:` Only when it's after the first usage. Reasoning is: the next step of LLM labeling (prediction/non-prediction) will use this saved file and store results in same file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "138b7b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentiment', 'sentence'],\n",
       "    num_rows: 4846\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_file = True\n",
    "base_data_path = os.path.join(notebook_dir, '../data/')\n",
    "phrase_bank_data_path = os.path.join(base_data_path, 'financial_phrase_bank/')\n",
    "hybrid_retrieval_results_path = os.path.join(base_data_path, 'hybrid_retrieval/')\n",
    "if new_file == True: \n",
    "    new_file_name = \"all_data-adjusted_header.csv\"\n",
    "    financial_full_path = os.path.join(phrase_bank_data_path, new_file_name)\n",
    "    dataset = load_dataset(\"csv\", data_files=financial_full_path, split=\"train\")\n",
    "\n",
    "else:\n",
    "    new_file_name = \"text_label_name_meta_data-v1.csv\"\n",
    "    financial_full_path = os.path.join(hybrid_retrieval_results_path, new_file_name)\n",
    "    dataset = load_dataset(\"csv\", data_files=financial_full_path, split=\"train\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a467a7fe",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "**Hybrid Retrieval** combines keyword-based and embedding-based retrieval techniques, leveraging the strengths of both approaches. In essence, dense embeddings excel in grasping the contextual nuances of the query, while keyword-based methods excel in matching keywords.\n",
    "\n",
    "There are many cases when a simple keyword-based approaches like BM25 performs better than a dense retrieval (for example in a specific domain like healthcare) because a dense model needs to be trained on data. For more details about Hybrid Retrieval, check out [Blog Post: Hybrid Document Retrieval](https://haystack.deepset.ai/blog/hybrid-retrieval)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c9350",
   "metadata": {},
   "source": [
    "## Fetching and Processing Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6aa4a4",
   "metadata": {},
   "source": [
    "For searching, use the *sentence* feature (column). The other features (columns) will be stored as metadata for [metadata filtering](https://docs.haystack.deepset.ai/docs/metadata-filtering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5087f8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id=63461e5f36b506ade08357e3bdb34e98c8ba387ec40e2d27f0b651cdc0416edf, content: 'According to Gran , the company has no plans to move all production to Russia , although that is whe...', meta: {'sentiment': 'neutral'}),\n",
       " Document(id=99e7dc0575e03709f270d73b2dd4f9b878b6e2b998cdc488afb27daad6fb44a2, content: 'Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to hos...', meta: {'sentiment': 'neutral'}),\n",
       " Document(id=a733e18a009c0cdef1ee85366b3506eb3f869588c69b0c4d604021aa6d34a1df, content: 'The international electronic industry company Elcoteq has laid off tens of employees from its Tallin...', meta: {'sentiment': 'negative'}),\n",
       " Document(id=39e2ff2d164bed02386d1da93730042991b977cb8b62db9d4786722a19a10695, content: 'With the new production plant the company would increase its capacity to meet the expected increase ...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=1f38a8a49050433e5fabd819b0bc84b4944a4f683c6797d3fe98a0feeb0c8146, content: 'According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term n...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=2c106b768ca3455523070e94cfcdbc9e145ca808ae79f54e5d2f7c56e21ab280, content: 'FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is aggressively pursuing its growth strategy by increasingl...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=852ab50b47d2e32fda355f76e6f1c81a29e0501c423710922ac67f559ec09ad4, content: 'For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same p...', meta: {'sentiment': 'positive'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = []\n",
    "\n",
    "for doc in dataset:\n",
    "    docs.append(\n",
    "        Document(content=doc[\"sentence\"], meta={\"sentiment\": doc[\"sentiment\"]})\n",
    "    )\n",
    "docs = docs[:7]\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea9968",
   "metadata": {},
   "source": [
    "## Indexing Documents with a Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be4e24",
   "metadata": {},
   "source": [
    "Create a pipeline to store the data in the document store with their embedding. For this pipeline, you need\n",
    "\n",
    "1. [DocumentSplitter](https://docs.haystack.deepset.ai/docs/documentsplitter) to split documents into chunks of 512 words.\n",
    "    - Why by `split_by` word?\n",
    "    - Why `split_length` 512?\n",
    "    - Why `split_overlap` is 32?\n",
    "\n",
    "2. Dense Models are [SentenceTransformersDocumentEmbedder](https://docs.haystack.deepset.ai/docs/sentencetransformersdocumentembedder) to create document embeddings for dense retrieval, where `sentence-transformers/all-mpnet-base-v2` is the default embedding model. Specify another model with the model parameter when initializing this component. For ex, can use [BAAI/bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5) on Hugging Face. \n",
    "\n",
    "    > If this step takes too long for you, replace the embedding model with a smaller model such as the base model or `sentence-transformers/all-MiniLM-L6-v2`. Make sure that the `split_length` is updated according to your model's token limit.  \n",
    "\n",
    "3. You'll start creating your question answering system by initializing a DocumentStore. A DocumentStore stores the Documents that your system uses to find answers to your questions. In this tutorial, you'll be using the [`InMemoryDocumentStore`](https://docs.haystack.deepset.ai/docs/inmemorydocumentstore). `InMemoryDocumentStore` is the simplest DocumentStore to get started with. It requires no external dependencies and it's a good option for smaller projects and debugging. But it doesn't scale up so well to larger Document collections, so it's not a good choice for production systems. To learn more about the different types of external databases that Haystack supports, see [DocumentStore Integrations](https://haystack.deepset.ai/integrations?type=Document+Store&version=2.0). \n",
    "\n",
    "3. Write documents to the document store with [DocumentWriter](https://docs.haystack.deepset.ai/docs/documentwriter). Test other models on Hugging Face or use another [Embedder](https://docs.haystack.deepset.ai/docs/embedders) to switch the model provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb2a67e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcf90b586af45848b53f279a30e2f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'document_writer': {'documents_written': 7}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_splitter = DocumentSplitter(split_by=\"word\", split_length=512, split_overlap=32)\n",
    "document_embedder = SentenceTransformersDocumentEmbedder(\n",
    "    model=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "document_writer = DocumentWriter(document_store)\n",
    "\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_component(\"document_splitter\", document_splitter) # sentences/documents alone\n",
    "indexing_pipeline.add_component(\"document_embedder\", document_embedder) # embeddings per document\n",
    "indexing_pipeline.add_component(\"document_writer\", document_writer) # documents -> vector store\n",
    "\n",
    "indexing_pipeline.connect(\"document_splitter\", \"document_embedder\") # map documents : embeddings\n",
    "indexing_pipeline.connect(\"document_embedder\", \"document_writer\") # embeddings : vector store\n",
    "\n",
    "indexing_pipeline.run({\"document_splitter\": {\"documents\": docs}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8530902",
   "metadata": {},
   "source": [
    "Documents are stored in `InMemoryDocumentStore` with their embeddings, now it's time for creating the hybrid retrieval pipeline âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536a0a3f",
   "metadata": {},
   "source": [
    "## Creating a Pipeline for Hybrid Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc915e",
   "metadata": {},
   "source": [
    "Hybrid retrieval refers to the combination of multiple retrieval methods to enhance overall performance. In the context of search systems, a hybrid retrieval pipeline executes both traditional keyword-based search and dense vector search, later ranking the results with a **cross-encoder model**. This combination allows the search system to leverage the strengths of different approaches, providing more accurate and diverse results.\n",
    "\n",
    "Here are the required steps for a hybrid retrieval pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7e6c50",
   "metadata": {},
   "source": [
    "### 1) Initialize Retrievers and the Embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74efe42",
   "metadata": {},
   "source": [
    "1. Keyword-based retrieval (sparse): [InMemoryBM25Retriever](https://docs.haystack.deepset.ai/docs/inmemorybm25retriever)\n",
    "2. Embeddings retrieval (dense): [InMemoryEmbeddingRetriever](https://docs.haystack.deepset.ai/docs/inmemoryembeddingretriever)\n",
    "    > For dense retrieval, you also need a [SentenceTransformersTextEmbedder](https://docs.haystack.deepset.ai/docs/sentencetransformerstextembedder) that computes the embedding of the search query by using the same embedding model `BAAI/bge-small-en-v1.5` that was used in the indexing pipeline as the document embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a697cfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.components.retrievers.in_memory.bm25_retriever.InMemoryBM25Retriever object at 0x347cf0e50>\n",
       "Inputs:\n",
       "  - query: str\n",
       "  - filters: Optional[dict[str, Any]]\n",
       "  - top_k: Optional[int]\n",
       "  - scale_score: Optional[bool]\n",
       "Outputs:\n",
       "  - documents: list[Document]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_retrieval = Pipeline()\n",
    "bm25_retriever = InMemoryBM25Retriever(document_store)\n",
    "bm25_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ad88833",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retrieval.add_component(\"bm25_retriever\", bm25_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d93a7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.components.retrievers.in_memory.embedding_retriever.InMemoryEmbeddingRetriever object at 0x3487e8f50>\n",
       "Inputs:\n",
       "  - query_embedding: list[float]\n",
       "  - filters: Optional[dict[str, Any]]\n",
       "  - top_k: Optional[int]\n",
       "  - scale_score: Optional[bool]\n",
       "  - return_embedding: Optional[bool]\n",
       "Outputs:\n",
       "  - documents: list[Document]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embedder = SentenceTransformersTextEmbedder(\n",
    "    model=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "embedding_retriever = InMemoryEmbeddingRetriever(document_store)\n",
    "embedding_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a58768",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retrieval.add_component(\"text_embedder\", text_embedder)\n",
    "hybrid_retrieval.add_component(\"embedding_retriever\", embedding_retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1377db",
   "metadata": {},
   "source": [
    "### 2) Join + Rank Retrieval Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5936c29a",
   "metadata": {},
   "source": [
    "1. **Join:** Haystack offers several joining methods in [`DocumentJoiner`](https://docs.haystack.deepset.ai/docs/documentjoiner) to be used for different use cases such as `merge` and `reciprocal_rank_fusion`. In this example, you will use the default `concatenate` mode to join the documents coming from two Retrievers as the [Ranker](https://docs.haystack.deepset.ai/docs/rankers) will be the main component to rank the documents for relevancy.\n",
    "\n",
    "2. **Rank:** Use the [TransformersSimilarityRanker](https://docs.haystack.deepset.ai/docs/transformerssimilarityranker) that scores the relevancy of all retrieved documents for the given search query by using a cross encoder model. In this example, you will use [BAAI/bge-reranker-base](https://huggingface.co/BAAI/bge-reranker-base) model to rank the retrieved documents but you can replace this model with other cross-encoder models on Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d73252b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TransformersSimilarityRanker is considered legacy and will no longer receive updates. It may be deprecated in a future release, with removal following after a deprecation period. Consider using SentenceTransformersSimilarityRanker instead, which provides the same functionality along with additional features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<haystack.components.joiners.document_joiner.DocumentJoiner object at 0x348787dd0>\n",
       " Inputs:\n",
       "   - documents: list[Document]\n",
       "   - top_k: Optional[int]\n",
       " Outputs:\n",
       "   - documents: list[Document],\n",
       " <haystack.components.rankers.transformers_similarity.TransformersSimilarityRanker object at 0x34841d1d0>\n",
       " Inputs:\n",
       "   - query: str\n",
       "   - documents: list[Document]\n",
       "   - top_k: Optional[int]\n",
       "   - scale_score: Optional[bool]\n",
       "   - calibration_factor: Optional[float]\n",
       "   - score_threshold: Optional[float]\n",
       " Outputs:\n",
       "   - documents: list[Document])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_joiner = DocumentJoiner()\n",
    "ranker = TransformersSimilarityRanker(model=\"BAAI/bge-reranker-base\")\n",
    "document_joiner, ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5553d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retrieval.add_component(\"document_joiner\", document_joiner)\n",
    "hybrid_retrieval.add_component(\"ranker\", ranker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7002e2",
   "metadata": {},
   "source": [
    "### 4) Connect the Hybrid Retrieval Components to Hybrid Pipeline\n",
    "\n",
    "Add all initialized components to your pipeline and connect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d05b634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x347cc6990>\n",
       "ðŸš… Components\n",
       "  - bm25_retriever: InMemoryBM25Retriever\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - embedding_retriever: InMemoryEmbeddingRetriever\n",
       "  - document_joiner: DocumentJoiner\n",
       "  - ranker: TransformersSimilarityRanker\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - bm25_retriever.documents -> document_joiner.documents (list[Document])\n",
       "  - text_embedder.embedding -> embedding_retriever.query_embedding (list[float])\n",
       "  - embedding_retriever.documents -> document_joiner.documents (list[Document])\n",
       "  - document_joiner.documents -> ranker.documents (list[Document])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_retrieval.connect(\"text_embedder\", \"embedding_retriever\")\n",
    "hybrid_retrieval.connect(\"bm25_retriever\", \"document_joiner\")\n",
    "hybrid_retrieval.connect(\"embedding_retriever\", \"document_joiner\")\n",
    "hybrid_retrieval.connect(\"document_joiner\", \"ranker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f5f6ac",
   "metadata": {},
   "source": [
    "### 5) Visualize the Pipeline (Optional)\n",
    "\n",
    "To understand how you formed a hybrid retrieval pipeline, use [draw()](https://docs.haystack.deepset.ai/docs/drawing-pipeline-graphs) method of the pipeline. If you're running this notebook on Google Colab, the generate file will be saved in \"Files\" section on the sidebar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dff346f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_img_name = \"hybrid-retrieval.png\"\n",
    "# save_image_path = os.path.join(notebook_dir, \"../data/hybrid_retrieval/\", save_img_name)\n",
    "# hybrid_retrieval.draw(path=save_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd7e4d",
   "metadata": {},
   "source": [
    "## Create Prompt + Test the Hybrid Retrieval\n",
    "\n",
    "Pass the query to `bm25_retriever`, `text_embedder`, and `ranker` and run the retrieval pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48078227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DataProcessing class if we want to load all prediction property steps at once\n",
    "# prediction_properties = DataProcessing.load_prediction_properties()\n",
    "# prediction_properties\n",
    "\n",
    "prediction_properties = PredictionProperties.get_prediction_properties()\n",
    "prediction_requirements = PredictionProperties.get_requirements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da592f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction <p> = (<p_s>, <p_t>, <p_d>, <p_o>), where it consists of the following four properties:\\n\\n        1. <p_s>\\n            - Defined as: \\n                - Source entity that states the <p>\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n                3. A person with a gender only: He\\n                4. A person with a domain specific title: reporter, analyst, expert, top executive, senior level person, etc \\n                5. A person with a combination: Detravious, a reporter\\n                6. An associated organization: FitTo...\\n                7. A combination of person with associated organization: Detravious, a reporter at FitTo...\\n\\n        2. <p_t>\\n            - Defined as: \\n                - Target entity that the <p> is about\\n            - Characteristics:\\n                - Same and <p_s>\\n            - Examples:\\n                1. A person with a name only: Jakalia\\n                2. A person with a profile name: FitToCode\\n                3. A person with a gender only: She\\n                4. A person with a domain specific title: reporter, analyst, expert, top executive, senior level person, etc \\n                5. A person with a combination: Jamari, a senior level person\\n                6. An associated organization: Roeh Labs\\n                7. A combination of person with associated organization: A senior level person at Roeh Labs named Jamari\\n\\n        3. <p_d>\\n            - Defined as: \\n                - Date when the <p> is made\\n                - Date when the <p> is expected to come to fruition\\n            - Characteristics:\\n                - Forecast can range from a second to anytime in the future.\\n                - Could answer the question: \"How far out is the <p> from today?\"\\n                - Any format\\n                - Must be made before it is expected to come to fruition\\n                - Named entity: Date, cardinal?\\n                - Part of speech: ?\\n            - Examples:\\n                1. Wednesday, August 21, 2024\\n                2. Wed, August 21, 2024 to 11-23-2024\\n                3. 3 minutes\\n                4. 08/21/2024 to 12.21.2024\\n                5. 21/08/2024\\n                6. 21 August 2024\\n                7. 1 year from now\\n\\n        4. <p_o>\\n            - Defined as:\\n                - Outcome\\n            - Characteristics:\\n                - Relevant or misc details such as a quantifiable metric, slope, attribute of interest\\n                - From Pegah at USC: Value at an instant, statistical function minimum, changes over interval, second order effect comparison, recurrent pattern\\n                - Named entity: ?\\n                - Part of speech: ?\\n            - Examples:\\n                1. remain stable\\n                2. increase\\n                3. decrease from 8 to 3\\n                4. stock price\\n                5. voting results\\n                6. team win\\n                7. number of steps\\n\\n        \\n\\n    Enforce: \\n\\n            1. Usage of the future verb tense, such as: {future_tense_verbs}.\\n            2. Do NOT use past or present tense verbs.\\n\\n        \\n    Know: Some examples of predictions in the PhraseBank dataset are\\n    1. According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\\n    2. According to the company \\'s updated strategy for the years 2009-2012 , Basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net sales .\\n    3. Its board of directors will propose a dividend of EUR0 .12 per share for 2010 , up from the EUR0 .08 per share paid in 2009 .\\n\\n    Know: Some examples of non-predictions in the PPhraseBank dataset are\\n    1. Net sales increased to EUR193 .3 m from EUR179 .9 m and pretax profit rose by 34.2 % to EUR43 .1 m. ( EUR1 = USD1 .4 )\\n    2. Net sales surged by 18.5 % to EUR167 .8 m. Teleste said that EUR20 .4 m , or 12.2 % , of the sales came from the acquisitions made in 2009 .\\n    3. STORA ENSO , NORSKE SKOG , M-REAL , UPM-KYMMENE Credit Suisse First Boston ( CFSB ) raised the fair value for shares in four of the largest Nordic forestry groups .\\n\\n    Question: Given the above and in an extractive manner, identify the predictions in the given documents.\\n\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_identity_prompt = \"You are an expert at identifying specific types of sentences by knowing the sentence format.\"\n",
    "prediction_examples_prompt = \"\"\"Some examples of predictions in the PhraseBank dataset are\n",
    "    1. According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\n",
    "    2. According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net sales .\n",
    "    3. Its board of directors will propose a dividend of EUR0 .12 per share for 2010 , up from the EUR0 .08 per share paid in 2009 .\n",
    "\"\"\"\n",
    "non_prediction_examples_prompt = \"\"\"Some examples of non-predictions in the PPhraseBank dataset are\n",
    "    1. Net sales increased to EUR193 .3 m from EUR179 .9 m and pretax profit rose by 34.2 % to EUR43 .1 m. ( EUR1 = USD1 .4 )\n",
    "    2. Net sales surged by 18.5 % to EUR167 .8 m. Teleste said that EUR20 .4 m , or 12.2 % , of the sales came from the acquisitions made in 2009 .\n",
    "    3. STORA ENSO , NORSKE SKOG , M-REAL , UPM-KYMMENE Credit Suisse First Boston ( CFSB ) raised the fair value for shares in four of the largest Nordic forestry groups .\n",
    "\"\"\"\n",
    "goal_prompt = \"Given the above and in an extractive manner, identify the predictions in the given documents.\"\n",
    "structured_query_string = f\"\"\"{system_identity_prompt} The sentence format is based on: \n",
    "    {prediction_properties}\n",
    "    \n",
    "    Enforce: {prediction_requirements}\n",
    "    Know: {prediction_examples_prompt}\n",
    "    Know: {non_prediction_examples_prompt}\n",
    "    Question: {goal_prompt}\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "structured_query_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b3051b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f7aadcb161499eb5c925618204050f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>blob</th>\n",
       "      <th>meta</th>\n",
       "      <th>score</th>\n",
       "      <th>embedding</th>\n",
       "      <th>sparse_embedding</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c8250eb1bfc021b035d71ba172e262a21ab427b756d6a7776cbbdf3bdc56e96c</td>\n",
       "      <td>According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .</td>\n",
       "      <td>None</td>\n",
       "      <td>{'sentiment': 'neutral', 'source_id': '63461e5f36b506ade08357e3bdb34e98c8ba387ec40e2d27f0b651cdc0416edf', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []}</td>\n",
       "      <td>0.048373</td>\n",
       "      <td>[0.04417748004198074, -0.03718455508351326, -0.026471151039004326, -0.014962117187678814, 0.046283308416604996, -0.02831903286278248, -0.07162532210350037, 0.05365421622991562, -0.04093141108751297, 0.0298501905053854, 0.009826543740928173, 0.01519095804542303, 0.034347400069236755, -0.028681518509984016, -0.03954571112990379, -0.002502115909010172, -0.006628081202507019, -0.12832355499267578, -0.09077678620815277, -0.07121571153402328, 0.048768915235996246, -0.08011864125728607, 0.010965651832520962, 0.004186794627457857, 0.08360739052295685, -0.05175008624792099, -0.015410348773002625, 0.06874939799308777, -0.05621153116226196, -0.10414990782737732, -0.04159145802259445, -0.011647788807749748, -0.017109237611293793, 0.047060608863830566, 0.06767600029706955, 0.056333694607019424, 0.0...</td>\n",
       "      <td>None</td>\n",
       "      <td>You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction &lt;p&gt; = (&lt;p_s&gt;, &lt;p_t&gt;, &lt;p_d&gt;, &lt;p_o&gt;), where it consists of the following four properties:\\n\\n        1. &lt;p_s&gt;\\n            - Defined as: \\n                - Source entity that states the &lt;p&gt;\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9e8da179f1923e36a0092be7b7b424377e1daae0870033d8c91988bd15b3c277</td>\n",
       "      <td>With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .</td>\n",
       "      <td>None</td>\n",
       "      <td>{'sentiment': 'positive', 'source_id': '39e2ff2d164bed02386d1da93730042991b977cb8b62db9d4786722a19a10695', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []}</td>\n",
       "      <td>0.041144</td>\n",
       "      <td>[-0.035207055509090424, -0.04257950559258461, 0.034338660538196564, 0.04421427473425865, 0.07892248779535294, 0.0337398499250412, 0.013001815415918827, 0.0477336049079895, -0.06594444811344147, 0.015794288367033005, 0.020301755517721176, -0.025846945121884346, 0.04249538853764534, 0.0024806081783026457, 0.0225980244576931, -0.003781020874157548, 0.025006961077451706, -0.06871230900287628, -0.11034145206212997, -0.042451225221157074, -0.007218378130346537, -0.005378246307373047, -0.019224535673856735, -0.04748206585645676, 0.016703318804502487, -0.08213851600885391, -0.06476438790559769, 0.050822217017412186, -0.014659274369478226, -0.09981179237365723, -0.04532046988606453, 0.038232963532209396, 0.09121283888816833, -0.0176495760679245, -0.027979986742138863, 0.024657418951392174, -0.0...</td>\n",
       "      <td>None</td>\n",
       "      <td>You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction &lt;p&gt; = (&lt;p_s&gt;, &lt;p_t&gt;, &lt;p_d&gt;, &lt;p_o&gt;), where it consists of the following four properties:\\n\\n        1. &lt;p_s&gt;\\n            - Defined as: \\n                - Source entity that states the &lt;p&gt;\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>084eec7989f0cfbbb94860b54ffffe5c0ea064f896a8dc4e4e69dfa1f4fb6eb0</td>\n",
       "      <td>FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is aggressively pursuing its growth strategy by increasingly focusing on technologically more demanding HDI printed circuit boards PCBs .</td>\n",
       "      <td>None</td>\n",
       "      <td>{'sentiment': 'positive', 'source_id': '2c106b768ca3455523070e94cfcdbc9e145ca808ae79f54e5d2f7c56e21ab280', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []}</td>\n",
       "      <td>0.039757</td>\n",
       "      <td>[-0.09474382549524307, 0.03575887158513069, -0.01008855551481247, -0.02626115269958973, -0.032105542719364166, 0.003865437349304557, 0.014795641414821148, 0.08497466146945953, -0.028726238757371902, 0.011877134442329407, 0.027913358062505722, -0.033456381410360336, -0.006573919206857681, 0.015562358312308788, 0.00737267080694437, 0.003023969242349267, 0.016429778188467026, -0.056831132620573044, 0.05786523222923279, 0.07459749281406403, -0.004638561047613621, -0.007768626324832439, -0.01902686432003975, -0.0597747303545475, 0.028151750564575195, -0.007394744548946619, -0.0034259746316820383, -0.04720968380570412, 0.0038298871368169785, -0.17240238189697266, 0.022011369466781616, -0.03369791433215141, 0.11034069955348969, -0.060524240136146545, -0.005658744368702173, 0.02845997549593448...</td>\n",
       "      <td>None</td>\n",
       "      <td>You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction &lt;p&gt; = (&lt;p_s&gt;, &lt;p_t&gt;, &lt;p_d&gt;, &lt;p_o&gt;), where it consists of the following four properties:\\n\\n        1. &lt;p_s&gt;\\n            - Defined as: \\n                - Source entity that states the &lt;p&gt;\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bc1d4924ecbc2356699cdec2c4662ea3f2125a2dcf7c7215f4d0ca06408718fa</td>\n",
       "      <td>The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .</td>\n",
       "      <td>None</td>\n",
       "      <td>{'sentiment': 'negative', 'source_id': 'a733e18a009c0cdef1ee85366b3506eb3f869588c69b0c4d604021aa6d34a1df', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []}</td>\n",
       "      <td>0.039729</td>\n",
       "      <td>[0.0015696012414991856, 0.020328842103481293, 0.019818270578980446, 0.04947220906615257, 0.03532050922513008, -0.05796285718679428, 0.008652362041175365, -0.01944827474653721, -0.009909278713166714, 0.016989462077617645, -0.027807975187897682, 0.018154840916395187, 0.028072606772184372, 0.027880067005753517, -0.057872090488672256, -0.07978159189224243, -0.04243866726756096, -0.04546249657869339, 0.006874066311866045, -0.010249821469187737, 0.00147753965575248, -0.05592601001262665, 0.016597405076026917, 0.04210502281785011, -0.004663458559662104, 0.11669496446847916, -0.05408050864934921, -0.061443477869033813, -0.014450674876570702, -0.03275688365101814, -0.07827884703874588, 0.011589611880481243, 0.021334180608391762, 0.025920234620571136, 0.10664574056863785, -0.026037318632006645, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction &lt;p&gt; = (&lt;p_s&gt;, &lt;p_t&gt;, &lt;p_d&gt;, &lt;p_o&gt;), where it consists of the following four properties:\\n\\n        1. &lt;p_s&gt;\\n            - Defined as: \\n                - Source entity that states the &lt;p&gt;\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eca3bde5827e8c41cf7ff34ad824d59d20238393c3fdcaee1e188dcb729a9f67</td>\n",
       "      <td>Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .</td>\n",
       "      <td>None</td>\n",
       "      <td>{'sentiment': 'neutral', 'source_id': '99e7dc0575e03709f270d73b2dd4f9b878b6e2b998cdc488afb27daad6fb44a2', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []}</td>\n",
       "      <td>0.035642</td>\n",
       "      <td>[0.04630071669816971, 0.07204117625951767, 0.017594104632735252, -0.029257599264383316, -0.019784018397331238, -0.030141139402985573, -0.0817226693034172, 0.06145090237259865, -0.03713926300406456, -0.020847128704190254, 0.04031316563487053, -0.012344671413302422, 0.03221141919493675, 0.037878021597862244, 0.03815079107880592, 0.03218069300055504, 0.032456498593091965, -0.06587936729192734, 0.04780890420079231, 0.05331951379776001, 0.07672900706529617, 0.003880580887198448, 0.01521730050444603, -0.018973171710968018, -0.020536495372653008, -0.039369288831949234, -0.02029009722173214, -0.022223148494958878, 0.021031159907579422, -0.022486941888928413, 0.017007697373628616, 0.02651798538863659, 0.04697044938802719, 0.05715585872530937, 0.04016794636845589, 0.009188780561089516, -0.025014...</td>\n",
       "      <td>None</td>\n",
       "      <td>You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction &lt;p&gt; = (&lt;p_s&gt;, &lt;p_t&gt;, &lt;p_d&gt;, &lt;p_o&gt;), where it consists of the following four properties:\\n\\n        1. &lt;p_s&gt;\\n            - Defined as: \\n                - Source entity that states the &lt;p&gt;\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73d23111fc1b25d31fe5cbbe355c8bb049337865c70fb926be3775c4b718a03a</td>\n",
       "      <td>For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .</td>\n",
       "      <td>None</td>\n",
       "      <td>{'sentiment': 'positive', 'source_id': '852ab50b47d2e32fda355f76e6f1c81a29e0501c423710922ac67f559ec09ad4', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []}</td>\n",
       "      <td>0.034660</td>\n",
       "      <td>[-0.01977328211069107, -0.0006782960845157504, 0.004197688773274422, 0.008549429476261139, 0.00079585105413571, -0.012986055575311184, -0.0322977751493454, 0.08971510827541351, 0.06262925267219543, 0.006873776204884052, -0.009138626977801323, -0.0004523413081187755, 0.030919233337044716, 0.032683055847883224, -0.03587600216269493, 0.0169424656778574, 0.041251227259635925, -0.07370208948850632, -0.04786425828933716, -0.008989573456346989, 0.013630560599267483, -0.025575026869773865, 0.07452664524316788, 0.024510575458407402, 0.05542443320155144, 0.021249916404485703, -0.038454942405223846, -0.011156403459608555, 0.018944524228572845, -0.13731145858764648, 0.03593116253614426, 0.0222391989082098, -0.03129721060395241, -0.03019612841308117, 0.011866819113492966, -0.01958608254790306, -0.0...</td>\n",
       "      <td>None</td>\n",
       "      <td>You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction &lt;p&gt; = (&lt;p_s&gt;, &lt;p_t&gt;, &lt;p_d&gt;, &lt;p_o&gt;), where it consists of the following four properties:\\n\\n        1. &lt;p_s&gt;\\n            - Defined as: \\n                - Source entity that states the &lt;p&gt;\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4a03f278be2029758643f0f66786357d43a09d42e5629430b9c2a79196d07400</td>\n",
       "      <td>According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net sales .</td>\n",
       "      <td>None</td>\n",
       "      <td>{'sentiment': 'positive', 'source_id': '1f38a8a49050433e5fabd819b0bc84b4944a4f683c6797d3fe98a0feeb0c8146', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []}</td>\n",
       "      <td>0.018463</td>\n",
       "      <td>[-0.01745886355638504, 0.01482729148119688, 0.020775308832526207, -0.06313874572515488, 0.0020731547847390175, -0.0193954985588789, -0.029298460111021996, 0.03914877027273178, -0.013426211662590504, -0.01183039229363203, -0.04687410965561867, 0.03554028645157814, 0.017195463180541992, 0.04681131988763809, -0.03842860460281372, 0.0034608659334480762, 0.05894489958882332, -0.04916747659444809, 0.044625524431467056, 0.03538520634174347, 0.03609863668680191, -0.02803066186606884, 0.0046316394582390785, 0.014810824766755104, 0.028691019862890244, -0.05344802513718605, 0.016210302710533142, 0.006988603621721268, -0.0285661481320858, -0.1190299317240715, -0.030388228595256805, -0.07651226222515106, 0.0560644268989563, -0.020919064059853554, -0.014732511714100838, 0.04285265505313873, -0.01339...</td>\n",
       "      <td>None</td>\n",
       "      <td>You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction &lt;p&gt; = (&lt;p_s&gt;, &lt;p_t&gt;, &lt;p_d&gt;, &lt;p_o&gt;), where it consists of the following four properties:\\n\\n        1. &lt;p_s&gt;\\n            - Defined as: \\n                - Source entity that states the &lt;p&gt;\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 id  \\\n",
       "0  c8250eb1bfc021b035d71ba172e262a21ab427b756d6a7776cbbdf3bdc56e96c   \n",
       "1  9e8da179f1923e36a0092be7b7b424377e1daae0870033d8c91988bd15b3c277   \n",
       "2  084eec7989f0cfbbb94860b54ffffe5c0ea064f896a8dc4e4e69dfa1f4fb6eb0   \n",
       "3  bc1d4924ecbc2356699cdec2c4662ea3f2125a2dcf7c7215f4d0ca06408718fa   \n",
       "4  eca3bde5827e8c41cf7ff34ad824d59d20238393c3fdcaee1e188dcb729a9f67   \n",
       "5  73d23111fc1b25d31fe5cbbe355c8bb049337865c70fb926be3775c4b718a03a   \n",
       "6  4a03f278be2029758643f0f66786357d43a09d42e5629430b9c2a79196d07400   \n",
       "\n",
       "                                                                                                                                                                                                                                content  \\\n",
       "0                                                                                                       According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .   \n",
       "1                        With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .   \n",
       "2                                                    FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is aggressively pursuing its growth strategy by increasingly focusing on technologically more demanding HDI printed circuit boards PCBs .   \n",
       "3  The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .   \n",
       "4                                        Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .   \n",
       "5                                     For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .   \n",
       "6                           According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net sales .   \n",
       "\n",
       "   blob  \\\n",
       "0  None   \n",
       "1  None   \n",
       "2  None   \n",
       "3  None   \n",
       "4  None   \n",
       "5  None   \n",
       "6  None   \n",
       "\n",
       "                                                                                                                                                                                      meta  \\\n",
       "0   {'sentiment': 'neutral', 'source_id': '63461e5f36b506ade08357e3bdb34e98c8ba387ec40e2d27f0b651cdc0416edf', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []}   \n",
       "1  {'sentiment': 'positive', 'source_id': '39e2ff2d164bed02386d1da93730042991b977cb8b62db9d4786722a19a10695', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []}   \n",
       "2  {'sentiment': 'positive', 'source_id': '2c106b768ca3455523070e94cfcdbc9e145ca808ae79f54e5d2f7c56e21ab280', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []}   \n",
       "3  {'sentiment': 'negative', 'source_id': 'a733e18a009c0cdef1ee85366b3506eb3f869588c69b0c4d604021aa6d34a1df', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []}   \n",
       "4   {'sentiment': 'neutral', 'source_id': '99e7dc0575e03709f270d73b2dd4f9b878b6e2b998cdc488afb27daad6fb44a2', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []}   \n",
       "5  {'sentiment': 'positive', 'source_id': '852ab50b47d2e32fda355f76e6f1c81a29e0501c423710922ac67f559ec09ad4', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []}   \n",
       "6  {'sentiment': 'positive', 'source_id': '1f38a8a49050433e5fabd819b0bc84b4944a4f683c6797d3fe98a0feeb0c8146', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []}   \n",
       "\n",
       "      score  \\\n",
       "0  0.048373   \n",
       "1  0.041144   \n",
       "2  0.039757   \n",
       "3  0.039729   \n",
       "4  0.035642   \n",
       "5  0.034660   \n",
       "6  0.018463   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         embedding  \\\n",
       "0  [0.04417748004198074, -0.03718455508351326, -0.026471151039004326, -0.014962117187678814, 0.046283308416604996, -0.02831903286278248, -0.07162532210350037, 0.05365421622991562, -0.04093141108751297, 0.0298501905053854, 0.009826543740928173, 0.01519095804542303, 0.034347400069236755, -0.028681518509984016, -0.03954571112990379, -0.002502115909010172, -0.006628081202507019, -0.12832355499267578, -0.09077678620815277, -0.07121571153402328, 0.048768915235996246, -0.08011864125728607, 0.010965651832520962, 0.004186794627457857, 0.08360739052295685, -0.05175008624792099, -0.015410348773002625, 0.06874939799308777, -0.05621153116226196, -0.10414990782737732, -0.04159145802259445, -0.011647788807749748, -0.017109237611293793, 0.047060608863830566, 0.06767600029706955, 0.056333694607019424, 0.0...   \n",
       "1  [-0.035207055509090424, -0.04257950559258461, 0.034338660538196564, 0.04421427473425865, 0.07892248779535294, 0.0337398499250412, 0.013001815415918827, 0.0477336049079895, -0.06594444811344147, 0.015794288367033005, 0.020301755517721176, -0.025846945121884346, 0.04249538853764534, 0.0024806081783026457, 0.0225980244576931, -0.003781020874157548, 0.025006961077451706, -0.06871230900287628, -0.11034145206212997, -0.042451225221157074, -0.007218378130346537, -0.005378246307373047, -0.019224535673856735, -0.04748206585645676, 0.016703318804502487, -0.08213851600885391, -0.06476438790559769, 0.050822217017412186, -0.014659274369478226, -0.09981179237365723, -0.04532046988606453, 0.038232963532209396, 0.09121283888816833, -0.0176495760679245, -0.027979986742138863, 0.024657418951392174, -0.0...   \n",
       "2  [-0.09474382549524307, 0.03575887158513069, -0.01008855551481247, -0.02626115269958973, -0.032105542719364166, 0.003865437349304557, 0.014795641414821148, 0.08497466146945953, -0.028726238757371902, 0.011877134442329407, 0.027913358062505722, -0.033456381410360336, -0.006573919206857681, 0.015562358312308788, 0.00737267080694437, 0.003023969242349267, 0.016429778188467026, -0.056831132620573044, 0.05786523222923279, 0.07459749281406403, -0.004638561047613621, -0.007768626324832439, -0.01902686432003975, -0.0597747303545475, 0.028151750564575195, -0.007394744548946619, -0.0034259746316820383, -0.04720968380570412, 0.0038298871368169785, -0.17240238189697266, 0.022011369466781616, -0.03369791433215141, 0.11034069955348969, -0.060524240136146545, -0.005658744368702173, 0.02845997549593448...   \n",
       "3  [0.0015696012414991856, 0.020328842103481293, 0.019818270578980446, 0.04947220906615257, 0.03532050922513008, -0.05796285718679428, 0.008652362041175365, -0.01944827474653721, -0.009909278713166714, 0.016989462077617645, -0.027807975187897682, 0.018154840916395187, 0.028072606772184372, 0.027880067005753517, -0.057872090488672256, -0.07978159189224243, -0.04243866726756096, -0.04546249657869339, 0.006874066311866045, -0.010249821469187737, 0.00147753965575248, -0.05592601001262665, 0.016597405076026917, 0.04210502281785011, -0.004663458559662104, 0.11669496446847916, -0.05408050864934921, -0.061443477869033813, -0.014450674876570702, -0.03275688365101814, -0.07827884703874588, 0.011589611880481243, 0.021334180608391762, 0.025920234620571136, 0.10664574056863785, -0.026037318632006645, ...   \n",
       "4  [0.04630071669816971, 0.07204117625951767, 0.017594104632735252, -0.029257599264383316, -0.019784018397331238, -0.030141139402985573, -0.0817226693034172, 0.06145090237259865, -0.03713926300406456, -0.020847128704190254, 0.04031316563487053, -0.012344671413302422, 0.03221141919493675, 0.037878021597862244, 0.03815079107880592, 0.03218069300055504, 0.032456498593091965, -0.06587936729192734, 0.04780890420079231, 0.05331951379776001, 0.07672900706529617, 0.003880580887198448, 0.01521730050444603, -0.018973171710968018, -0.020536495372653008, -0.039369288831949234, -0.02029009722173214, -0.022223148494958878, 0.021031159907579422, -0.022486941888928413, 0.017007697373628616, 0.02651798538863659, 0.04697044938802719, 0.05715585872530937, 0.04016794636845589, 0.009188780561089516, -0.025014...   \n",
       "5  [-0.01977328211069107, -0.0006782960845157504, 0.004197688773274422, 0.008549429476261139, 0.00079585105413571, -0.012986055575311184, -0.0322977751493454, 0.08971510827541351, 0.06262925267219543, 0.006873776204884052, -0.009138626977801323, -0.0004523413081187755, 0.030919233337044716, 0.032683055847883224, -0.03587600216269493, 0.0169424656778574, 0.041251227259635925, -0.07370208948850632, -0.04786425828933716, -0.008989573456346989, 0.013630560599267483, -0.025575026869773865, 0.07452664524316788, 0.024510575458407402, 0.05542443320155144, 0.021249916404485703, -0.038454942405223846, -0.011156403459608555, 0.018944524228572845, -0.13731145858764648, 0.03593116253614426, 0.0222391989082098, -0.03129721060395241, -0.03019612841308117, 0.011866819113492966, -0.01958608254790306, -0.0...   \n",
       "6  [-0.01745886355638504, 0.01482729148119688, 0.020775308832526207, -0.06313874572515488, 0.0020731547847390175, -0.0193954985588789, -0.029298460111021996, 0.03914877027273178, -0.013426211662590504, -0.01183039229363203, -0.04687410965561867, 0.03554028645157814, 0.017195463180541992, 0.04681131988763809, -0.03842860460281372, 0.0034608659334480762, 0.05894489958882332, -0.04916747659444809, 0.044625524431467056, 0.03538520634174347, 0.03609863668680191, -0.02803066186606884, 0.0046316394582390785, 0.014810824766755104, 0.028691019862890244, -0.05344802513718605, 0.016210302710533142, 0.006988603621721268, -0.0285661481320858, -0.1190299317240715, -0.030388228595256805, -0.07651226222515106, 0.0560644268989563, -0.020919064059853554, -0.014732511714100838, 0.04285265505313873, -0.01339...   \n",
       "\n",
       "  sparse_embedding  \\\n",
       "0             None   \n",
       "1             None   \n",
       "2             None   \n",
       "3             None   \n",
       "4             None   \n",
       "5             None   \n",
       "6             None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             query  \n",
       "0  You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction <p> = (<p_s>, <p_t>, <p_d>, <p_o>), where it consists of the following four properties:\\n\\n        1. <p_s>\\n            - Defined as: \\n                - Source entity that states the <p>\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n ...  \n",
       "1  You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction <p> = (<p_s>, <p_t>, <p_d>, <p_o>), where it consists of the following four properties:\\n\\n        1. <p_s>\\n            - Defined as: \\n                - Source entity that states the <p>\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n ...  \n",
       "2  You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction <p> = (<p_s>, <p_t>, <p_d>, <p_o>), where it consists of the following four properties:\\n\\n        1. <p_s>\\n            - Defined as: \\n                - Source entity that states the <p>\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n ...  \n",
       "3  You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction <p> = (<p_s>, <p_t>, <p_d>, <p_o>), where it consists of the following four properties:\\n\\n        1. <p_s>\\n            - Defined as: \\n                - Source entity that states the <p>\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n ...  \n",
       "4  You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction <p> = (<p_s>, <p_t>, <p_d>, <p_o>), where it consists of the following four properties:\\n\\n        1. <p_s>\\n            - Defined as: \\n                - Source entity that states the <p>\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n ...  \n",
       "5  You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction <p> = (<p_s>, <p_t>, <p_d>, <p_o>), where it consists of the following four properties:\\n\\n        1. <p_s>\\n            - Defined as: \\n                - Source entity that states the <p>\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n ...  \n",
       "6  You are an expert at identifying specific types of sentences by knowing the sentence format. The sentence format is based on: \\n     A prediction <p> = (<p_s>, <p_t>, <p_d>, <p_o>), where it consists of the following four properties:\\n\\n        1. <p_s>\\n            - Defined as: \\n                - Source entity that states the <p>\\n            - Characteristics:\\n                - A person with either: a name only, profile name only, geneder only, domain specific title only or any combination of these.\\n                - An associated organization\\n                - Named entity: Person, organization\\n                - Part of speech: Noun\\n            - Examples:\\n                1. A person with a name only: Detravious\\n                2. A person with a profile name: FitToJesus\\n ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_result = hybrid_retrieval.run(\n",
    "    {\"text_embedder\": {\"text\": structured_query_string}, \"bm25_retriever\": {\"query\": structured_query_string}, \"ranker\": {\"query\": structured_query_string}}\n",
    ")\n",
    "\n",
    "retrieved_result[\"ranker\"][\"documents\"]\n",
    "retrieved_result_df = pd.DataFrame(retrieved_result[\"ranker\"][\"documents\"])\n",
    "retrieved_result_df['query'] = structured_query_string\n",
    "retrieved_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac31c8c",
   "metadata": {},
   "source": [
    "## Save Data\n",
    "\n",
    "- **Problems:**\n",
    "    1. Multiple files with distinct retrieved results\n",
    "    2. Same file where we duplicate retrieved results. Duplicate as in first run: 0 to 7, second run 7 to 14, but it includes 0 to 7, so file would be 0 to 7, 0 to 7, then 7 to 14.\n",
    "\n",
    "- **Solutions:**\n",
    "    - `new_file = True:` Only when it's the first usage.\n",
    "    - `new_file = False:` Only when it's after the first usage. Reasoning is: the next step of LLM labeling (prediction/non-prediction) will use this saved file and store results in same file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab83c139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9241bf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: \n",
      "\t/Users/detraviousjamaribrinkley/Documents/Development/research_labs/uf_ds/predictions/predictions_with_rag/../data/hybrid_retrieval/retrieved_results-v1.csv\n"
     ]
    }
   ],
   "source": [
    "if new_file == True:\n",
    "    prefix = \"retrieved_results\"\n",
    "    save_file_type = \"csv\"\n",
    "    DataProcessing.save_to_file(retrieved_result_df, hybrid_retrieval_results_path, prefix, save_file_type)\n",
    "else:\n",
    "    \"\"\"If append to previous file, then save:\"\"\"\n",
    "    path = os.path.join(base_data_path, \"../data/rag/retrieved/\", \"text_label_name_meta_data-v1.csv\")\n",
    "    # prefix = \"text_label_metadata\"\n",
    "    save_file_type = \"csv\"\n",
    "    df = DataProcessing.load_from_file(path, save_file_type)\n",
    "    df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89909f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = retrieved_result_df.content\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a012b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_df = retrieved_result_df.drop(['content'], axis=1)\n",
    "meta_data_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(content)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1274829",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_datas = []\n",
    "for idx, row in meta_data_df.iterrows():\n",
    "    meta_datas.append(row)\n",
    "\n",
    "meta_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f16bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['meta_data'] = meta_datas\n",
    "new_df.rename(columns={'content': 'text'}, inplace=True)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488f6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = pd.concat([df, new_df])\n",
    "updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05343d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(notebook_dir, \"../data/rag/retrieved/\")\n",
    "prefix = \"text_label_name_meta_data\"\n",
    "save_file_type = \"csv\"\n",
    "DataProcessing.save_to_file(updated_df, path, prefix, save_file_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9534e3f5",
   "metadata": {},
   "source": [
    "### Pretty Print the Results\n",
    "Create a function to print a kind of *search page*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f0bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_results(prediction):\n",
    "    for doc in prediction[\"documents\"]:\n",
    "        print(doc.content, \"\\t\", doc.score)\n",
    "        # print(doc.meta[\"abstract\"])\n",
    "        print(\"\\n\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbb05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print_results(result[\"ranker\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f84f0",
   "metadata": {},
   "source": [
    "## What's next\n",
    "\n",
    "ðŸŽ‰ Congratulations! You've create a hybrid retrieval pipeline!\n",
    "\n",
    "If you'd like to use this retrieval method in a RAG pipeline, check out [Tutorial: Creating Your First QA Pipeline with Retrieval-Augmentation](https://haystack.deepset.ai/tutorials/27_first_rag_pipeline) to learn about the next steps.\n",
    "\n",
    "To stay up to date on the latest Haystack developments, you can [sign up for our newsletter](https://landing.deepset.ai/haystack-community-updates) or [join Haystack discord community](https://discord.gg/haystack).\n",
    "\n",
    "Thanks for reading!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa6f3de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11fe4a15",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_predictions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
