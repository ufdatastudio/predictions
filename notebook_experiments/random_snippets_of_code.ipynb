{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa7c372",
   "metadata": {},
   "source": [
    "# Random snippets of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spacy.io/usage/linguistic-features#morphology\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"Pipeline:\", nlp.pipe_names)\n",
    "doc = nlp(\"I was reading the paper.\")\n",
    "token = doc[0]  # 'I'\n",
    "print(token.morph)  # 'Case=Nom|Number=Sing|Person=1|PronType=Prs'\n",
    "print(token.morph.get(\"PronType\"))  # ['Prs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9a83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spacy.io/usage/linguistic-features#morphology\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"Pipeline:\", nlp.pipe_names)\n",
    "doc = nlp(\"She was reading the paper.\")\n",
    "token = doc[0]\n",
    "print(token.morph)  \n",
    "print(token.morph.get(\"PronType\"))  # ['Prs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaecb643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"I live in New York\")\n",
    "print(\"Before:\", [token.text for token in doc])\n",
    "\n",
    "with doc.retokenize() as retokenizer:\n",
    "    retokenizer.merge(doc[3:5], attrs={\"LEMMA\": \"new york\"})\n",
    "print(\"After:\", [token.text for token in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9825cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"This is a sentence. This is another sentence.\")\n",
    "# assert doc.has_annotation(\"SENT_START\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9382981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"I saw The Who perform. Who did you see?\"\n",
    "doc1 = nlp(text)\n",
    "print(doc1[2].tag_, doc1[2].pos_)  # DT DET\n",
    "print(doc1[3].tag_, doc1[3].pos_)  # WP PRON\n",
    "\n",
    "# Add attribute ruler with exception for \"The Who\" as NNP/PROPN NNP/PROPN\n",
    "ruler = nlp.get_pipe(\"attribute_ruler\")\n",
    "# Pattern to match \"The Who\"\n",
    "patterns = [[{\"LOWER\": \"the\"}, {\"TEXT\": \"Who\"}]]\n",
    "# The attributes to assign to the matched token\n",
    "attrs = {\"TAG\": \"NNP\", \"POS\": \"PROPN\"}\n",
    "# Add rules to the attribute ruler\n",
    "ruler.add(patterns=patterns, attrs=attrs, index=0)  # \"The\" in \"The Who\"\n",
    "ruler.add(patterns=patterns, attrs=attrs, index=1)  # \"Who\" in \"The Who\"\n",
    "\n",
    "doc2 = nlp(text)\n",
    "print(doc2[2].tag_, doc2[2].pos_)  # NNP PROPN\n",
    "print(doc2[3].tag_, doc2[3].pos_)  # NNP PROPN\n",
    "# The second \"Who\" remains unmodified\n",
    "print(doc2[5].tag_, doc2[5].pos_)  # WP PRON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20060431-85b0-4b83-8ca2-13979fe6d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c77aceed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n",
      "tensor([[1.0000, 0.9214, 0.7928],\n",
      "        [0.9214, 1.0000, 0.8919],\n",
      "        [0.7928, 0.8919, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "prediction_sentence = [\"Warren Buffet predicts that the net profit at Berkshire Hathaway will rise by 10% on 2024/08/21.\"]\n",
    "\n",
    "observations_sentence = [\"Warren Buffet observed that the net profit at Berkshire Hathaway did rise by 10% on 2024/08/21.\", \n",
    "                \"Warren Buffet observed that the net profit at Berkshire Hathaway did not rise by 10% on 2024/08/21.\"]\n",
    "\n",
    "po_sentences = prediction_sentence + observations_sentence\n",
    "\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(my_sentences)\n",
    "print(embeddings.shape)\n",
    "\n",
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n",
    "# tensor([[1.0000, 0.6660, 0.1046],\n",
    "#         [0.6660, 1.0000, 0.1411],\n",
    "#         [0.1046, 0.1411, 1.0000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f75d0d8-1ce1-4ea2-8f98-7111e44d9afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
