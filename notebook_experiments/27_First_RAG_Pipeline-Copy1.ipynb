{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OvkPji9O-qX"
   },
   "source": [
    "# Tutorial: Creating Your First QA Pipeline with Retrieval-Augmentation\n",
    "\n",
    "- **Level**: Beginner\n",
    "- **Time to complete**: 10 minutes\n",
    "- **Components Used**: [`InMemoryDocumentStore`](https://docs.haystack.deepset.ai/docs/inmemorydocumentstore), [`SentenceTransformersDocumentEmbedder`](https://docs.haystack.deepset.ai/docs/sentencetransformersdocumentembedder), [`SentenceTransformersTextEmbedder`](https://docs.haystack.deepset.ai/docs/sentencetransformerstextembedder), [`InMemoryEmbeddingRetriever`](https://docs.haystack.deepset.ai/docs/inmemoryembeddingretriever), [`PromptBuilder`](https://docs.haystack.deepset.ai/docs/promptbuilder), [`OpenAIChatGenerator`](https://docs.haystack.deepset.ai/docs/openaichatgenerator)\n",
    "- **Prerequisites**: You must have an [OpenAI API Key](https://platform.openai.com/api-keys).\n",
    "- **Goal**: After completing this tutorial, you'll have learned the new prompt syntax and how to use PromptBuilder and OpenAIChatGenerator to build a generative question-answering pipeline with retrieval-augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from uuid import uuid4\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# from langchain_core.documents import Document\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.join(notebook_dir, '../'))\n",
    "\n",
    "# import log_files\n",
    "from data_processing import DataProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFqHcXYPO-qZ"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This tutorial shows you how to create a generative question-answering pipeline using the retrieval-augmentation ([RAG](https://www.deepset.ai/blog/llms-retrieval-augmentation)) approach with Haystack. The process involves four main components: [SentenceTransformersTextEmbedder](https://docs.haystack.deepset.ai/docs/sentencetransformerstextembedder) for creating an embedding for the user query, [InMemoryBM25Retriever](https://docs.haystack.deepset.ai/docs/inmemorybm25retriever) for fetching relevant documents, [PromptBuilder](https://docs.haystack.deepset.ai/docs/promptbuilder) for creating a template prompt, and [OpenAIChatGenerator](https://docs.haystack.deepset.ai/docs/openaichatgenerator) for generating responses.\n",
    "\n",
    "For this tutorial, you'll use the Wikipedia pages of [Seven Wonders of the Ancient World](https://en.wikipedia.org/wiki/Wonders_of_the_World) as Documents, but you can replace them with any text you want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXjVlbPiO-qZ"
   },
   "source": [
    "## Preparing the Colab Environment\n",
    "\n",
    "- [Enable GPU Runtime in Colab](https://docs.haystack.deepset.ai/docs/enabling-gpu-acceleration)\n",
    "- [Set logging level to INFO](https://docs.haystack.deepset.ai/docs/logging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kww5B_vXO-qZ"
   },
   "source": [
    "## Installing Haystack\n",
    "\n",
    "Install Haystack and other required packages with `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQbU8GUfO-qZ",
    "outputId": "c33579e9-5557-43bd-a3c5-63b8373770c7"
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# pip install haystack-ai\n",
    "# pip install \"datasets>=2.6.1\"\n",
    "# pip install \"sentence-transformers>=4.1.0\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lvfew16O-qa",
    "tags": []
   },
   "source": [
    "## Fetching and Indexing Documents\n",
    "\n",
    "You'll start creating your question answering system by downloading the data and indexing the data with its embeddings to a DocumentStore. \n",
    "\n",
    "In this tutorial, you will take a simple approach to writing documents and their embeddings into the DocumentStore. For a full indexing pipeline with preprocessing, cleaning and splitting, check out our tutorial on [Preprocessing Different File Types](https://haystack.deepset.ai/tutorials/30_file_type_preprocessing_index_pipeline).\n",
    "\n",
    "\n",
    "### Initializing the DocumentStore\n",
    "\n",
    "Initialize a DocumentStore to index your documents. A DocumentStore stores the Documents that the question answering system uses to find answers to your questions. In this tutorial, you'll be using the `InMemoryDocumentStore`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CbVN-s5LO-qa"
   },
   "outputs": [],
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yL8nuJdWO-qa"
   },
   "source": [
    "> `InMemoryDocumentStore` is the simplest DocumentStore to get started with. It requires no external dependencies and it's a good option for smaller projects and debugging. But it doesn't scale up so well to larger Document collections, so it's not a good choice for production systems. To learn more about the different types of external databases that Haystack supports, see [DocumentStore Integrations](https://haystack.deepset.ai/integrations?type=Document+Store)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvLVaFHTO-qb"
   },
   "source": [
    "The DocumentStore is now ready. Now it's time to fill it with some Documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HryYZP9ZO-qb"
   },
   "source": [
    "### Fetch the Data\n",
    "\n",
    "You'll use the Wikipedia pages of [Seven Wonders of the Ancient World](https://en.wikipedia.org/wiki/Wonders_of_the_World) as Documents. We preprocessed the data and uploaded to a Hugging Face Space: [Seven Wonders](https://huggingface.co/datasets/bilgeyucel/seven-wonders). Thus, you don't need to perform any additional cleaning or splitting.\n",
    "\n",
    "Fetch the data and convert it into Haystack Documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /orange/ufdatastudios/dj.brinkley/predictions/data/financial_phrase_bank/all_data-adjusted_header.csv\n",
    "# /orange/ufdatastudios/dj.brinkley/predictions/data/financial_phrase_bank/all_data-adjusted_header.csv\n",
    "# /orange/ufdatastudios/dj.brinkley/predictions/data/financial_phrase_bank/all_data-adjusted_header.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path = os.path.join(notebook_dir, '../data/')\n",
    "base_path = os.path.join('/orange/ufdatastudios/dj.brinkley/predictions/data/')\n",
    "financial_full_path = os.path.join(base_path, 'financial_phrase_bank/all_data-adjusted_header.csv')\n",
    "# financial_df = pd.read_csv(financial_full_path, encoding_errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INdC3WvLO-qb",
    "outputId": "1af43d0f-2999-4de4-d152-b3cca9fb49e6"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from haystack import Document\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=financial_full_path, split=\"train\")\n",
    "docs = [Document(content=doc[\"sentence\"], meta={\"sentiment\": doc[\"sentiment\"]}) for doc in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = docs[:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def build_documents(df: pd.DataFrame):\n",
    "#     documents = []\n",
    "#     \"\"\"(Abstract) Processes raw data into LangChain Documents.\"\"\"\n",
    "#     metadata_cols = [col for col in df.columns if col != 'sentence']\n",
    "#     print(f\"\\tMetadata Columns: {metadata_cols}\")\n",
    "\n",
    "#     for _, row in tqdm(df.iterrows()):\n",
    "#         # Correctly create metadata from just the current row\n",
    "#         doc_metadata = {col: row[col] for col in metadata_cols}\n",
    "\n",
    "#         document = Document(\n",
    "#             content=row['sentence'],\n",
    "#             meta=doc_metadata\n",
    "#         )\n",
    "#         documents.append(document)\n",
    "#     return documents\n",
    "# docs = build_documents(financial_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id=63461e5f36b506ade08357e3bdb34e98c8ba387ec40e2d27f0b651cdc0416edf, content: 'According to Gran , the company has no plans to move all production to Russia , although that is whe...', meta: {'sentiment': 'neutral'}),\n",
       " Document(id=99e7dc0575e03709f270d73b2dd4f9b878b6e2b998cdc488afb27daad6fb44a2, content: 'Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to hos...', meta: {'sentiment': 'neutral'}),\n",
       " Document(id=a733e18a009c0cdef1ee85366b3506eb3f869588c69b0c4d604021aa6d34a1df, content: 'The international electronic industry company Elcoteq has laid off tens of employees from its Tallin...', meta: {'sentiment': 'negative'}),\n",
       " Document(id=39e2ff2d164bed02386d1da93730042991b977cb8b62db9d4786722a19a10695, content: 'With the new production plant the company would increase its capacity to meet the expected increase ...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=1f38a8a49050433e5fabd819b0bc84b4944a4f683c6797d3fe98a0feeb0c8146, content: 'According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term n...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=2c106b768ca3455523070e94cfcdbc9e145ca808ae79f54e5d2f7c56e21ab280, content: 'FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is aggressively pursuing its growth strategy by increasingl...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=852ab50b47d2e32fda355f76e6f1c81a29e0501c423710922ac67f559ec09ad4, content: 'For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same p...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=bca848dda5f80a663b837b5ea06d5487b72541e3c5d3d6b7ed17ebba0f689553, content: 'In the third quarter of 2010 , net sales increased by 5.2 % to EUR 205.5 mn , and operating profit b...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=7417514bc204a468fc9d902fc35f71a5e8821c0518a6ad475db11e7bf594b0c1, content: 'Operating profit rose to EUR 13.1 mn from EUR 8.7 mn in the corresponding period in 2007 representin...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=66dbb14c11d98599471ee300509a41e8449c48f2e60f718be8d824dbbafbe59e, content: 'Operating profit totalled EUR 21.1 mn , up from EUR 18.6 mn in 2007 , representing 9.7 % of net sale...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=42a2e3a5d7bafafe347dc618eba5a1891e029b67dca1a392fe9388fb1073c638, content: 'TeliaSonera TLSN said the offer is in line with its strategy to increase its ownership in core busin...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=1543db09833342809c76087e5c9ca4a4e7980f88d1b4b64f83281df255b24872, content: 'STORA ENSO , NORSKE SKOG , M-REAL , UPM-KYMMENE Credit Suisse First Boston ( CFSB ) raised the fair ...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=1d9fa05b4686413ad405bd4ac819100204c1500aa5ab7894e91f37facd52deec, content: 'A purchase agreement for 7,200 tons of gasoline with delivery at the Hamina terminal , Finland , was...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=c4fff1f5fb136e3170ef2af33b26fe54a73fcf7f1f8feb8458dcf57c6fd3d7f8, content: 'Finnish Talentum reports its operating profit increased to EUR 20.5 mn in 2005 from EUR 9.3 mn in 20...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=3bb6573ebc4395991fba0a7b270a0d4b7135665f2e88e079e3acab93f272f9ab, content: 'Clothing retail chain Sepp+Ã†l+Ã† 's sales increased by 8 % to EUR 155.2 mn , and operating profit ros...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=06fa3329a1ef43fe66c8b42a75a5f818b4bf45070f6afa3ab5b1c6cbe61dcbca, content: 'Consolidated net sales increased 16 % to reach EUR74 .8 m , while operating profit amounted to EUR0 ...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=69c09efcaa6d964bb354445a97de73561f24e97f6a277f66462cce394b2f4489, content: 'Foundries division reports its sales increased by 9.7 % to EUR 63.1 mn from EUR 57.5 mn in the corre...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=4db66b63c8420b9fa457c043675c8d98c6de936a37d20c3329ded115982452e5, content: 'HELSINKI ( AFX ) - Shares closed higher , led by Nokia after it announced plans to team up with Sany...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=e0e082ae9897f41acf9c174d7057d1fb40f4c4cefce1423a74e642d04472c839, content: 'Incap Contract Manufacturing Services Pvt Ltd , a subsidiary of Incap Corporation of Finland , plans...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=6e6bf28594d6da037f1700c81b166474a47d8f5faf4fbbdf61a3b01e8df5f051, content: 'Its board of directors will propose a dividend of EUR0 .12 per share for 2010 , up from the EUR0 .08...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=f987ce35df4a21fba483e2901fa4dc6ca621d00ce08486f7247c516a1f0389f0, content: 'Lifetree was founded in 2000 , and its revenues have risen on an average by 40 % with margins in lat...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=3eda7465b45d7d801dd9a05bf74a1579bb75c8b18addc8a756ed295333d4b8f5, content: '( Filippova ) A trilateral agreement on investment in the construction of a technology park in St Pe...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=c5b8b4f92b0f510facc42c9301e2acf4e0e71b1f3a5dd484e7bd9a194e30fccf, content: 'MegaFon 's subscriber base increased 16.1 % in 2009 to 50.5 million users as of December 31 , while ...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=155559e5e1bb04dcd708d042d4a27ed837f0a95cc14ac6e8aefad90465789a71, content: 'Net income from life insurance doubled to EUR 6.8 mn from EUR 3.2 mn , and net income from non-life ...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=05cd57bf4ff16df5b7ce02521b34e1bd6169e226e914f9c42a7f21cc7b5e343a, content: 'Net sales increased to EUR193 .3 m from EUR179 .9 m and pretax profit rose by 34.2 % to EUR43 .1 m. ...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=72866e12a99f331230f3114fc6a6ff33f4148b762f6420f1c68318041b72962d, content: 'Net sales surged by 18.5 % to EUR167 .8 m. Teleste said that EUR20 .4 m , or 12.2 % , of the sales c...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=1c6b913e52202210be98af7d62b29295ec45b0bfbe78cd5ebc288f4c1448d18c, content: 'Nordea Group 's operating profit increased in 2010 by 18 percent year-on-year to 3.64 billion euros ...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=ec43dd47c502ef3b0b57e42e7620081536f22ba49be56a81ab7f5aa35f795515, content: 'Operating profit for the nine-month period increased from EUR13 .6 m , while net sales increased fro...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=dd4a7f08027e8b6af9d44bc93cd40da7e4d1e2f1f21e131e16ebc753836ffb8d, content: 'Operating profit for the nine-month period increased from EUR3 .1 m and net sales increased from EUR...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=2059c411433ac0c15e3f2e003d9e7f0222e4e74b7d313ef4a2b761b7019496f4, content: 'Operating profit for the three-month period increased from EUR1 .2 m , while revenue increased from ...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=e51f1dca4b545ff3d899962c961c30eb97ce92d4666c46f2bed796745482cb42, content: 'The Brazilian unit of Finnish security solutions provider F-Secure signed up 1,500 new clients last ...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=4d7e0b8d29de68619a54ae2bbd8ecaf3f8fee294b5e8e32dd3c9ecad310fe065, content: 'The company 's net profit rose 11.4 % on the year to 82.2 million euros in 2005 on sales of 686.5 mi...', meta: {'sentiment': 'positive'}),\n",
       " Document(id=1c6b3ec98f1fd9502cf251c71e7fa5b851cdd54ee1cf973d92ca84057a7744e7, content: 'The Lithuanian beer market made up 14.41 million liters in January , a rise of 0.8 percent from the ...', meta: {'sentiment': 'positive'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czMjWwnxPA-3"
   },
   "source": [
    "### Initalize a Document Embedder\n",
    "\n",
    "To store your data in the DocumentStore with embeddings, initialize a [SentenceTransformersDocumentEmbedder](https://docs.haystack.deepset.ai/docs/sentencetransformersdocumentembedder) with the model name and call `warm_up()` to download the embedding model.\n",
    "\n",
    "> If you'd like, you can use a different [Embedder](https://docs.haystack.deepset.ai/docs/embedders) for your documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUmAH9sEn3R7",
    "outputId": "ee54b59b-4d4a-45eb-c1a9-0b7b248f1dd4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-13 16:31:15.445233: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-13 16:31:15.455427: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760387475.466145 2195416 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760387475.469244 2195416 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1760387475.478220 2195416 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1760387475.478232 2195416 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1760387475.478233 2195416 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1760387475.478234 2195416 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-13 16:31:15.481461: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "doc_embedder.warm_up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9y4iJE_SrS4K"
   },
   "source": [
    "### Write Documents to the DocumentStore\n",
    "\n",
    "Run the `doc_embedder` with the Documents. The embedder will create embeddings for each document and save these embeddings in Document object's `embedding` field. Then, you can write the Documents to the DocumentStore with `write_documents()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "7d482188c12d4a7886f20a65d3402c59",
      "2a3ec74419ae4a02ac0210db66133415",
      "ddeff9a822404adbbc3cad97a939bc0c",
      "36d341ab3a044709b5af2e8ab97559bc",
      "88fc33e1ab78405e911b5eafa512c935",
      "91e5d4b0ede848319ef0d3b558d57d19",
      "d2428c21707d43f2b6f07bfafbace8bb",
      "7fdb2c859e454e72888709a835f7591e",
      "6b8334e071a3438397ba6435aac69f58",
      "5f5cfa425cac4d37b2ea29e53b4ed900",
      "3c59a82dac5c476b9a3e3132094e1702"
     ]
    },
    "id": "ETpQKftLplqh",
    "outputId": "b9c8658c-90c8-497c-e765-97487c0daf8e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b11e082c21a473c980a2768f622fc88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_with_embeddings = doc_embedder.run(docs)\n",
    "document_store.write_documents(docs_with_embeddings[\"documents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdojTxg6uubn"
   },
   "source": [
    "## Building the RAG Pipeline\n",
    "\n",
    "The next step is to build a [Pipeline](https://docs.haystack.deepset.ai/docs/pipelines) to generate answers for the user query following the RAG approach. To create the pipeline, you first need to initialize each component, add them to your pipeline, and connect them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uyV6-u-u56P"
   },
   "source": [
    "### Initialize a Text Embedder\n",
    "\n",
    "Initialize a text embedder to create an embedding for the user query. The created embedding will later be used by the Retriever to retrieve relevant documents from the DocumentStore.\n",
    "\n",
    "> âš ï¸ Notice that you used `sentence-transformers/all-MiniLM-L6-v2` model to create embeddings for your documents before. This is why you need to use the same model to embed the user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LyJY2yW628dl"
   },
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "\n",
    "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_cj-5m-O-qb"
   },
   "source": [
    "### Initialize the Retriever\n",
    "\n",
    "Initialize a [InMemoryEmbeddingRetriever](https://docs.haystack.deepset.ai/docs/inmemoryembeddingretriever) and make it use the InMemoryDocumentStore you initialized earlier in this tutorial. This Retriever will get the relevant documents to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-uo-6fjiO-qb"
   },
   "outputs": [],
   "source": [
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "\n",
    "retriever = InMemoryEmbeddingRetriever(document_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CEuQpB7O-qb"
   },
   "source": [
    "### Define a Template Prompt\n",
    "\n",
    "Create a custom prompt for a generative question answering task using the RAG approach. The prompt should take in two parameters: `documents`, which are retrieved from a document store, and a `question` from the user. Use the Jinja2 looping syntax to combine the content of the retrieved documents in the prompt.\n",
    "\n",
    "Next, initialize a [PromptBuilder](https://docs.haystack.deepset.ai/docs/promptbuilder) instance with your prompt template. The PromptBuilder, when given the necessary values, will automatically fill in the variable values and generate a complete prompt. This approach allows for a more tailored and effective question-answering experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ObahTh45FqOT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ChatPromptBuilder has 2 prompt variables, but `required_variables` is not set. By default, all prompt variables are treated as optional, which may lead to unintended behavior in multi-branch pipelines. To avoid unexpected execution, ensure that variables intended to be required are explicitly set in `required_variables`.\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "\n",
    "template = [\n",
    "    ChatMessage.from_user(\n",
    "        \"\"\"\n",
    "        Given the following information, answer the question.\n",
    "\n",
    "        Context:\n",
    "        {% for document in documents %}\n",
    "            {{ document.content }}\n",
    "        {% endfor %}\n",
    "\n",
    "        Question: {{question}}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt_builder = ChatPromptBuilder(template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HR14lbfcFtXj"
   },
   "source": [
    "### Initialize a ChatGenerator\n",
    "\n",
    "\n",
    "ChatGenerators are the components that interact with large language models (LLMs). Now, set `OPENAI_API_KEY` environment variable and initialize a [OpenAIChatGenerator](https://docs.haystack.deepset.ai/docs/OpenAIChatGenerator) that can communicate with OpenAI GPT models. As you initialize, provide a model name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SavE_FAqfApo",
    "outputId": "1afbf2e8-ae63-41ff-c37f-5123b2103356"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter OpenAI API key: Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from haystack.components.generators.chat import HuggingFaceLocalChatGenerator\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")\n",
    "chat_generator = HuggingFaceLocalChatGenerator(model=\"HuggingFaceH4/zephyr-7b-beta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nenbo2SvycHd"
   },
   "source": [
    "> You can replace `OpenAIChatGenerator` in your pipeline with another `ChatGenerator`. Check out the full list of chat generators [here](https://docs.haystack.deepset.ai/docs/generators)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bfHwOQwycHe"
   },
   "source": [
    "### Build the Pipeline\n",
    "\n",
    "To build a pipeline, add all components to your pipeline and connect them. Create connections from `text_embedder`'s \"embedding\" output to \"query_embedding\" input of `retriever`, from `retriever` to `prompt_builder` and from `prompt_builder` to `llm`. Explicitly connect the output of `retriever` with \"documents\" input of the `prompt_builder` to make the connection obvious as `prompt_builder` has two inputs (\"documents\" and \"question\").\n",
    "\n",
    "For more information on pipelines and creating connections, refer to [Creating Pipelines](https://docs.haystack.deepset.ai/docs/creating-pipelines) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f6NFmpjEO-qb",
    "outputId": "89fd1b48-5189-4401-9cf8-15f55c503676"
   },
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "basic_rag_pipeline = Pipeline()\n",
    "# Add components to your pipeline\n",
    "basic_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "basic_rag_pipeline.add_component(\"retriever\", retriever)\n",
    "basic_rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "basic_rag_pipeline.add_component(\"llm\", chat_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x151dda005650>\n",
       "ðŸš… Components\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - llm: HuggingFaceLocalChatGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - text_embedder.embedding -> retriever.query_embedding (list[float])\n",
       "  - retriever.documents -> prompt_builder.documents (list[Document])\n",
       "  - prompt_builder.prompt -> llm.messages (list[ChatMessage])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, connect the components to each other\n",
    "basic_rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "basic_rag_pipeline.connect(\"retriever\", \"prompt_builder\")\n",
    "basic_rag_pipeline.connect(\"prompt_builder.prompt\", \"llm.messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NqyLhx7O-qc"
   },
   "source": [
    "That's it! Your RAG pipeline is ready to generate answers to questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBAyF5tVO-qc"
   },
   "source": [
    "## Asking a Question\n",
    "\n",
    "When asking a question, use the `run()` method of the pipeline. Make sure to provide the question to both the `text_embedder` and the `prompt_builder`. This ensures that the `{{question}}` variable in the template prompt gets replaced with your specific question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "4e6e97b6d54f4f80bb7e8b25aba8e616",
      "1a820c06a7a049d8b6c9ff300284d06e",
      "58ff4e0603a74978a134f63533859be5",
      "8bdb8bfae31d4f4cb6c3b0bf43120eed",
      "39a68d9a5c274e2dafaa2d1f86eea768",
      "d0cfe5dacdfc431a91b4c4741123e2d0",
      "e7f1e1a14bb740d18827dd78bbe7b2e3",
      "3fda06f905b445a488efdd2dd08c0939",
      "2bc341a780f7498ba9cd475468841bb5",
      "d7218475e23b420a8c03d00ca4ab8718",
      "a694abaf765f4d1b82fa0138e59c6793"
     ]
    },
    "id": "Vnt283M5O-qc",
    "outputId": "d2843a73-3ad5-4daa-8d1e-a58de7aa2bb0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a1c52700a4499492ca71790d26994b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Can you identify the predictions?\"\n",
    "\n",
    "response = basic_rag_pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})\n",
    "\n",
    "print(response[\"llm\"][\"replies\"][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWQN-aoGO-qc"
   },
   "source": [
    "Here are some other example questions to test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OHUQ5xxO-qc"
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"Where is Gardens of Babylon?\",\n",
    "    \"Why did people build Great Pyramid of Giza?\",\n",
    "    \"What does Rhodes Statue look like?\",\n",
    "    \"Why did people visit the Temple of Artemis?\",\n",
    "    \"What is the importance of Colossus of Rhodes?\",\n",
    "    \"What happened to the Tomb of Mausolus?\",\n",
    "    \"How did Colossus of Rhodes collapse?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XueCK3y4O-qc"
   },
   "source": [
    "## What's next\n",
    "\n",
    "ðŸŽ‰ Congratulations! You've learned how to create a generative QA system for your documents with the RAG approach.\n",
    "\n",
    "If you liked this tutorial, you may also enjoy:\n",
    "- [Filtering Documents with Metadata](https://haystack.deepset.ai/tutorials/31_metadata_filtering)\n",
    "- [Preprocessing Different File Types](https://haystack.deepset.ai/tutorials/30_file_type_preprocessing_index_pipeline)\n",
    "- [Creating a Hybrid Retrieval Pipeline](https://haystack.deepset.ai/tutorials/33_hybrid_retrieval)\n",
    "\n",
    "To stay up to date on the latest Haystack developments, you can [subscribe to our newsletter](https://landing.deepset.ai/haystack-community-updates) and [join Haystack discord community](https://discord.gg/haystack).\n",
    "\n",
    "Thanks for reading!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (venv_predictions)",
   "language": "python",
   "name": "venv_predictions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
