{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addd8ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "AXIS_FONT_SIZE = 16\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "# print(notebook_dir)\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.join(notebook_dir, '../'))\n",
    "\n",
    "from text_generation_models import TextGenerationModelFactory\n",
    "from data_acquisition import OpenMeasuresBuilder, OpenMeasuresDirector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82595351",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 800)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde30ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_measures_builder = OpenMeasuresBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "581b6f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data_acquisition.OpenMeasuresBuilder at 0x138884310>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_measures_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca94c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query's URL: http://api.smat-app.com/content?term=will rise&limit=100&site=bluesky&since=2024-01-01&until=2025-02-18&querytype=query_string\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'$type': 'app.bsky.feed.post',\n",
       " 'author': 'did:plc:pb5rjeqxt3vgnkltkdusyibp',\n",
       " 'authorProfile': {'_id': 'did:plc:pb5rjeqxt3vgnkltkdusyibp',\n",
       "  '_index': 'smat-bluesky-users',\n",
       "  'avatar': 'https://cdn.bsky.app/img/avatar/plain/did:plc:pb5rjeqxt3vgnkltkdusyibp/bafkreibzv5ishpgnz32vzsxovunekp2rtzcbz4sqcvjjgqazzdjllhyqwa@jpeg',\n",
       "  'banner': 'https://cdn.bsky.app/img/banner/plain/did:plc:pb5rjeqxt3vgnkltkdusyibp/bafkreibt7fjfnfohjx2cg57mh7n54wcneq43nmewnptdx4yrbo7ht3qvvm@jpeg',\n",
       "  'description': 'The best wrestling. The best stories. The best in Virtual Wrestling since 2013. Subscribe to the YouTube channel for more great content!\\n\\nhttps://www.youtube.com/@DWall4869Gaming',\n",
       "  'did': 'did:plc:pb5rjeqxt3vgnkltkdusyibp',\n",
       "  'display_name': 'DCA Wrestling',\n",
       "  'followers': 16,\n",
       "  'following': 1,\n",
       "  'handle': 'dcawrestling.bsky.social',\n",
       "  'indexed_at': '2024-11-20T01:17:14.904Z',\n",
       "  'lastseents': '2024-11-29T21:28:40.247950',\n",
       "  'posts': 2828},\n",
       " 'cid': 'bafyreiep3cnudiw2prdxycf7hvrzn7uel7sdpr6bwwo472eiytbjdr7y64',\n",
       " 'createdAt': '2024-01-01T00:00:32.000Z',\n",
       " 'embed': None,\n",
       " 'entities': None,\n",
       " 'facets': None,\n",
       " 'labels': None,\n",
       " 'langs': None,\n",
       " 'reply': None,\n",
       " 'tags': None,\n",
       " 'text': 'The following thread contains the matches that are currently official for the Wildcats: Death and Defiance card, the exclusive Wildcats only mega event!\\n\\nAs always, the card is subject to change, and more matches will be announced following Wildcats 206.',\n",
       " 'uri': 'at://did:plc:pb5rjeqxt3vgnkltkdusyibp/app.bsky.feed.post/3lccouzozqr2t',\n",
       " 'lastseents': '2024-12-02T18:19:40.552419'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Configuring parameters\n",
    "terms = \"will win\"\n",
    "limit = 50\n",
    "site = 'bluesky'\n",
    "since = '2024-01-01'\n",
    "until = '2025-02-18' \n",
    "esquery = 'query_string' # Elasticsearch across all fields\n",
    "\n",
    "OpenMeasuresDirector.construct_from_dataset(builder=open_measures_builder, terms=terms, limit=limit, site=site, start_date=since, end_date=until, querytype=esquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # or make a request using requests\n",
    "# r = requests.get(\n",
    "#     url\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c499eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.status_code\n",
    "# data = r.json()\n",
    "# data.keys(), data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119912e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hits = data['hits']['hits']\n",
    "# hits[0]['_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162748e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame([hit['_source'] for hit in hits])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38171db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['text'].to_list()\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11958bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgmf = TextGenerationModelFactory()\n",
    "\n",
    "# Groq Cloud (https://console.groq.com/docs/overview)\n",
    "gemma_29b_generation_model = tgmf.create_instance('gemma2-9b-it') \n",
    "llama_318b_instant_generation_model = tgmf.create_instance('llama-3.1-8b-instant') \n",
    "llama_3370b_versatile_generation_model = tgmf.create_instance('llama-3.3-70b-versatile')  \n",
    "llama_guard_4_12b_generation_model = tgmf.create_instance('meta-llama/llama-guard-4-12b')  \n",
    "\n",
    "models = [gemma_29b_generation_model, llama_318b_instant_generation_model, llama_3370b_versatile_generation_model, llama_guard_4_12b_generation_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c9b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def save_to_json(data, path):\n",
    "    file_number = len([file for file in os.listdir(path) if file.startswith('tiktok_comments-')]) + 1\n",
    "    file_name = f'tiktok_comments-{file_number}.json'\n",
    "    file_path = os.path.join(path, file_name)\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ca872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_predictions_with_llms(sentences: list, notebook_dir: str):\n",
    "    labels = []\n",
    "    batch_size = 50\n",
    "    for batch_idx in tqdm(range(0, len(sentences), batch_size)):\n",
    "        batch = sentences[batch_idx:batch_idx+batch_size]\n",
    "        for sentences_idx in tqdm(range(len(batch))):\n",
    "            sentence = batch[sentences_idx]\n",
    "            prompt = f\"Given this sentence ({sentence}), state if the sentence is a prediction, not a prediction, or not enough information. Also, if it is a prediction, state the prediction domain if any are finance, health, weather, policy, sports, or miscellaneous. Do not explain or provide any other details. Only state prediction, not a prediction, or not enough information.\"\n",
    "            # print(f\"Prompt: {prompt}\")\n",
    "            for model in models:  \n",
    "                input_prompt = model.user(prompt)\n",
    "                # print(input_prompt)  \n",
    "                \n",
    "                raw_text_llm_generation = model.chat_completion([input_prompt])\n",
    "                # print(raw_text_llm_generation)\n",
    "                # print(\"====================================\")\n",
    "                for line in raw_text_llm_generation.split(\"\\n\"):\n",
    "                    # print(line)\n",
    "                    if line.strip():\n",
    "                        labels.append({\"sentence\": sentence, \"model\": model.__name__(), \"label\": line})\n",
    "        save_dir = os.path.dirname(notebook_dir)\n",
    "        save_dir = os.path.join(save_dir, 'data', 'tiktok_comments')\n",
    "        save_to_json(labels, save_dir)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llms_generated = detect_predictions_with_llms(sentences, notebook_dir)\n",
    "llms_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(llms_generated).rename(columns={'sentence': 'Text', 'model': 'Model', 'label': 'Label'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40402427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_predictions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
