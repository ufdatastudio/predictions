{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addd8ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "AXIS_FONT_SIZE = 16\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "# print(notebook_dir)\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.join(notebook_dir, '../'))\n",
    "\n",
    "from data_processing import DataProcessing\n",
    "from data_acquisition import OpenMeasuresDirector\n",
    "from text_generation_models import TextGenerationModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82595351",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 800)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca94c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query's URL: http://api.smat-app.com/content?term=will win&limit=100&site=tiktok_comment&since=2024-01-01&until=2025-02-18&querytype=query_string\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'hits'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m hits_per_site_dfs = []\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m sites:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     hits_for_site_df = \u001b[43mOpenMeasuresDirector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct_from_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mterms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mterms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msite\u001b[49m\u001b[43m=\u001b[49m\u001b[43msite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m=\u001b[49m\u001b[43msince\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m=\u001b[49m\u001b[43muntil\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquerytype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mesquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     hits_per_site_dfs.append(hits_for_site_df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Development/research_labs/uf_ds/predictions/notebook_experiments/../data_acquisition.py:82\u001b[39m, in \u001b[36mOpenMeasuresDirector.construct_from_dataset\u001b[39m\u001b[34m(terms, limit, site, start_date, end_date, querytype)\u001b[39m\n\u001b[32m     80\u001b[39m builder.set_terms(terms)\n\u001b[32m     81\u001b[39m builder.set_query(limit, site, start_date, end_date, querytype)\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_raw_hits\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m df = builder.convert_raw_hits_to_df()\n\u001b[32m     84\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mSite\u001b[39m\u001b[33m'\u001b[39m] = site\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Development/research_labs/uf_ds/predictions/notebook_experiments/../data_acquisition.py:64\u001b[39m, in \u001b[36mOpenMeasuresBuilder.get_raw_hits\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     62\u001b[39m r.status_code\n\u001b[32m     63\u001b[39m data = r.json()\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28mself\u001b[39m.hits = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhits\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mhits\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;28mself\u001b[39m.hits\n",
      "\u001b[31mKeyError\u001b[39m: 'hits'"
     ]
    }
   ],
   "source": [
    "# Configuring parameters\n",
    "terms = \"(nba OR mlb OR nfl) AND (will win)\"\n",
    "terms = \"will win\"\n",
    "terms_for_query = OpenMeasuresDirector\n",
    "limit = 100\n",
    "since = '2024-01-01'\n",
    "until = '2025-02-18' \n",
    "esquery = 'query_string' # Elasticsearch across all fields\n",
    "\n",
    "sites = [\"tiktok_comment\", \"bluesky\", \"truth_social\"]\n",
    "hits_per_site_dfs = []\n",
    "for site in sites:\n",
    "    hits_for_site_df = OpenMeasuresDirector.construct_from_dataset(terms=terms, limit=limit, site=site, start_date=since, end_date=until, querytype=esquery)\n",
    "    hits_per_site_dfs.append(hits_for_site_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5736309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_per_site_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e4e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiktok_df = hits_per_site_dfs[0]\n",
    "bluesocial_df = hits_per_site_dfs[1]\n",
    "true_social_df = hits_per_site_dfs[2]\n",
    "true_social_df['text'] = true_social_df['content_cleaned']\n",
    "true_social_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7588b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_social_df['text'] == true_social_df['content_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11958bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgmf = TextGenerationModelFactory()\n",
    "\n",
    "# Groq Cloud (https://console.groq.com/docs/overview)\n",
    "gemma_29b_generation_model = tgmf.create_instance('gemma2-9b-it') \n",
    "llama_318b_instant_generation_model = tgmf.create_instance('llama-3.1-8b-instant') \n",
    "llama_3370b_versatile_generation_model = tgmf.create_instance('llama-3.3-70b-versatile')  \n",
    "llama_guard_4_12b_generation_model = tgmf.create_instance('meta-llama/llama-guard-4-12b')  \n",
    "\n",
    "models = [gemma_29b_generation_model, llama_318b_instant_generation_model, llama_3370b_versatile_generation_model, llama_guard_4_12b_generation_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c9b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def save_to_json(data, path, site):\n",
    "    site = f\"{site}s\"\n",
    "    print(site)\n",
    "    file_number = len([file for file in os.listdir(path) if file.startswith('{site}-')]) + 1\n",
    "    file_name = f'{site}-{file_number}.json'\n",
    "    file_path = os.path.join(path, file_name)\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ca872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_predictions_with_llms(df: pd.DataFrame, notebook_dir: str, site: str):\n",
    "    labels = []\n",
    "    batch_size = 50\n",
    "    show_data = 1\n",
    "\n",
    "    sentences = DataProcessing.df_to_list(df, col='text')\n",
    "    \n",
    "    for batch_idx in tqdm(range(0, len(sentences), batch_size)):\n",
    "        batch = sentences[batch_idx:batch_idx+batch_size]\n",
    "        for sentences_idx in tqdm(range(len(batch))):\n",
    "            sentence = batch[sentences_idx]\n",
    "            if show_data <=3: \n",
    "                print(f\"       {sentence} --- {site}\")\n",
    "                show_data += 1\n",
    "            prompt = f\"Given this sentence ({sentence}), state if the sentence is a prediction, not a prediction, or not enough information. Also, if it is a prediction, state the prediction domain if any are finance, health, weather, policy, sports, or miscellaneous. Do not explain or provide any other details. Only state prediction, not a prediction, or not enough information.\"\n",
    "            # print(f\"Prompt: {prompt}\")\n",
    "            for model in models:  \n",
    "                input_prompt = model.user(prompt)\n",
    "                # print(input_prompt)  \n",
    "                \n",
    "                raw_text_llm_generation = model.chat_completion([input_prompt])\n",
    "                # print(raw_text_llm_generation)\n",
    "                # print(\"====================================\")\n",
    "                for line in raw_text_llm_generation.split(\"\\n\"):\n",
    "                    # print(line)\n",
    "                    if line.strip():\n",
    "                        labels.append({\"sentence\": sentence, \"model\": model.__name__(), \"label\": line})\n",
    "        save_dir = os.path.dirname(notebook_dir)\n",
    "        save_dir = os.path.join(save_dir, 'data', 'open_measures', site)\n",
    "        save_to_json(labels, save_dir, site)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiktok_site = tiktok_df['Site'][0]\n",
    "llms_generated_for_tiktok_comments = detect_predictions_with_llms(tiktok_df, notebook_dir, tiktok_site)\n",
    "llms_generated_for_tiktok_comments_df = pd.DataFrame(llms_generated_for_tiktok_comments).rename(columns={'sentence': 'Text', 'model': 'Model', 'label': 'Label'})\n",
    "llms_generated_for_tiktok_comments_df['Site'] = tiktok_site\n",
    "llms_generated_for_tiktok_comments_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "llms_generated_for_bluesocial_comments = detect_predictions_with_llms(bluesocial_df, notebook_dir)\n",
    "llms_generated_for_bluesocial_comments_df = pd.DataFrame(llms_generated_for_bluesocial_comments).rename(columns={'sentence': 'Text', 'model': 'Model', 'label': 'Label'})\n",
    "llms_generated_for_bluesocial_comments_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40402427",
   "metadata": {},
   "outputs": [],
   "source": [
    "llms_generated_for_true_social_comments = detect_predictions_with_llms(true_social_df, notebook_dir)\n",
    "llms_generated_for_true_social_comments_df = pd.DataFrame(llms_generated_for_true_social_comments).rename(columns={'sentence': 'Text', 'model': 'Model', 'label': 'Label'})\n",
    "llms_generated_for_true_social_comments_df.head(7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_predictions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
