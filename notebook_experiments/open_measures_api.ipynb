{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd8ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "AXIS_FONT_SIZE = 16\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "# print(notebook_dir)\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.join(notebook_dir, '../'))\n",
    "\n",
    "from data_processing import DataProcessing\n",
    "from real_data_acquisition import OpenMeasuresDirector\n",
    "from text_generation_models import TextGenerationModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82595351",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 800)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eb851f",
   "metadata": {},
   "source": [
    "## Create prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b4983",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_properties = \"\"\"a prediction <p> = (<p_s>, <p_t>, <p_d>, <p_o>), where it consists of the following four properties:\n",
    "\n",
    "    1. <p_s>, any source entity in the sports domain.\n",
    "        - Can be a person (with a name) or a sports domain person such as a sports reporter, sports analyst, sports expert, sports top executive, sports senior level person, etc), civilian.\n",
    "        - Can only be an organization that is associated with the sports prediction.\n",
    "    2. <p_t>, any target entity in the sports domain.\n",
    "\t    - Can be a person (with a name) or a sports person such as a sports reporter, sports analyst, sports expert, sports top executive, sports senior level person, etc).\n",
    "        - Can only be an organization that is associated with the sports prediction.\n",
    "    3. <p_d>, date or time range when <p> is expected to come to fruition or when one should observe the <p>.\n",
    "        - Forecast can range from a second to anytime in the future.\n",
    "        - Answers the questions: \"How far to go out from today?\" or \"Where to stop?\".\n",
    "    4. <p_o>, sports prediction outcome.\n",
    "        - Details relevant details such as outcome, a quantifiable metric, or slope.\n",
    "        - Some example outcomes are the following: score, touchdown, goal, points, win, lose, etc.\n",
    "\"\"\"\n",
    "\n",
    "prediction_structures = \"\"\"Here are how some sports predictions are structured:\n",
    "    - sports template 1: <p_s> forecasts that the <p_o> at <p_t> potentially decrease in <p_d>.\n",
    "    - sports template 2: On <p_d>, <p_s> speculates the <p_o> at <p_t> will likely increase.\n",
    "    - sports template 3: <p_s> predicts on <p_d>, the <p_t> <p_o> may rise.\n",
    "    - sports template 4: According to <p_s>, the <p_o> at <p_t> would fall in <p_d>.\n",
    "    - sports template 5: In <p_d>, <p_s> envisions that <p_t> <p_o> has some probability to remain stable.\n",
    "    - sports template 6: <p_t> <p_o> should stay same <p_d>, according to <p_s>. \n",
    "\"\"\"\n",
    "\n",
    "sport_examples = \"\"\"Here are some corresponding examples of sports predictions:\n",
    "    - sport examples for template 1:\n",
    "        1. Coach Lisa Martinez predicts that the touchdown rate at the Miami Dolphins will fall in 2020 of October.\n",
    "        2. Analyst Mark Johnson forecasts that the goal average at Manchester United will stay the same in November 2025.\n",
    "        3. Ryan forecasts win percentage he has for soccer will go up in 12/25/2016.\n",
    "    - sport examples for template 2:\n",
    "        1. On Sep 20, 2100, Coach Maria Lopez suggests that the score average at the Chicago Bulls is climbing.\n",
    "        2. On 9/12/2025, Analyst David Kim anticipates the touchdown rate at the Kansas City Chiefs will likely surge.\n",
    "        3. On October 8, 2123, Detravious foresees that the win probability he has for rugby is expected to trend downward.\n",
    "    - sport examples for template 3:\n",
    "        1. Coach Elena Ruiz predicts on 9/22/2025, the goal count at Real Madrid will climb.\n",
    "        2. Analyst Marcus Lee forecasts that on Sep 30, 2055, the point average at the Golden State Warriors will be higher.\n",
    "        3. George Jr. estimates that on October 15, 2035, the win ratio for games he has will disimprove.\n",
    "    - sport examples for template 4:\n",
    "        1. According to Coach Sarah Nguyen, the scoring average at the Dallas Mavericks is expected to dip in Sep 2021.\n",
    "        2. According to Analyst Trevor Simmons, the touchdown rate at the Green Bay Packers will increase in 10/2025.\n",
    "        3. According to Manchester United, the win percentage at Manchester United is projected to drop in October 2034.\n",
    "    - sport examples for template 5:\n",
    "        1. In 9/2025, Coach Miguel Torres envisions that the goal average at Paris Saint-Germain will hold steady.\n",
    "        2. In October 2056, Analyst Fiona Bennett anticipates that the win rate at the Toronto Raptors will decrease slightly.\n",
    "        3. In Sep 2086, Calvin foresees that the points per game he has in football will gradually increase.\n",
    "    - sport examples for template 6:\n",
    "        1. The goal count at Liverpool FC will surge in Sep 2012, according to Coach Daniel Alvarez.\n",
    "        2. The win percentage at the Chicago Bears will taper off in October 2025, according to Analyst Priya Sharma.\n",
    "        3. The scoring average on Arnolds footbal team will remain steady in 10/2034, according to Arnold.\n",
    "\"\"\"\n",
    "\n",
    "sport_requirements = \"\"\"- Should be based on real-world sports.\n",
    "    - Suppose the time when <p> was made is during any season of sports.\n",
    "    - Include reports from all sports professionals, coaches, or any type of sport entity.\n",
    "\"\"\"\n",
    "\n",
    "initial_query_string = \"\"\"NBA\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaacd0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Generate a query string using boolean logic and keywords (related to sports predictions) to search a database. I define {prediction_properties} \n",
    "{prediction_structures}\n",
    "{sport_examples}\n",
    "These sports predictions can be found in social media data at large. My task here is to query the site to find relatable sentences (that aren't predictions) and prediction sentences). \n",
    "My initial query string: {initial_query_string}. Don't use brackets to wrap words nor to use quotation marks to wrap words. \n",
    "I need you to generate an improved (better prediction precision) query string taking into consideration the above along with {sport_requirements} \\n Don't generate anything other than a new/imporved query string!\n",
    "\"\"\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3952ae53",
   "metadata": {},
   "source": [
    "## Query for data\n",
    "\n",
    "- For query string, have user define `initial_query_string` or have any LLM in `text_generation_models.py` to generate via the prompt. Either way, the system is set up for user feedback. With this, check the query string (and url for data). If good with it type 'agree'. If not, add details. The details will append to old prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca94c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring parameters\n",
    "terms_for_query = OpenMeasuresDirector\n",
    "query_string_by = 'llm'\n",
    "limit = 1000\n",
    "# Use default since and until: https://api.smat-app.com/docs#/default/content_content_get\n",
    "since = '2024-08-26'\n",
    "until = '2025-02-26' \n",
    "esquery = 'query_string' # Elasticsearch across all fields\n",
    "\n",
    "sites = [\"tiktok_comment\", \"bluesky\", \"truth_social\"]\n",
    "# sites = [\"truth_social\"]\n",
    "hits_per_site_dfs = []\n",
    "for site in sites:\n",
    "    hits_for_site_df = OpenMeasuresDirector.construct_from_dataset(query_string=prompt, query_string_by=query_string_by, limit=limit, site=site, start_date=since, end_date=until, querytype=esquery)\n",
    "    hits_per_site_dfs.append(hits_for_site_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5736309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_per_site_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc847f",
   "metadata": {},
   "source": [
    "- in json i'm saving collect more metadataa - use all cols given from each site\n",
    "1. time for each query using query process with Dr. Grant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e4e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiktok_dfs = hits_per_site_dfs[0]\n",
    "tiktok_df = DataProcessing.concat_dfs(tiktok_dfs)\n",
    "\n",
    "bluesky_dfs = hits_per_site_dfs[1]\n",
    "bluesky_df = DataProcessing.concat_dfs(bluesky_dfs)\n",
    "\n",
    "true_social_dfs = hits_per_site_dfs[2]\n",
    "true_social_df = DataProcessing.concat_dfs(true_social_dfs)\n",
    "true_social_df['text'] = true_social_df['content_cleaned']\n",
    "true_social_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6784f6b5",
   "metadata": {},
   "source": [
    "## Detect Prediction Label with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11958bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgmf = TextGenerationModelFactory()\n",
    "\n",
    "# Groq Cloud (https://console.groq.com/docs/overview)\n",
    "gemma_29b_generation_model = tgmf.create_instance('gemma2-9b-it') \n",
    "llama_318b_instant_generation_model = tgmf.create_instance('llama-3.1-8b-instant') \n",
    "llama_3370b_versatile_generation_model = tgmf.create_instance('llama-3.3-70b-versatile')  \n",
    "llama_guard_4_12b_generation_model = tgmf.create_instance('meta-llama/llama-guard-4-12b')  \n",
    "\n",
    "# models = [gemma_29b_generation_model, llama_318b_instant_generation_model, llama_3370b_versatile_generation_model, llama_guard_4_12b_generation_model]\n",
    "models = [gemma_29b_generation_model, llama_318b_instant_generation_model, llama_guard_4_12b_generation_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ca872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_predictions_with_llms(df: pd.DataFrame, notebook_dir: str, site: str, meta_data: dict):\n",
    "    \"\"\"\n",
    "    Given a sentence, use any LLM from text_generation_models to detect if it's a prediction or not.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Data with the sentences we want to label\n",
    "    notebook_dir : str\n",
    "        The location of this notebook, so we can save files using relative paths\n",
    "    site : str\n",
    "        Source of the data ('tiktok', 'bluesky', 'truth social', 'llm generated', etc).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The mappings of 1 (sentence) : many LLMs\n",
    "        The mappings of 1 LLM : 1 prediction label\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    batch_size = 20\n",
    "    show_data = 1\n",
    "\n",
    "    sentences = DataProcessing.df_to_list(df, col='text')\n",
    "    \n",
    "    for batch_idx in tqdm(range(0, len(sentences), batch_size)):\n",
    "        batch = sentences[batch_idx:batch_idx+batch_size]\n",
    "        for sentences_idx in tqdm(range(len(batch))):\n",
    "            sentence = batch[sentences_idx]\n",
    "            if show_data <=3: \n",
    "                print(f\"\\>>>Sentence: {sentence} --- {site}\\n\")\n",
    "                show_data += 1\n",
    "            prompt = f\"Given this sentence ({sentence}), state if the sentence is a prediction, not a prediction, or not enough information. Also, if it is a prediction, state the prediction domain if any are finance, health, weather, policy, sports, or miscellaneous. Do not explain or provide any other details. Remember, your responses are discrete corresponding to the states in the list; [prediction, not a prediction, not enough information].\"\n",
    "            # print(f\"Prompt: {prompt}\")\n",
    "            for model in models:  \n",
    "                input_prompt = model.user(prompt)\n",
    "                # print(input_prompt)  \n",
    "                \n",
    "                raw_text_llm_generation = model.chat_completion([input_prompt])\n",
    "                # print(raw_text_llm_generation)\n",
    "                # print(\"====================================\")\n",
    "                for line in raw_text_llm_generation.split(\"\\n\"):\n",
    "                    # print(line)\n",
    "                    if line.strip():\n",
    "                        labels.append({\"sentence\": sentence, \"model\": model.__name__(), \"label\": line, \"site\": site})\n",
    "        save_dir = os.path.dirname(notebook_dir)\n",
    "        # print(f\"Site: {site}\")\n",
    "        save_dir = os.path.join(save_dir, 'data', 'open_measures', f\"{site}s\")\n",
    "        DataProcessing.save_to_json(labels, save_dir, site)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiktok_site = tiktok_df['Site'][0]\n",
    "llms_generated_for_tiktok_comments = detect_predictions_with_llms(tiktok_df, notebook_dir, tiktok_site)\n",
    "llms_generated_for_tiktok_comments_df = pd.DataFrame(llms_generated_for_tiktok_comments).rename(columns={'sentence': 'Text', 'model': 'Model', 'label': 'Label'})\n",
    "llms_generated_for_tiktok_comments_df['Site'] = tiktok_site\n",
    "llms_generated_for_tiktok_comments_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "bluesky_site = bluesky_df['Site'][0]\n",
    "# bluesky_site = 'bluesky'\n",
    "llms_generated_for_bluesocial_comments = detect_predictions_with_llms(bluesky_df, notebook_dir, bluesky_site)\n",
    "llms_generated_for_bluesocial_comments_df = pd.DataFrame(llms_generated_for_bluesocial_comments).rename(columns={'sentence': 'Text', 'model': 'Model', 'label': 'Label'})\n",
    "llms_generated_for_bluesocial_comments_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e39d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llms_generated_for_bluesocial_comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40402427",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_social_site = true_social_df['Site'][0]\n",
    "# true_social_site = 'Site'\n",
    "llms_generated_for_true_social_comments = detect_predictions_with_llms(true_social_df, notebook_dir, true_social_site)\n",
    "llms_generated_for_true_social_comments_df = pd.DataFrame(llms_generated_for_true_social_comments).rename(columns={'sentence': 'Text', 'model': 'Model', 'label': 'Label'})\n",
    "llms_generated_for_true_social_comments_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3089d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llms_generated_for_true_social_comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9e76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc06632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_predictions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
