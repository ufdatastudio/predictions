{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db82edd6",
   "metadata": {},
   "source": [
    "# Learning the formal names in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "debfd1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.join(notebook_dir, '../'))\n",
    "\n",
    "from text_generation_models import TextGenerationModelFactory, Llama3170BInstructTextGenerationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69fd23f",
   "metadata": {},
   "source": [
    "- T1: Create an instance of the `TextGenerationModelFactory` class without using a method\n",
    "- T2: Create an instance of the `TextGenerationModelFactory` class with using a method\n",
    "- T3: Create an instance of the `Llama3170BInstructTextGenerationModel` class without using a method\n",
    "- T4: Use the instance in T1 to create an instance of the `Llama3170BInstructTextGenerationModel` class using a method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b43be6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<text_generation_models.TextGenerationModelFactory object at 0x17bf0f8d0>\n",
      "<text_generation_models.Llama3170BInstructTextGenerationModel object at 0x17bf0dfd0>\n",
      "<text_generation_models.Llama3170BInstructTextGenerationModel object at 0x162ef5510>\n",
      "<text_generation_models.Llama3170BInstructTextGenerationModel object at 0x17bf0f790>\n"
     ]
    }
   ],
   "source": [
    "# T1\n",
    "tgmf = TextGenerationModelFactory() # create instance of ABC class\n",
    "print(tgmf)\n",
    "\n",
    "# T2\n",
    "llama_3170b_generation_model_v1 = TextGenerationModelFactory.create_instance(\"llama-3.1-70b-instruct\")\n",
    "print(llama_3170b_generation_model_v1)\n",
    "\n",
    "# T3\n",
    "llama_3170b_generation_model_v2 = Llama3170BInstructTextGenerationModel()\n",
    "print(llama_3170b_generation_model_v2)\n",
    "\n",
    "# T4\n",
    "llama_3170b_generation_model_v3 = tgmf.create_instance('llama-3.1-70b-instruct')\n",
    "print(llama_3170b_generation_model_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be927fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_predictions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
