{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b96bc64c",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd452ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.join(notebook_dir, '../'))\n",
    "\n",
    "import log_files\n",
    "from log_files import LogData\n",
    "from data_processing import DataProcessing\n",
    "from feature_extraction import SpacyFeatureExtraction, TfidfFeatureExtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e30c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 800)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba09a1bc",
   "metadata": {},
   "source": [
    "## Read csv files and load as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec24c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = \"data/prediction_logs\"\n",
    "predictions = True\n",
    "predictions_df = log_files.read_data(notebook_dir, log_file_path, predictions)\n",
    "predictions_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938db367",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = \"data/observation_logs\"\n",
    "predictions = False\n",
    "observations_df = log_files.read_data(notebook_dir, log_file_path, predictions)\n",
    "observations_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686e6649",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Base Sentence'\n",
    "predictions = DataProcessing.df_to_list(predictions_df, col_name)\n",
    "observations = DataProcessing.df_to_list(observations_df, col_name)\n",
    "len(predictions), len(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f238924",
   "metadata": {},
   "source": [
    "## Extract Embeddings with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69e63d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by_prediction_df = pd.read_csv('../data/entailment/entailment-v1.csv')  \n",
    "# by_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8501a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_components = [\"\"]\n",
    "pred_spacy_fe = SpacyFeatureExtraction(predictions_df, \"Base Sentence\")\n",
    "pred_sentence_features = pred_spacy_fe.sentence_feature_extraction()\n",
    "\n",
    "obser_spacy_fe = SpacyFeatureExtraction(observations_df, \"Base Sentence\")\n",
    "obser_sentence_features = obser_spacy_fe.sentence_feature_extraction()\n",
    "\n",
    "len(pred_sentence_features), len(pred_sentence_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_pred_sent_embedding = pred_sentence_features[0]\n",
    "spacy_obser_sent_embedding = obser_sentence_features[0]\n",
    "len(spacy_pred_sent_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f14538",
   "metadata": {},
   "source": [
    "## Extract Embeddings with Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660bf8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "sentences = [] \n",
    "sentences.append(predictions[0])\n",
    "sentences.append(observations[0])\n",
    "print(sentences)\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "# => (3, 384)\n",
    "\n",
    "\n",
    "# spacy_pred_sent_embedding.shape\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n",
    "# tensor([[1.0000, 0.6660, 0.1046],\n",
    "#         [0.6660, 1.0000, 0.1411],\n",
    "#         [0.1046, 0.1411, 1.0000]])\n",
    "\n",
    "sent_transformer_pred_sent_embedding = model.encode(predictions[0])\n",
    "sent_transformer_obser_sent_embedding = model.encode(observations[0])\n",
    "similarities = model.similarity(sent_transformer_pred_sent_embedding, sent_transformer_obser_sent_embedding)\n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793a354",
   "metadata": {},
   "source": [
    "## Extract Embeddings with Bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "def get_bert_embeddings(sentence: str):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    # text = \"Replace me by any text you'd like.\"\n",
    "    encoded_input = tokenizer(sentence, return_tensors='pt')\n",
    "    # Get hidden states from BERT\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "\n",
    "    # Extract embeddings for [CLS] token\n",
    "    sentence_embedding = output.last_hidden_state[:, 0, :].squeeze()\n",
    "\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe802e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pred_sent_embedding = get_bert_embeddings(predictions[0])\n",
    "bert_obser_sent_embedding = get_bert_embeddings(observations[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f15edc",
   "metadata": {},
   "source": [
    "## Extract Embeddings with TF x IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f565a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tfidf_fe = TfidfFeatureExtraction(predictions_df, 'Base Sentence')\n",
    "obser_tfidf_fe = TfidfFeatureExtraction(observations_df, 'Base Sentence')\n",
    "\n",
    "pred_tfidf_df = pred_tfidf_fe.feature_scores(max_features=300)\n",
    "obser_tfidf_df = obser_tfidf_fe.feature_scores(max_features=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa99f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tfidf_df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd545d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pred_embedding = pred_tfidf_df.iloc[:1 , 2:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27e1989",
   "metadata": {},
   "outputs": [],
   "source": [
    "obser_tfidf_df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_obser_embedding = obser_tfidf_df.iloc[:1 , 2:].to_numpy()\n",
    "tfidf_obser_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605bc3ee",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b68a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta_fe = RobertaFeatureExtraction(by_prediction_df, type_of_df=\"Pivot Table\")\n",
    "# predicton_embeddings, observation_embeddings = roberta_fe.entailment_feature_extraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231dd1c0",
   "metadata": {},
   "source": [
    "## Embeddings Similary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6287dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_cosine_similarity(prediction_embeddings: np.array, observation_embeddings: np.array):\n",
    "\n",
    "    # make them (1 Ã— vector_dim) for sklearn\n",
    "    pred_sent_embedding_reshaped = prediction_embeddings.reshape(1, -1)\n",
    "    obser_sent_embedding_reshaped = observation_embeddings.reshape(1, -1)\n",
    "\n",
    "    sim = cosine_similarity(pred_sent_embedding_reshaped, obser_sent_embedding_reshaped)[0, 0]\n",
    "    \n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ecb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_cs_metric = get_cosine_similarity(spacy_pred_sent_embedding, spacy_obser_sent_embedding)\n",
    "sent_tranformer_cs_metric = get_cosine_similarity(sent_transformer_pred_sent_embedding, sent_transformer_obser_sent_embedding)\n",
    "bert_cs_metric = get_cosine_similarity(bert_pred_sent_embedding, bert_obser_sent_embedding)\n",
    "tfidf_cs_metric = get_cosine_similarity(tfidf_pred_embedding, tfidf_obser_embedding)\n",
    "\n",
    "spacy_cs_metric, sent_tranformer_cs_metric, bert_cs_metric, tfidf_cs_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369afa43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_predictions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
