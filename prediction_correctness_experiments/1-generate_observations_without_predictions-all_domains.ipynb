{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc9e2f4",
   "metadata": {},
   "source": [
    "# 1-Generate Observations using LangChain\n",
    "\n",
    "- **Goal:** Use LLMs to generate textual observations for the following domains: financial, health, policy, weather, sports, and miscellaneous. \n",
    "\n",
    "- **Code Structure:** \n",
    "\n",
    "    1. Base template: This is included in every domain's input.\n",
    "    2. Domain template: Vary or specific to a domain.\n",
    "\n",
    "- **Run Notebook:**\n",
    "\n",
    "    1. See README.md for installation and initial setup.\n",
    "    2. Choose models (from `text_generation_models.py`) to generate data.\n",
    "    3. Here in JupyerNotebook, click `Run All` button at top/in menu bar.\n",
    "    4. Reach out if any problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a3b011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orange/ufdatastudios/dj.brinkley/predictions/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from langchain_core.prompts import PipelinePromptTemplate, PromptTemplate\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.join(notebook_dir, '../'))\n",
    "\n",
    "from log_files import LogData\n",
    "from data_processing import DataProcessing\n",
    "from text_generation_models import TextGenerationModelFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f78c6a",
   "metadata": {},
   "source": [
    "## Base Templates for Domain Observations\n",
    "\n",
    "- `{observation_properties}:` These are the variables for each observation.\n",
    "- `{observation_requirements}:` These are to state how outcome observations should be limited to or expressed as.\n",
    "- `{observation_templates}:` These are to give LLMs proper structure/syntax.\n",
    "- `{observation_examples}:` These are to provide LLMs with examples that match the templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d32edc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_observation_template = \"\"\"{observation_properties}\n",
    "\n",
    "{observation_requirements}\n",
    "\n",
    "{observation_templates}\n",
    "\n",
    "{observation_examples}\n",
    "\"\"\"\n",
    "full_observation_prompt = PromptTemplate.from_template(full_observation_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d420e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_properties_template = \"\"\"An observation <o> = (<o_s>, <o_t>, <o_d>, <o_a>), where it consists of the following four properties:\n",
    "\n",
    "    1. <o_s>, any source entity in the {observation_domain} domain.\n",
    "        - Can be a person (with a name) or a {observation_domain} person such as a {observation_domain} reporter, {observation_domain} analyst, {observation_domain} expert, {observation_domain} top executive, {observation_domain} senior level person, etc, civilian.\n",
    "        - Can only be an organization that is associated with the {observation_domain} observation.\n",
    "    2. <o_t>, any target entity in the {observation_domain} domain.\n",
    "        - Can be a person (with a name) or a {observation_domain} person such as a {observation_domain} reporter, {observation_domain} analyst, {observation_domain} expert, {observation_domain} top executive, {observation_domain} senior level person, etc).\n",
    "        - Can only be an organization that is associated with the {observation_domain} observation.\n",
    "    3. <o_d>, date or time range when <o> is expected to come to fruition or when one should observe the <o>.\n",
    "        - Forecast can range from a second to anytime in the future.\n",
    "        - Answers the questions: \"How far to go out from today?\" or \"Where to stop?\".\n",
    "    4. <o_a>, {observation_domain} observation output.\n",
    "        - Characteristics of a domain-specific outputs such as various quantifiable metrics relevant to the {observation_domain} domain.\n",
    "        - Some examples are {observation_domain_output}.\n",
    "    \"\"\"\n",
    "observation_properties_prompt = PromptTemplate.from_template(observation_properties_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95548954",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_requirements_template = \"\"\"Requirements to use for each observation:\n",
    "\n",
    "    - Should be based on real-world {observation_domain} data and not hallucinate.\n",
    "    - Must be a simple sentence (observation) (and NOT compounding using \"and\" or \"or\").\n",
    "    - Should diversify all four properties of the observation (<o>) as in change and not use same for <o_s>, <o_t>, <o_d>, <o_a>.\n",
    "    - The observation should be unique and not repeated.\n",
    "    - Do not number the observations.\n",
    "    - In front of every observation, put the template number in the format of \"T1:\", \"T2:\", etc. and do not number them like \"1.\", \"2.\", etc. Should have template number and generated prediction matching.\n",
    "    - Must not generate, \"template 1:..., template 2:..., etc\" or anything similar and don't generate \"T1:\", \"T2:\", etc by itself.    \n",
    "    - Must not generate, \"Here are {observations_N} unique observation based on the provided templates or anything similar.\n",
    "    - Change how the current date (<o_d>) written in the observation with examples of (1) Wednesday, August 21, 2024; (2) Wed, August 21, 2024; (3) 08/21/2024; (4) 08/21/2024; (5) 21/08/2024; (6) 21 August 2024; (7) 2024/08/21; (8) 2024-08-21; (9) August 21, 2024; (10) Aug 21, 2024; (11) 21 August 2024, (12) 21 Aug 2024, Q3 of 2027, 2029 of Q3, etc.\n",
    "    - Do not use any of the examples in the prompt.\n",
    "    - Do not put template number on line by itself. Always pair with an observation.\n",
    "    - Disregard brackets: \"<>\"\n",
    "    - Do not use person name of entity name more than once as in don't use name Joe as both the <o_s> and <o_t>, unless like Mr. Sach and Goldman Sach or Mr. Sam Walton and Sam's Club, etc.\n",
    "    - The source entity (<o_s>) is rarely the same as the target entity (<o_t>) and if same, the <o_s> is making a observation on itself in the <o_t>.\n",
    "    - Should variate the slope of rose/increased/as much as, fell/decreased/as little as, changed, stayed stable, high/low chance/probability/degree of, etc.\n",
    "    - Must be past tense as in already occurred and not future tense.\n",
    "    - Must not use will, would, be going to, should, etc. in the observation.\n",
    "    - Do not include \"{observation_domain} template 1:\t\"\n",
    "    - Should variate the past tense prediction verbs such as observed, saw, noted, etc.\n",
    "    \"\"\"\n",
    "observation_requirements_prompt = PromptTemplate.from_template(observation_requirements_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07129ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_templates_template = \"\"\"Here are some {observation_domain} templates:\n",
    "\n",
    "    - {observation_domain} template 1: <o_s> observed that the <o_a> at <o_t> had remained stable in <o_d>.\n",
    "    - {observation_domain} template 2: On <o_d>, <o_s> monitored the <o_a> at <o_t> changed.\n",
    "    - {observation_domain} template 3: <o_s> noted on <o_d>, the <o_t> <o_a> fell.\n",
    "    - {observation_domain} template 4: According to <o_s>, the <o_a> at <o_t> rose <o_d>.\n",
    "    - {observation_domain} template 5: In <o_d>, <o_s> envisioned that <o_t> <o_a> decreased.\n",
    "    - {observation_domain} template 6: <o_t> <o_a> increased <o_d>, according to <o_s>.  \n",
    "\"\"\"\n",
    "observation_templates_prompt = PromptTemplate.from_template(observation_templates_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e559ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_examples_template = \"\"\"Here are some examples of {observation_domain} observations:\n",
    "{domain_examples}\n",
    "\n",
    "With the above (observation with four properties, requirements, templates, and examples), generate a unique set of {observations_N} observation per template following the examples. \n",
    "Think from the perspective of an {observation_domain} analyst, expert, top executive, or senior level person and even a college student, professional, research advisor, etc.\n",
    "\"\"\"\n",
    "observation_examples_prompt = PromptTemplate.from_template(observation_examples_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad59deb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/6864376/ipykernel_2039181/1258429815.py:7: LangChainDeprecationWarning: This class is deprecated. Please see the docstring below or at the link for a replacement option: https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.pipeline.PipelinePromptTemplate.html\n",
      "  pipeline_prompt = PipelinePromptTemplate(\n"
     ]
    }
   ],
   "source": [
    "observation_input_prompts = [\n",
    "    (\"observation_properties\", observation_properties_prompt),\n",
    "    (\"observation_requirements\", observation_requirements_prompt),\n",
    "    (\"observation_templates\", observation_templates_prompt),\n",
    "    (\"observation_examples\", observation_examples_prompt),\n",
    "]\n",
    "pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=full_observation_prompt, pipeline_prompts=observation_input_prompts\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099b1ddb",
   "metadata": {},
   "source": [
    "## Specific Templates for Domain Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f51c614",
   "metadata": {},
   "source": [
    "- For now, generating 1 observation per template. From here, I'll try 3 and increase by increments/multiples of 3.\n",
    "\n",
    "- With 1 observation per template,\n",
    "    - 1 observation per template x 6 examples per domain so 6 observations per domain\n",
    "    - 6 observations per domain x 4 domains = 24 observations per model\n",
    "    - 24 observations per model x 2 models = 48 observations across all models\n",
    "    - 48 observations across all models x 2 batches = 96 across all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6a146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_per_template = 1\n",
    "generate_N_observations_per_template = 1 * examples_per_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd133022",
   "metadata": {},
   "source": [
    "### Template for Financial observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e2ddf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An observation <o> = (<o_s>, <o_t>, <o_d>, <o_a>), where it consists of the following four properties:\n",
      "\n",
      "    1. <o_s>, any source entity in the financial domain.\n",
      "        - Can be a person (with a name) or a financial person such as a financial reporter, financial analyst, financial expert, financial top executive, financial senior level person, etc, civilian.\n",
      "        - Can only be an organization that is associated with the financial observation.\n",
      "    2. <o_t>, any target entity in the financial domain.\n",
      "        - Can be a person (with a name) or a financial person such as a financial reporter, financial analyst, financial expert, financial top executive, financial senior level person, etc).\n",
      "        - Can only be an organization that is associated with the financial observation.\n",
      "    3. <o_d>, date or time range when <o> is expected to come to fruition or when one should observe the <o>.\n",
      "        - Forecast can range from a second to anytime in the future.\n",
      "        - Answers the questions: \"How far to go out from today?\" or \"Where to stop?\".\n",
      "    4. <o_a>, financial observation output.\n",
      "        - Characteristics of a domain-specific outputs such as various quantifiable metrics relevant to the financial domain.\n",
      "        - Some examples are stock price, net profit, revenue, operating cash flow, research and development expenses, operating income, gross profit..\n",
      "    \n",
      "\n",
      "Requirements to use for each observation:\n",
      "\n",
      "    - Should be based on real-world financial data and not hallucinate.\n",
      "    - Must be a simple sentence (observation) (and NOT compounding using \"and\" or \"or\").\n",
      "    - Should diversify all four properties of the observation (<o>) as in change and not use same for <o_s>, <o_t>, <o_d>, <o_a>.\n",
      "    - The observation should be unique and not repeated.\n",
      "    - Do not number the observations.\n",
      "    - In front of every observation, put the template number in the format of \"T1:\", \"T2:\", etc. and do not number them like \"1.\", \"2.\", etc. Should have template number and generated prediction matching.\n",
      "    - Must not generate, \"template 1:..., template 2:..., etc\" or anything similar and don't generate \"T1:\", \"T2:\", etc by itself.    \n",
      "    - Must not generate, \"Here are 1 unique observation based on the provided templates or anything similar.\n",
      "    - Change how the current date (<o_d>) written in the observation with examples of (1) Wednesday, August 21, 2024; (2) Wed, August 21, 2024; (3) 08/21/2024; (4) 08/21/2024; (5) 21/08/2024; (6) 21 August 2024; (7) 2024/08/21; (8) 2024-08-21; (9) August 21, 2024; (10) Aug 21, 2024; (11) 21 August 2024, (12) 21 Aug 2024, Q3 of 2027, 2029 of Q3, etc.\n",
      "    - Do not use any of the examples in the prompt.\n",
      "    - Do not put template number on line by itself. Always pair with an observation.\n",
      "    - Disregard brackets: \"<>\"\n",
      "    - Do not use person name of entity name more than once as in don't use name Joe as both the <o_s> and <o_t>, unless like Mr. Sach and Goldman Sach or Mr. Sam Walton and Sam's Club, etc.\n",
      "    - The source entity (<o_s>) is rarely the same as the target entity (<o_t>) and if same, the <o_s> is making a observation on itself in the <o_t>.\n",
      "    - Should variate the slope of rose/increased/as much as, fell/decreased/as little as, changed, stayed stable, high/low chance/probability/degree of, etc.\n",
      "    - Must be past tense as in already occurred and not future tense.\n",
      "    - Must not use will, would, be going to, should, etc. in the observation.\n",
      "    - Do not include \"financial template 1:\t\"\n",
      "    - Should variate the past tense prediction verbs such as observed, saw, noted, etc.\n",
      "    \n",
      "\n",
      "Here are some financial templates:\n",
      "\n",
      "    - financial template 1: <o_s> observed that the <o_a> at <o_t> had remained stable in <o_d>.\n",
      "    - financial template 2: On <o_d>, <o_s> monitored the <o_a> at <o_t> changed.\n",
      "    - financial template 3: <o_s> noted on <o_d>, the <o_t> <o_a> fell.\n",
      "    - financial template 4: According to <o_s>, the <o_a> at <o_t> rose <o_d>.\n",
      "    - financial template 5: In <o_d>, <o_s> envisioned that <o_t> <o_a> decreased.\n",
      "    - financial template 6: <o_t> <o_a> increased <o_d>, according to <o_s>.  \n",
      "\n",
      "\n",
      "Here are some examples of financial observations:\n",
      "\n",
      "   - financial examples for template 1:\n",
      "      1. Joseph, the young entrepreneur, observed that the revenue at FUBU (his parents clothing line) had increased for Q3 2028.\n",
      "      2. BJ monitored the operating cash flow at UF's school of Engineering  and saw it decreased in 05/2021.\n",
      "      3. An fresh investor noticed the ETFs in his portfolio exponentially grew from Apr 7, 1997 to Apr 7, 2009.\n",
      "   - financial examples for template 2:\n",
      "      1. On March 15, 2025 to March 16, 2026, Goldman Sachs observed that the interest rates at the Federal Reserve rose.\n",
      "      2. On April 2, 2000, Fidelity oted that the valuation of the market value at Tesla fell.\n",
      "      3. On 1/23/2012, Chase analysts recorded that their stock prices increased.\n",
      "   - financial examples for template 3:\n",
      "      1. Charles Schwab observed that on 3/2/2035, the NASDAQ composite index climbed moderately.\n",
      "      2. BlackRock documented that on April 22, 2028, the value of Bitcoin rose sharply.\n",
      "      3. Morgan Stanley reported that on the 3rd of May, 2025, their stock price declined.\n",
      "   - financial examples for template 4:\n",
      "      1. According to Chase Bank, the returns at emerging market equities gone down in May 2035.\n",
      "      2. According to Ryan, the revenue at Meta Platforms dropped in Q2 2055.\n",
      "      3. According to Apple, the trading volume it had increased on 1/2/2027.\n",
      "   - financial examples for template 5:\n",
      "      1. On Q1 2012, Wells Fargo noted that U.S. Treasury yields remained stable.\n",
      "      2. On 5/5/2002, Bob detected that the inflation rate at Wells Fargo remained stable\n",
      "      3. On June 1997, Rob recorded that the stocks he held remained stable.\n",
      "   - financial examples for template 6:\n",
      "      1. Apple stock price decreased in Quarter 3 of 2046, according to Roger.\n",
      "      2. The NASDAQ index rose in 7/5/2060, according to Bank of America.\n",
      "      3. The stock price increased in July 1999, according to my records.\n",
      " \n",
      "\n",
      "With the above (observation with four properties, requirements, templates, and examples), generate a unique set of 1 observation per template following the examples. \n",
      "Think from the perspective of an financial analyst, expert, top executive, or senior level person and even a college student, professional, research advisor, etc.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "financial_outputs = \"\"\"stock price, net profit, revenue, operating cash flow, research and development expenses, operating income, gross profit.\"\"\"\n",
    "financial_requirements = \"\"\"- Should be based on real-world financial earnings reports.\n",
    "   - Suppose the time when <o> was made is during any earning season.\n",
    "   - Include stocks from all sectors such as consumer staples, energy, finance, health care, industrials, materials, media, real estate, retail, technology, utilities, defense, etc.\n",
    "   - Include the US Dollar sign ($) before or USD after the amount of the financial output.\"\"\"\n",
    "financial_examples = \"\"\"\n",
    "   - financial examples for template 1:\n",
    "      1. Joseph, the young entrepreneur, observed that the revenue at FUBU (his parents clothing line) had increased for Q3 2028.\n",
    "      2. BJ monitored the operating cash flow at UF's school of Engineering  and saw it decreased in 05/2021.\n",
    "      3. An fresh investor noticed the ETFs in his portfolio exponentially grew from Apr 7, 1997 to Apr 7, 2009.\n",
    "   - financial examples for template 2:\n",
    "      1. On March 15, 2025 to March 16, 2026, Goldman Sachs observed that the interest rates at the Federal Reserve rose.\n",
    "      2. On April 2, 2000, Fidelity oted that the valuation of the market value at Tesla fell.\n",
    "      3. On 1/23/2012, Chase analysts recorded that their stock prices increased.\n",
    "   - financial examples for template 3:\n",
    "      1. Charles Schwab observed that on 3/2/2035, the NASDAQ composite index climbed moderately.\n",
    "      2. BlackRock documented that on April 22, 2028, the value of Bitcoin rose sharply.\n",
    "      3. Morgan Stanley reported that on the 3rd of May, 2025, their stock price declined.\n",
    "   - financial examples for template 4:\n",
    "      1. According to Chase Bank, the returns at emerging market equities gone down in May 2035.\n",
    "      2. According to Ryan, the revenue at Meta Platforms dropped in Q2 2055.\n",
    "      3. According to Apple, the trading volume it had increased on 1/2/2027.\n",
    "   - financial examples for template 5:\n",
    "      1. On Q1 2012, Wells Fargo noted that U.S. Treasury yields remained stable.\n",
    "      2. On 5/5/2002, Bob detected that the inflation rate at Wells Fargo remained stable\n",
    "      3. On June 1997, Rob recorded that the stocks he held remained stable.\n",
    "   - financial examples for template 6:\n",
    "      1. Apple stock price decreased in Quarter 3 of 2046, according to Roger.\n",
    "      2. The NASDAQ index rose in 7/5/2060, according to Bank of America.\n",
    "      3. The stock price increased in July 1999, according to my records.\n",
    " \"\"\"\n",
    "financial_input_dict = {\n",
    "    \"observation_domain\": \"financial\",\n",
    "    \"observation_domain_output\": financial_outputs,\n",
    "    \"domain_requirements\": financial_requirements,\n",
    "    \"domain_examples\": financial_examples,\n",
    "    \"observations_N\": generate_N_observations_per_template\n",
    "}\n",
    "financial_prompt_output = pipeline_prompt.format(**financial_input_dict)\n",
    "print(financial_prompt_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf6df7a",
   "metadata": {},
   "source": [
    "###  Template for Health observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d766f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_outputs = \"\"\"obesity rates, prevalence of chronic illnesses, average physical activity levels, nutritional intake, etc.\"\"\"\n",
    "health_requirements = \"\"\"- Should be based on real-world health reports.\n",
    "   - Suppose the time when <o> was made is during any season such as flu season, allergy season, pandemic, epidemic, etc.\n",
    "   - Include reports from all Health organization, researcher, doctor, physical therapist, physician assistant, nurse practictioners, fitness expert, etc.\"\"\"\n",
    "health_examples = \"\"\"\n",
    "   - health examples for template 1:\n",
    "      1. Florida caught that the patients' blood glucose at all hospitals in Florida improved from Q1 2021 to Q3 2021.\n",
    "      2. Nurse John observed that the heart rate in patients at Alaska's General Hospital had stabilized from 2023 January to 2023 Dec.\n",
    "      3. I noted the number of visits my patients in Piscataway, NJ decreased from start of week to end of week.\n",
    "   - health examples for template 2:\n",
    "      1. On 3/14/2017, the CDC observed that vaccination adherence at urban elementary schools changed.\n",
    "      2. On September 8, 2034, Sam reported that the calcium intake at prenatal clinics in the Midwest increased.\n",
    "      3. On the 12th of November, 2020, I recorded that hypertension rates at the state level decreased.\n",
    "   - health examples for template 3:\n",
    "      1. The NIH reported that on 6/22/2042, public participation in mental health workshops declined.\n",
    "      2. Alex identified that on October 19, 2074, the diabetes prevalence at regional hospitals decreased.\n",
    "      3. I noted that on January 3, 2025, the daily step count of individuals significantly changed.\n",
    "   - health examples for template 4:\n",
    "      1. According to the study conducted at UF, the hydration levels at Florida middle schools dropped in Spring 2035.\n",
    "      2. According to Joe, the fiber intake at the university cafeterias fell on 10/14/2055.\n",
    "      3. According to my study of wellness habits, his average sleep duration decreased in Q4, 2029.\n",
    "   - health examples for template 5:\n",
    "      1. On 5/2/2028, Dr. Maria Thompson tracked that national cholesterol averages declined.\n",
    "      2. In July 2051, Professor James Liu recorded that aerobic capacity among children increased.\n",
    "      3. In Q1 2027, Dr. Aisha Reynolds observed that her protein consumption remained stable.\n",
    "   - health examples for template 6:\n",
    "      1. Physical activity levels among seniors fell on 8/7/2015, according to Dr. Elena Morales’ study.\n",
    "      2. Nutritional awareness in South America became more evident on the 3rd of September 2016, according to me.\n",
    "      3. Sarah's flu vaccination participation rose in early Q4 2024, according to Sarah’s records.\n",
    "   \"\"\"\n",
    "health_input_dict = {\n",
    "    \"observation_domain\": \"health\",\n",
    "    \"observation_domain_output\": health_outputs,\n",
    "    \"domain_requirements\": health_requirements,\n",
    "    \"domain_examples\": health_examples,\n",
    "    \"observations_N\": generate_N_observations_per_template\n",
    "}\n",
    "health_prompt_output = pipeline_prompt.format(**health_input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0959d8",
   "metadata": {},
   "source": [
    "###  Template for Policy observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79c8c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_outputs = \"\"\"election outcomes, economic reforms, legislative impacts.\"\"\"\n",
    "policy_requirements = \"\"\"- Should be based on real-world policy reports.\n",
    "    - Suppose the time when <o> was made is during an election cycle or non-election cycles.\n",
    "    - Include policies & laws, from all sectors such as consumer staples, energy, finance, health care, industrials, materials, media, real estate, retail, technology, utilities, defense, etc.\"\"\"\n",
    "policy_examples = \"\"\"\n",
    "   - policy examples for template 1:\n",
    "      1. Local journalist, Aaron, identified economic reforms in Thomson, GA rose jan 2033.\n",
    "      2. Policy analyst, Michael (Ph.D), remarked that the home tax in Austin, TX had increased on 7/9/28.\n",
    "      3. Policy maker Sarah noted that company employment rates in her city San Francisco had risen from Q1 2025 to Q3 2025.\n",
    "   - policy examples for template 2:\n",
    "      1. On 4/5/2030, the Brookings Institution noted that lobbying intensity at swing districts stayed stable.\n",
    "      2. On March 3, 2021, the International Monetary Fund observed that trade policy compliance at Southeast Asian nations rose.\n",
    "      3. On the 18th of July, 2026, policy analyst Rachel Kim reported that tax incentives in her clean energy firms decreased.\n",
    "   - policy examples for template 3:\n",
    "      1. Representative Angela Brooks observed that on October 15, 2027, the infrastructure funding distribution remained stable.\n",
    "      2. Economist Dr. Henry Zhao recorded that on 6/4/2023, the property tax rate in urban zones increased.\n",
    "      3. Senator Michael Greene noted that on November 3, 2022, his campaign donations in rural counties declined.\n",
    "   - policy examples for template 4:\n",
    "      1. According to state representate Alicia Ramirez, civic participation at state-level agencies increased in early 2018.\n",
    "      2. According to Thomas Nguyen, regulatory support in the transportation sector fell in Q1 2034.\n",
    "      3. According to policy advisor Natalie Chen, the job creation rate at her nonprofit coalition remained stable in October 2026.\n",
    "   - policy examples for template 5:\n",
    "      1. On 3/2/2024, Senator Jordan Ellis observed that educational grant spending stayed stable.\n",
    "      2. In March 2026, economist Dr. Priya Nandakumar reported that food assistance claims in urban counties increased.\n",
    "      3. In Q4 of 2022, policy strategist Kevin Adler noted that his green tech subsidy approvals declined.\n",
    "   - policy examples for template 6:\n",
    "      1. Renewable energy investments inflated in Q3 2023, according to Dr. Elena Foster.\n",
    "      2. Housing subsidies decreased in December 2051, according to Senator Marcus Lee.\n",
    "      3. My advocacy involvement in education reform stayed the same on 9/5/2020, noted by me.\n",
    "   \"\"\"\n",
    "policy_input_dict = {\n",
    "    \"observation_domain\": \"policy\",\n",
    "    \"observation_domain_output\": policy_outputs,\n",
    "    \"domain_requirements\": policy_requirements,\n",
    "    \"domain_examples\": policy_examples,\n",
    "    \"observations_N\": generate_N_observations_per_template\n",
    "}\n",
    "policy_prompt_output = pipeline_prompt.format(**policy_input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad02107",
   "metadata": {},
   "source": [
    "###  Template for Weather observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc4bdd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_outputs = \"\"\"temperature, precipitation, wind speed, humidity, etc.\"\"\"\n",
    "weather_requirements = \"\"\"- Should be based on real-world weather reports.\n",
    "    - Suppose the time when <o> was made is during any season and any location (ie: Florida known for hurricanes, California known for wildfires, etc).\n",
    "    - Include reports from all meteorologists, weather organizations, or any type of weather entity.\"\"\"\n",
    "weather_examples = \"\"\"\n",
    "   - weather examples for template 1:\n",
    "        1. The street cleaner monitored the snow in Minnesota increase from 12/8/9 to 2/8/10.\n",
    "        2. Jade, a farmer, caught that the rainfall in Kansas had decreased at midnight.\n",
    "        3. I identified the wind speed in North Dakota picked up drastically today.\n",
    "   - weather examples for template 2:\n",
    "      1. On 1/1/2024, Meteorologist Lisa Park reported that the temperature at San Diego rose.\n",
    "      2. On 2023 Aug 15, Dr. Mark Williams noted that the air pressure at Dallas became lower.\n",
    "      3. On October 3, 2025, Chicago’s meteorological team recorded that the wind gusts in the suburbs remained stable.\n",
    "   - weather examples for template 3:\n",
    "      1. Anna Lee, PH.D observed that in May 2024, the dew point at Denver decreased.\n",
    "      2. Meteorologist John Roberts noted that on August 12, 2022, the wind chill in New York increased.\n",
    "      3. I recorded that on 6/9/2023, the humidity at Coral Gables stayed the same.\n",
    "   - weather examples for template 4:\n",
    "      1. According to Me, the heat index at Philadelphia rose in 07/2023.\n",
    "      2. According to Meteorologist Jake Wilson, the rainfall levels at Portland stayed consistent on March 18, 2022.\n",
    "      3. According to Dylan, the wind speed at his cabin dropped on 11/6/2025.\n",
    "   - weather examples for template 5:\n",
    "      1. On December 3, 2023, Meteorologist Claire Thompson noted that the cloud coverage in Buffalo increased.\n",
    "      2. On 4/28/2022, I observed that the humidity at Tampa remained stable.\n",
    "      3. During the month of September, the Los Angeles Weather Bureau recorded that the precipitation levels in Pasadena fell.\n",
    "   - weather examples for template 6:\n",
    "      1. Temperature in Las Vegas rose in July 2023, according to Meteorologist Nina Patel.\n",
    "      2. Humidity in Austin declined on August 3, 2024, according to Dr. Kevin Morales.\n",
    "      3. Wind speed in Key West remained stable on 10/9/2023, according to the Florida Weather Bureau.\n",
    "   \"\"\"\n",
    "weather_input_dict = {\n",
    "    \"observation_domain\": \"weather\",\n",
    "    \"observation_domain_output\": weather_outputs,\n",
    "    \"domain_requirements\": weather_requirements,\n",
    "    \"domain_examples\": weather_examples,\n",
    "    \"observations_N\": generate_N_observations_per_template\n",
    "}\n",
    "weather_prompt_output = pipeline_prompt.format(**weather_input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4311d7d7",
   "metadata": {},
   "source": [
    "###  Template for Sports observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab0a5699",
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_outputs = \"\"\"score, touchdown, goal, points, win, lose, etc.\"\"\"\n",
    "sport_requirements = \"\"\"- Should be based on real-world sports.\n",
    "    - Suppose the time when $p$ was made is during any season of sports.\n",
    "    - Include reports from all sports professionals, coaches, or any type of sport entity.\"\"\"\n",
    "sport_examples = \"\"\"\n",
    "    - sport examples for template 1:\n",
    "        1. Coach Lisa Martinez observed that the assist rate at the New York Knicks dropped in March 2022.\n",
    "        2. Analyst Mark Johnson noted that the batting average at the Boston Red Sox remained stable in July 2023.\n",
    "        3. Ryan recorded that the win percentage he had in tennis improved on 5/10/2019.\n",
    "    - sport examples for template 2:\n",
    "        1. On May 18, 2023, Coach Maria Lopez observed that the pass completion rate at the Denver Broncos increased.\n",
    "        2. On 11/5/2021, Analyst David Kim noted that the home run count at the New York Yankees rose sharply.\n",
    "        3. On August 12, 2024, Detravious recorded that the serve accuracy he had in volleyball declined.\n",
    "    - sport examples for template 3:\n",
    "        1. Coach Elena Ruiz observed that on 9/22/2022, the foul count at FC Barcelona increased.\n",
    "        2. Analyst Marcus Lee noted that on June 10, 2021, the shot accuracy at the LA Lakers dropped.\n",
    "        3. George Jr. recorded that on November 2, 2023, the save percentage he had in hockey stayed consistent.\n",
    "    - sport examples for template 4:\n",
    "        1. According to Coach Sarah Nguyen, the three-point percentage at the Houston Rockets decreased in February 2024.\n",
    "        2. According to Analyst Trevor Simmons, the rushing yards at the Buffalo Bills increased on 12/18/2023.\n",
    "        3. According to Real Madrid staff, the win ratio at Real Madrid improved in April 2022.\n",
    "    - sport examples for template 5:\n",
    "        1. In January 2021, Coach Miguel Torres observed that the tackle success rate at Juventus stayed stable.\n",
    "        2. In March 2030, Analyst Fiona Bennett recorded that the win rate at the Los Angeles Clippers decreased slightly.\n",
    "        3. In July 2023, Calvin noted that the goals per match he had in soccer increased steadily.\n",
    "    - sport examples for template 6:\n",
    "        1. The corner kick count at Liverpool FC surged in March 2016, according to Me.\n",
    "        2. The win percentage at the San Francisco 49ers dropped slightly in October 2023, according to Analyst Priya Sharma.\n",
    "        3. The shot accuracy on Arnold's basketball team remained steady in 11/2022, according to Arnold.\n",
    "    \"\"\"\n",
    "sport_input_dict = {\n",
    "    \"observation_domain\": \"sport\",\n",
    "    \"observation_domain_output\": sport_outputs,\n",
    "    \"domain_requirements\": sport_requirements,\n",
    "    \"domain_examples\": sport_examples,\n",
    "    \"observations_N\": generate_N_observations_per_template\n",
    "}\n",
    "sport_prompt_output = pipeline_prompt.format(**sport_input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f5d213",
   "metadata": {},
   "source": [
    "###  Template for miscellaneous observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a1dbca",
   "metadata": {},
   "source": [
    "- Too many `2021`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b6fd6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "miscellaneous_outputs = \"\"\"These outputs will take in any random output relating ot any real world situation.\"\"\"\n",
    "miscellaneous_requirements = \"\"\"These outputs will take in any random output relating ot any real world situation.\n",
    "    - Suppose the time when <p> was made is during any season or part of the year.\n",
    "    - Include any type of entity..\"\"\"\n",
    "miscellaneous_examples = \"\"\"\n",
    "    - miscellaneous examples for template 1:\n",
    "        1. Professor Laura White observed that attendance rates at Midtown University declined in April 2002.\n",
    "        2. Chef Alberto Reyes noted that the sourness of the lemon tart at his kitchen increased in summer 2020.\n",
    "        3. Gaming expert Jordan Lee recorded that the probability of drawing a queen during poker night rose in March 2023.\n",
    "    - miscellaneous examples for template 2:\n",
    "        1. On 4/12/2018, Professor Maria Jackson observed that class participation at Highschool rose steadily.\n",
    "        2. On November 22, 2023, Chef Gabrielle Moreau recorded that the burger flavor at Burger King increased.\n",
    "        3. On August 6, 2005, Oliver Cheng noted that the chance of rolling an odd number stayed stable.\n",
    "    - miscellaneous examples for template 3:\n",
    "        1. Dr. Sarah McDonald observed that on Dec 15, 2022, library usage at Jefferson High increased.\n",
    "        2. Coach Tony Roberts noted that on 6/30/2021, the sprint times for the Track Club improved.\n",
    "        3. Sarah recorded that on February 12, 2023, the odds of drawing an ace from the deck dropped.\n",
    "    - miscellaneous examples for template 4:\n",
    "        1. According to Coach Andre Collins, the turnover rate for the Basketball Club increased in March 3, 2019.\n",
    "        2. According to Chef Emily Gonzalez, the creaminess of the cheesecake at The Velvet Crumb dropped in late Winter 2020.\n",
    "        3. According to game analyst Tom Spencer, the frequency of triple rolls in Settlers of Catan increased in 2023.\n",
    "    - miscellaneous examples for template 5:\n",
    "        1. In Summer 2021, Professor Kim Tansley observed that dropout rates at Lakefield College remained consistent.\n",
    "        2. In 3/2017, Chef Michael Harris reported that customer satisfaction at Chipotle improved slightly.\n",
    "        3. In May of 2004, I recorded that the randomness of coin flips during the simulation remained unchanged.\n",
    "    - miscellaneous examples for template 6:\n",
    "        1. Lecture attendance improved in Spring 2023, according to Professor B.T.\n",
    "        2. The texture of the sourdough crust changed in September 2022, according to Chef Veronica Miller.\n",
    "        3. FD's probability of rolling a critical hit remained stable on 2/17/2024, according to FD.\n",
    "    \"\"\"\n",
    "miscellaneous_input_dict = {\n",
    "    \"observation_domain\": \"miscellaneous\",\n",
    "    \"observation_domain_output\": miscellaneous_outputs,\n",
    "    \"domain_requirements\": miscellaneous_requirements,\n",
    "    \"domain_examples\": miscellaneous_examples,\n",
    "    \"observations_N\": generate_N_observations_per_template\n",
    "}\n",
    "miscellaneous_prompt_output = pipeline_prompt.format(**miscellaneous_input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012d23d7",
   "metadata": {},
   "source": [
    "## Generate observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a598b119",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Text Generation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6f573fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tgmf = TextGenerationModelFactory()\n",
    "\n",
    "# Groq Cloud (https://console.groq.com/docs/overview)\n",
    "gemma_29b_generation_model = tgmf.create_instance('gemma2-9b-it') \n",
    "llama_318b_instant_generation_model = tgmf.create_instance('llama-3.1-8b-instant') \n",
    "llama_3370b_versatile_generation_model = tgmf.create_instance('llama-3.3-70b-versatile')  \n",
    "# llama_guard_4_12b_generation_model = tgmf.create_instance('meta-llama/llama-guard-4-12b')  \n",
    "\n",
    "text_generation_models_groqcloud = [gemma_29b_generation_model, llama_318b_instant_generation_model, llama_3370b_versatile_generation_model]\n",
    "\n",
    "# NaviGator (https://api.ai.it.ufl.edu/ui/)\n",
    "# llama_3170b_generation_model = tgmf.create_instance('llama-3.1-70b-instruct')  \n",
    "# llama_3370b_generation_model = tgmf.create_instance('llama-3.3-70b-instruct')  \n",
    "# mixtral_87b_instruct_generation_model = tgmf.create_instance('mixtral-8x7b-instruct') \n",
    "# llama_318b_generation_model = tgmf.create_instance('llama-3.1-8b-instruct')  \n",
    "# mistral_7b_generation_model = tgmf.create_instance('mistral-7b-instruct')  \n",
    "# mistral_small_31_generation_model = tgmf.create_instance('mistral-small-3.1')\n",
    "\n",
    "# text_generation_models_navigator = [llama_3170b_generation_model, llama_3370b_generation_model, \n",
    "#                                     mixtral_87b_instruct_generation_model, llama_318b_generation_model,\n",
    "#                                     mistral_7b_generation_model, mistral_small_31_generation_model\n",
    "#                                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d02699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================== Batch 0 ===============================================\n",
      "finance --- gemma2-9b-it --- GROQ_CLOUD\n",
      "finance --- llama-3.1-8b-instant --- GROQ_CLOUD\n",
      "finance --- llama-3.3-70b-versatile --- GROQ_CLOUD\n",
      "\n",
      "health --- gemma2-9b-it --- GROQ_CLOUD\n",
      "health --- llama-3.1-8b-instant --- GROQ_CLOUD\n",
      "health --- llama-3.3-70b-versatile --- GROQ_CLOUD\n",
      "\n",
      "policy --- gemma2-9b-it --- GROQ_CLOUD\n",
      "policy --- llama-3.1-8b-instant --- GROQ_CLOUD\n",
      "policy --- llama-3.3-70b-versatile --- GROQ_CLOUD\n",
      "\n",
      "weather --- gemma2-9b-it --- GROQ_CLOUD\n",
      "weather --- llama-3.1-8b-instant --- GROQ_CLOUD\n",
      "weather --- llama-3.3-70b-versatile --- GROQ_CLOUD\n",
      "\n",
      "sport --- gemma2-9b-it --- GROQ_CLOUD\n",
      "sport --- llama-3.1-8b-instant --- GROQ_CLOUD\n",
      "sport --- llama-3.3-70b-versatile --- GROQ_CLOUD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/7 [01:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 500 - {'error': {'message': 'Internal Server Error', 'type': 'internal_server_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalServerError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      3\u001b[39m observation_prompt_outputs = {\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfinance\u001b[39m\u001b[33m\"\u001b[39m: financial_prompt_output,\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhealth\u001b[39m\u001b[33m\"\u001b[39m: health_prompt_output,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmiscellaneous\u001b[39m\u001b[33m\"\u001b[39m: miscellaneous_prompt_output,\n\u001b[32m     10\u001b[39m }\n\u001b[32m     11\u001b[39m prediction_label = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m batched_observations_df = \u001b[43mtgmf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_generate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN_batches\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mtext_generation_models\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_generation_models_groqcloud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mdomains\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobservation_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mprompt_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobservation_prompt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m                                \u001b[49m\u001b[43msentence_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprediction_label\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orange/ufdatastudios/dj.brinkley/predictions/prediction_correctness_experiments/../text_generation_models.py:291\u001b[39m, in \u001b[36mTextGenerationModelFactory.batch_generate_data\u001b[39m\u001b[34m(self, N_batches, text_generation_models, domains, prompt_outputs, sentence_label)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomain\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m --- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_generation_model.\u001b[34m__name__\u001b[39m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m --- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_generation_model.api_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    290\u001b[39m prompt_output = prompt_outputs[domain]\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m model_df = \u001b[43mtext_generation_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43msentence_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m batch_dfs.append(model_df)\n\u001b[32m    294\u001b[39m batch_predictions_df = DataProcessing.concat_dfs(batch_dfs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orange/ufdatastudios/dj.brinkley/predictions/prediction_correctness_experiments/../text_generation_models.py:194\u001b[39m, in \u001b[36mTextGenerationModelFactory.generate_predictions\u001b[39m\u001b[34m(self, prompt_template, label, domain, batch_id)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate a completion response and return as a DataFrame.\u001b[39;00m\n\u001b[32m    172\u001b[39m \n\u001b[32m    173\u001b[39m \u001b[33;03mParameters:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    190\u001b[39m \u001b[33;03m    The generated completion response formatted as a DataFrame.\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# Generate the raw prediction text\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# print(f\"\\n  prompt_template: \\n{prompt_template}\\n\\n\")\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m raw_text = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# print(f\"    {self.model_name} + {domain} generates: {raw_text}\")\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[38;5;66;03m# print(f\"generates:\\n{raw_text}\")\u001b[39;00m\n\u001b[32m    197\u001b[39m \n\u001b[32m    198\u001b[39m \n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# Parse the raw text into structured data (assuming a consistent format)\u001b[39;00m\n\u001b[32m    200\u001b[39m predictions = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orange/ufdatastudios/dj.brinkley/predictions/prediction_correctness_experiments/../text_generation_models.py:162\u001b[39m, in \u001b[36mTextGenerationModelFactory.chat_completion\u001b[39m\u001b[34m(self, messages)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat_completion\u001b[39m(\u001b[38;5;28mself\u001b[39m, messages: List[Dict]) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    140\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Generate a chat completion response.\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03m    Parameters:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m \u001b[33;03m        The generated chat completion response.\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orange/ufdatastudios/dj.brinkley/predictions/.venv/lib/python3.11/site-packages/groq/resources/chat/completions.py:355\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    177\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    221\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    222\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    223\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    225\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    354\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orange/ufdatastudios/dj.brinkley/predictions/.venv/lib/python3.11/site-packages/groq/_base_client.py:1222\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1209\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1210\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1217\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1218\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1219\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1220\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1221\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orange/ufdatastudios/dj.brinkley/predictions/.venv/lib/python3.11/site-packages/groq/_base_client.py:1031\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1028\u001b[39m             err.response.read()\n\u001b[32m   1030\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mInternalServerError\u001b[39m: Error code: 500 - {'error': {'message': 'Internal Server Error', 'type': 'internal_server_error'}}"
     ]
    }
   ],
   "source": [
    "N_batches = 7\n",
    "observation_domains = [\"finance\", \"health\", \"policy\", \"weather\", \"sport\", \"miscellaneous\"]\n",
    "observation_prompt_outputs = {\n",
    "    \"finance\": financial_prompt_output,\n",
    "    \"health\": health_prompt_output,\n",
    "    \"policy\": policy_prompt_output,\n",
    "    \"weather\": weather_prompt_output,\n",
    "    \"sport\": sport_prompt_output,\n",
    "    \"miscellaneous\": miscellaneous_prompt_output,\n",
    "}\n",
    "prediction_label = 0\n",
    "batched_observations_df = tgmf.batch_generate_data(N_batches=N_batches, \n",
    "                                text_generation_models=text_generation_models_groqcloud, \n",
    "                                domains=observation_domains,\n",
    "                                prompt_outputs=observation_prompt_outputs,\n",
    "                                sentence_label=prediction_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff382f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 800)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "batched_observations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8023081b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predictions",
   "language": "python",
   "name": "predictions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
